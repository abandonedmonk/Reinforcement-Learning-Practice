{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "import gymnasium as gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=64, fc2_units=64):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "class ReplayBuffer:\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "        \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "        \n",
    "    def sample(self):\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "        \n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float()\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long()\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float()\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float()\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None])).astype(np.uint8).float()\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, seed, lr):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "        \n",
    "        self.qnetwork_local = QNetwork(state_size, action_size, seed)\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size, seed)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr)\n",
    "        \n",
    "        self.memory = ReplayBuffer(action_size, buffer_size=int(1e5), batch_size=64, seed = seed)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "        self.t_step = (self.t_step + 1) % 4\n",
    "        if self.t_step == 0:\n",
    "            if len(self.memory) > 64:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, gamma=0.99)\n",
    "    \n",
    "    def act(self, state, eps=0.):\n",
    "        state_tensor = torch.from_numpy(state).float().unsqueeze(0)\n",
    "        print(state_tensor.type())\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state_tensor)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        if np.random.random() > eps:\n",
    "            return action_values.argmax(dim=1).item()\n",
    "        else:\n",
    "            return np.random.randint(self.action_size)\n",
    "    \n",
    "    def learn(self, experiences, gamma):\n",
    "        states, actions, rewards, next_states, dones = zip(*experiences)\n",
    "        states = torch.from_numpy(np.vstack(states)).float()\n",
    "        actions = torch.from_numpy(np.vstack(actions)).long()\n",
    "        rewards = torch.from_numpy(np.vstack(rewards)).float()\n",
    "        next_states = torch.from_numpy(np.vstack(next_states)).float()\n",
    "        dones = torch.from_numpy(np.vstack(dones).astype(np.uint8)).float()\n",
    "\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, tau=1e-3)\n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau * local_param.data + (1.0 - tau) * target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Define training parameters\n",
    "num_episodes = 250\n",
    "max_steps_per_episode = 200\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = 0.2\n",
    "epsilon_decay_rate = 0.99\n",
    "gamma = 0.9\n",
    "lr = 0.0025\n",
    "buffer_size = 10000\n",
    "buffer = deque(maxlen=buffer_size)\n",
    "batch_size = 128\n",
    "update_frequency = 10\n",
    "\n",
    "\n",
    "# Initialize the DQNAgent\n",
    "input_dim = env.observation_space.shape[0]\n",
    "output_dim = env.action_space.n\n",
    "new_agent = DQNAgent(input_dim, output_dim, seed=170715, lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.00111257, -0.01993169, -0.01443949, -0.00084542], dtype=float32), {})\n",
      "[-0.00111257 -0.01993169 -0.01443949 -0.00084542]\n",
      "torch.FloatTensor\n",
      "(array([-0.0015112 , -0.21484362, -0.0144564 ,  0.2872469 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.00504925, -0.03751699,  0.03893349, -0.01428052], dtype=float32), {})\n",
      "[ 0.00504925 -0.03751699  0.03893349 -0.01428052]\n",
      "torch.FloatTensor\n",
      "(array([ 0.00429891, -0.23317504,  0.03864788,  0.2904277 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.00493403, -0.04527399,  0.01826592, -0.0194621 ], dtype=float32), {})\n",
      "[-0.00493403 -0.04527399  0.01826592 -0.0194621 ]\n",
      "torch.FloatTensor\n",
      "(array([-0.00583951, -0.24065307,  0.01787668,  0.2789275 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04212321,  0.02118369, -0.03138705,  0.03360751], dtype=float32), {})\n",
      "[-0.04212321  0.02118369 -0.03138705  0.03360751]\n",
      "torch.FloatTensor\n",
      "(array([-0.04169954, -0.17347443, -0.0307149 ,  0.3162246 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.04430927, -0.00299138,  0.04126004,  0.01711536], dtype=float32), {})\n",
      "[ 0.04430927 -0.00299138  0.04126004  0.01711536]\n",
      "torch.FloatTensor\n",
      "(array([ 0.04424944, -0.19868001,  0.04160234,  0.3225255 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04581245, -0.03883788, -0.0351328 , -0.02819565], dtype=float32), {})\n",
      "[-0.04581245 -0.03883788 -0.0351328  -0.02819565]\n",
      "torch.FloatTensor\n",
      "(array([-0.0465892 , -0.23343885, -0.03569671,  0.25319874], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.00270459,  0.0189891 ,  0.03045223, -0.00670336], dtype=float32), {})\n",
      "[ 0.00270459  0.0189891   0.03045223 -0.00670336]\n",
      "torch.FloatTensor\n",
      "(array([ 0.00308437,  0.21366139,  0.03031817, -0.28962484], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.00122364,  0.01309846,  0.01683991, -0.02425434], dtype=float32), {})\n",
      "[ 0.00122364  0.01309846  0.01683991 -0.02425434]\n",
      "torch.FloatTensor\n",
      "(array([ 0.00148561,  0.20797491,  0.01635482, -0.31157687], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.03781511,  0.04319637, -0.00971428,  0.02435091], dtype=float32), {})\n",
      "[ 0.03781511  0.04319637 -0.00971428  0.02435091]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03867903, -0.15178494, -0.00922726,  0.3139531 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.03456735, -0.0186015 , -0.03372724, -0.02312979], dtype=float32), {})\n",
      "[-0.03456735 -0.0186015  -0.03372724 -0.02312979]\n",
      "torch.FloatTensor\n",
      "(array([-0.03493938, -0.21322393, -0.03418984,  0.2587239 ], dtype=float32), 1.0, False, False, {})\n",
      "Episode 10: Finished training\n",
      "(array([-0.04679102, -0.02119385, -0.01238093,  0.02459934], dtype=float32), {})\n",
      "[-0.04679102 -0.02119385 -0.01238093  0.02459934]\n",
      "torch.FloatTensor\n",
      "(array([-0.0472149 ,  0.17410345, -0.01188895, -0.27196404], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.0423418 ,  0.02110112, -0.00820704,  0.02748701], dtype=float32), {})\n",
      "[ 0.0423418   0.02110112 -0.00820704  0.02748701]\n",
      "torch.FloatTensor\n",
      "(array([ 0.04276382, -0.17390218, -0.0076573 ,  0.31756926], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.02601132, -0.02443874,  0.04129572, -0.04114601], dtype=float32), {})\n",
      "[ 0.02601132 -0.02443874  0.04129572 -0.04114601]\n",
      "torch.FloatTensor\n",
      "(array([ 0.02552254, -0.22012779,  0.0404728 ,  0.2642748 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([0.00545141, 0.03845527, 0.0360075 , 0.03110694], dtype=float32), {})\n",
      "[0.00545141 0.03845527 0.0360075  0.03110694]\n",
      "torch.FloatTensor\n",
      "(array([ 0.00622051, -0.15716405,  0.03662964,  0.33492965], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04120469, -0.00426691, -0.04364334, -0.04577885], dtype=float32), {})\n",
      "[-0.04120469 -0.00426691 -0.04364334 -0.04577885]\n",
      "torch.FloatTensor\n",
      "(array([-0.04129003,  0.1914528 , -0.04455892, -0.35190594], dtype=float32), 1.0, False, False, {})\n",
      "(array([0.04410283, 0.03945536, 0.03014433, 0.03013246], dtype=float32), {})\n",
      "[0.04410283 0.03945536 0.03014433 0.03013246]\n",
      "torch.FloatTensor\n",
      "(array([ 0.04489194, -0.15608563,  0.03074698,  0.33217177], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.03139848,  0.01042124, -0.03047238,  0.0292956 ], dtype=float32), {})\n",
      "[ 0.03139848  0.01042124 -0.03047238  0.0292956 ]\n",
      "torch.FloatTensor\n",
      "(array([ 0.0316069 ,  0.20596664, -0.02988647, -0.2728438 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.04946109,  0.01176932, -0.04425861,  0.04565008], dtype=float32), {})\n",
      "[ 0.04946109  0.01176932 -0.04425861  0.04565008]\n",
      "torch.FloatTensor\n",
      "(array([ 0.04969648, -0.18269096, -0.04334561,  0.3240471 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.00023514,  0.03724287,  0.00318138,  0.00704194], dtype=float32), {})\n",
      "[-0.00023514  0.03724287  0.00318138  0.00704194]\n",
      "torch.FloatTensor\n",
      "(array([ 0.00050972, -0.15792456,  0.00332222,  0.30072695], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04969639, -0.03308568, -0.01635756,  0.03349874], dtype=float32), {})\n",
      "[-0.04969639 -0.03308568 -0.01635756  0.03349874]\n",
      "torch.FloatTensor\n",
      "(array([-0.0503581 , -0.22796929, -0.01568758,  0.32097614], dtype=float32), 1.0, False, False, {})\n",
      "Episode 20: Finished training\n",
      "(array([ 0.02559229, -0.02685463, -0.02274544, -0.0321364 ], dtype=float32), {})\n",
      "[ 0.02559229 -0.02685463 -0.02274544 -0.0321364 ]\n",
      "torch.FloatTensor\n",
      "(array([ 0.0250552 ,  0.16858599, -0.02338817, -0.33190808], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.02056885,  0.00412394, -0.0017013 ,  0.02659264], dtype=float32), {})\n",
      "[-0.02056885  0.00412394 -0.0017013   0.02659264]\n",
      "torch.FloatTensor\n",
      "(array([-0.02048637, -0.19097356, -0.00116945,  0.3187383 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04115192,  0.00971066, -0.02816666,  0.03948924], dtype=float32), {})\n",
      "[-0.04115192  0.00971066 -0.02816666  0.03948924]\n",
      "torch.FloatTensor\n",
      "(array([-0.0409577 ,  0.20522496, -0.02737687, -0.26194578], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.04480434, -0.01303665, -0.04387283,  0.04365436], dtype=float32), {})\n",
      "[ 0.04480434 -0.01303665 -0.04387283  0.04365436]\n",
      "torch.FloatTensor\n",
      "(array([ 0.04454361,  0.18268608, -0.04299974, -0.26254168], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.03786199, -0.02727133, -0.0466168 ,  0.01824928], dtype=float32), {})\n",
      "[ 0.03786199 -0.02727133 -0.0466168   0.01824928]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03731656,  0.16848709, -0.04625181, -0.28876972], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04363057,  0.04484736,  0.03286463, -0.01768767], dtype=float32), {})\n",
      "[-0.04363057  0.04484736  0.03286463 -0.01768767]\n",
      "torch.FloatTensor\n",
      "(array([-0.04273362,  0.23948295,  0.03251088, -0.29982296], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04656848,  0.028907  ,  0.03665156, -0.00687135], dtype=float32), {})\n",
      "[-0.04656848  0.028907    0.03665156 -0.00687135]\n",
      "torch.FloatTensor\n",
      "(array([-0.04599034,  0.22348467,  0.03651414, -0.2877687 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.02584415, -0.04551936, -0.03795379,  0.02368969], dtype=float32), {})\n",
      "[-0.02584415 -0.04551936 -0.03795379  0.02368969]\n",
      "torch.FloatTensor\n",
      "(array([-0.02675454, -0.24007705, -0.03748   ,  0.30416033], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.00473685,  0.0068258 ,  0.02332693,  0.01265784], dtype=float32), {})\n",
      "[-0.00473685  0.0068258   0.02332693  0.01265784]\n",
      "torch.FloatTensor\n",
      "(array([-0.00460034,  0.20160559,  0.02358009, -0.27257484], dtype=float32), 1.0, False, False, {})\n",
      "(array([0.03716935, 0.03032275, 0.02943724, 0.04582436], dtype=float32), {})\n",
      "[0.03716935 0.03032275 0.02943724 0.04582436]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03777581, -0.16520868,  0.03035373,  0.34764773], dtype=float32), 1.0, False, False, {})\n",
      "Episode 30: Finished training\n",
      "(array([ 0.03082116, -0.0070193 , -0.03651775, -0.0309923 ], dtype=float32), {})\n",
      "[ 0.03082116 -0.0070193  -0.03651775 -0.0309923 ]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03068077, -0.20159906, -0.0371376 ,  0.24994892], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.01513238, -0.0126527 ,  0.00617057,  0.02618999], dtype=float32), {})\n",
      "[-0.01513238 -0.0126527   0.00617057  0.02618999]\n",
      "torch.FloatTensor\n",
      "(array([-0.01538543,  0.18238023,  0.00669437, -0.2645397 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.04272917,  0.04150594,  0.03387066, -0.03236381], dtype=float32), {})\n",
      "[ 0.04272917  0.04150594  0.03387066 -0.03236381]\n",
      "torch.FloatTensor\n",
      "(array([ 0.04355929, -0.15408494,  0.03322339,  0.27081034], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.03321449, -0.03585899, -0.01351527, -0.00241168], dtype=float32), {})\n",
      "[ 0.03321449 -0.03585899 -0.01351527 -0.00241168]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03249732, -0.23078454, -0.0135635 ,  0.28597656], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.0321496 , -0.01943543,  0.04344236, -0.02403589], dtype=float32), {})\n",
      "[ 0.0321496  -0.01943543  0.04344236 -0.02403589]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03176089, -0.21515259,  0.04296165,  0.2820309 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.03023874, -0.04173792,  0.0257361 , -0.00509673], dtype=float32), {})\n",
      "[ 0.03023874 -0.04173792  0.0257361  -0.00509673]\n",
      "torch.FloatTensor\n",
      "(array([ 0.02940398,  0.15300567,  0.02563417, -0.2895498 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.01712018,  0.0101796 ,  0.04476641, -0.03791337], dtype=float32), {})\n",
      "[-0.01712018  0.0101796   0.04476641 -0.03791337]\n",
      "torch.FloatTensor\n",
      "(array([-0.01691659,  0.20463195,  0.04400815, -0.31614277], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04485175, -0.0408169 ,  0.0105458 , -0.03994003], dtype=float32), {})\n",
      "[-0.04485175 -0.0408169   0.0105458  -0.03994003]\n",
      "torch.FloatTensor\n",
      "(array([-0.04566809,  0.15415224,  0.009747  , -0.32927707], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.03055724, -0.00284646,  0.01438689,  0.01937547], dtype=float32), {})\n",
      "[ 0.03055724 -0.00284646  0.01438689  0.01937547]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03050031,  0.19206624,  0.0147744 , -0.26873374], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.02879764, -0.02196085, -0.04310131, -0.0389764 ], dtype=float32), {})\n",
      "[-0.02879764 -0.02196085 -0.04310131 -0.0389764 ]\n",
      "torch.FloatTensor\n",
      "(array([-0.02923686,  0.17375183, -0.04388084, -0.34494063], dtype=float32), 1.0, False, False, {})\n",
      "Episode 40: Finished training\n",
      "(array([ 0.01648149,  0.03338386, -0.0178299 ,  0.02343599], dtype=float32), {})\n",
      "[ 0.01648149  0.03338386 -0.0178299   0.02343599]\n",
      "torch.FloatTensor\n",
      "(array([ 0.01714917, -0.16147792, -0.01736118,  0.31044048], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.02111465, -0.02562611, -0.022647  , -0.02144013], dtype=float32), {})\n",
      "[-0.02111465 -0.02562611 -0.022647   -0.02144013]\n",
      "torch.FloatTensor\n",
      "(array([-0.02162717,  0.16981319, -0.0230758 , -0.32118154], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.04929645,  0.01172019, -0.01507902, -0.00713434], dtype=float32), {})\n",
      "[ 0.04929645  0.01172019 -0.01507902 -0.00713434]\n",
      "torch.FloatTensor\n",
      "(array([ 0.04953085,  0.20705512, -0.01522171, -0.3045365 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04113335, -0.00850596, -0.02455391, -0.02936506], dtype=float32), {})\n",
      "[-0.04113335 -0.00850596 -0.02455391 -0.02936506]\n",
      "torch.FloatTensor\n",
      "(array([-0.04130347,  0.18695934, -0.02514121, -0.32969278], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.00279899, -0.00135224, -0.01293012, -0.04795152], dtype=float32), {})\n",
      "[ 0.00279899 -0.00135224 -0.01293012 -0.04795152]\n",
      "torch.FloatTensor\n",
      "(array([ 0.00277194,  0.19395271, -0.01388915, -0.3446858 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04331329, -0.00835009,  0.03448093, -0.03554762], dtype=float32), {})\n",
      "[-0.04331329 -0.00835009  0.03448093 -0.03554762]\n",
      "torch.FloatTensor\n",
      "(array([-0.0434803 ,  0.18626086,  0.03376998, -0.31715515], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.01214848,  0.01415364,  0.01107685, -0.02004509], dtype=float32), {})\n",
      "[-0.01214848  0.01415364  0.01107685 -0.02004509]\n",
      "torch.FloatTensor\n",
      "(array([-0.01186541,  0.209115  ,  0.01067595, -0.30921265], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.01236801,  0.02498266,  0.04550095,  0.04739213], dtype=float32), {})\n",
      "[-0.01236801  0.02498266  0.04550095  0.04739213]\n",
      "torch.FloatTensor\n",
      "(array([-0.01186835, -0.1707612 ,  0.04644879,  0.3540767 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.03983049, -0.03851528,  0.04521135, -0.03801184], dtype=float32), {})\n",
      "[ 0.03983049 -0.03851528  0.04521135 -0.03801184]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03906019, -0.23425542,  0.04445111,  0.26858595], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.03710994,  0.00716639, -0.02983402, -0.02662979], dtype=float32), {})\n",
      "[ 0.03710994  0.00716639 -0.02983402 -0.02662979]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03725328,  0.20270321, -0.03036661, -0.3285744 ], dtype=float32), 1.0, False, False, {})\n",
      "Episode 50: Finished training\n",
      "(array([-0.04889674, -0.03195713,  0.02998515,  0.03492537], dtype=float32), {})\n",
      "[-0.04889674 -0.03195713  0.02998515  0.03492537]\n",
      "torch.FloatTensor\n",
      "(array([-0.04953588,  0.16272229,  0.03068366, -0.24814816], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.01078732, -0.03602347,  0.00716915, -0.01433572], dtype=float32), {})\n",
      "[ 0.01078732 -0.03602347  0.00716915 -0.01433572]\n",
      "torch.FloatTensor\n",
      "(array([ 0.01006686,  0.15899493,  0.00688243, -0.30474812], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.03528617,  0.0053889 , -0.03312071,  0.02185863], dtype=float32), {})\n",
      "[ 0.03528617  0.0053889  -0.03312071  0.02185863]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03539395,  0.2009698 , -0.03268354, -0.28108752], dtype=float32), 1.0, False, False, {})\n",
      "(array([0.02997391, 0.0386432 , 0.02577983, 0.02083511], dtype=float32), {})\n",
      "[0.02997391 0.0386432  0.02577983 0.02083511]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03074678, -0.15683879,  0.02619654,  0.3215391 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.01572099,  0.03017919, -0.02952633, -0.04530874], dtype=float32), {})\n",
      "[-0.01572099  0.03017919 -0.02952633 -0.04530874]\n",
      "torch.FloatTensor\n",
      "(array([-0.0151174 ,  0.22571182, -0.0304325 , -0.34715933], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.0265485 , -0.03447478, -0.04288219,  0.02313852], dtype=float32), {})\n",
      "[ 0.0265485  -0.03447478 -0.04288219  0.02313852]\n",
      "torch.FloatTensor\n",
      "(array([ 0.025859  , -0.22895637, -0.04241941,  0.3019892 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.03765734, -0.02570721,  0.01505343,  0.00867941], dtype=float32), {})\n",
      "[-0.03765734 -0.02570721  0.01505343  0.00867941]\n",
      "torch.FloatTensor\n",
      "(array([-0.03817149,  0.16919565,  0.01522702, -0.27921623], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.02551732,  0.01942658,  0.01153481, -0.02642225], dtype=float32), {})\n",
      "[ 0.02551732  0.01942658  0.01153481 -0.02642225]\n",
      "torch.FloatTensor\n",
      "(array([ 0.02590586,  0.21438123,  0.01100637, -0.3154436 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.01930555, -0.03176417, -0.03787363,  0.0330702 ], dtype=float32), {})\n",
      "[ 0.01930555 -0.03176417 -0.03787363  0.0330702 ]\n",
      "torch.FloatTensor\n",
      "(array([ 0.01867027,  0.16387986, -0.03721222, -0.27131757], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.03250054,  0.03835731,  0.02642609,  0.00976499], dtype=float32), {})\n",
      "[-0.03250054  0.03835731  0.02642609  0.00976499]\n",
      "torch.FloatTensor\n",
      "(array([-0.0317334 ,  0.2330905 ,  0.02662139, -0.27446446], dtype=float32), 1.0, False, False, {})\n",
      "Episode 60: Finished training\n",
      "(array([ 0.01417555,  0.04689674, -0.03495866,  0.03591414], dtype=float32), {})\n",
      "[ 0.01417555  0.04689674 -0.03495866  0.03591414]\n",
      "torch.FloatTensor\n",
      "(array([ 0.01511349,  0.24250211, -0.03424038, -0.2675904 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.00719836,  0.00238518, -0.03574181, -0.04551004], dtype=float32), {})\n",
      "[ 0.00719836  0.00238518 -0.03574181 -0.04551004]\n",
      "torch.FloatTensor\n",
      "(array([ 0.00724606,  0.19800094, -0.03665201, -0.34925213], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04039297,  0.00524999,  0.00190265, -0.03924889], dtype=float32), {})\n",
      "[-0.04039297  0.00524999  0.00190265 -0.03924889]\n",
      "torch.FloatTensor\n",
      "(array([-0.04028796, -0.18989919,  0.00111768,  0.25403374], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04621102,  0.04118891,  0.00740423,  0.03499653], dtype=float32), {})\n",
      "[-0.04621102  0.04118891  0.00740423  0.03499653]\n",
      "torch.FloatTensor\n",
      "(array([-0.04538724,  0.23620391,  0.00810416, -0.2553411 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.02823625,  0.02404633, -0.02843527, -0.00351553], dtype=float32), {})\n",
      "[-0.02823625  0.02404633 -0.02843527 -0.00351553]\n",
      "torch.FloatTensor\n",
      "(array([-0.02775532,  0.2195643 , -0.02850558, -0.30503276], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.04974328,  0.021948  , -0.03832946, -0.02689061], dtype=float32), {})\n",
      "[ 0.04974328  0.021948   -0.03832946 -0.02689061]\n",
      "torch.FloatTensor\n",
      "(array([ 0.05018224,  0.21759807, -0.03886727, -0.33141625], dtype=float32), 1.0, False, False, {})\n",
      "(array([0.03173548, 0.01795981, 0.0470848 , 0.04929137], dtype=float32), {})\n",
      "[0.03173548 0.01795981 0.0470848  0.04929137]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03209468,  0.21237609,  0.04807063, -0.22817203], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.02710063,  0.02093721,  0.00137889, -0.00461585], dtype=float32), {})\n",
      "[ 0.02710063  0.02093721  0.00137889 -0.00461585]\n",
      "torch.FloatTensor\n",
      "(array([ 0.02751937,  0.21603936,  0.00128657, -0.2968634 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.03870735, -0.00328357,  0.00307396, -0.0079921 ], dtype=float32), {})\n",
      "[ 0.03870735 -0.00328357  0.00307396 -0.0079921 ]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03864168, -0.19844948,  0.00291412,  0.2856591 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.01486589, -0.01029664, -0.02549956, -0.04521426], dtype=float32), {})\n",
      "[ 0.01486589 -0.01029664 -0.02549956 -0.04521426]\n",
      "torch.FloatTensor\n",
      "(array([ 0.01465996,  0.1851815 , -0.02640384, -0.3458322 ], dtype=float32), 1.0, False, False, {})\n",
      "Episode 70: Finished training\n",
      "(array([ 0.02979715,  0.02855385, -0.02301702,  0.03402763], dtype=float32), {})\n",
      "[ 0.02979715  0.02855385 -0.02301702  0.03402763]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03036823,  0.22399819, -0.02233647, -0.26582763], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.04989135,  0.00497433, -0.02170299, -0.04484301], dtype=float32), {})\n",
      "[ 0.04989135  0.00497433 -0.02170299 -0.04484301]\n",
      "torch.FloatTensor\n",
      "(array([ 0.04999084,  0.20040065, -0.02259985, -0.34429365], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.00797852, -0.01664801,  0.04090681, -0.03576853], dtype=float32), {})\n",
      "[ 0.00797852 -0.01664801  0.04090681 -0.03576853]\n",
      "torch.FloatTensor\n",
      "(array([ 0.00764556,  0.17786418,  0.04019144, -0.31526947], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04983475,  0.00610008,  0.01416019, -0.03047842], dtype=float32), {})\n",
      "[-0.04983475  0.00610008  0.01416019 -0.03047842]\n",
      "torch.FloatTensor\n",
      "(array([-0.04971275,  0.20101613,  0.01355062, -0.31866023], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.04760966,  0.0191484 , -0.02348118, -0.00848054], dtype=float32), {})\n",
      "[ 0.04760966  0.0191484  -0.02348118 -0.00848054]\n",
      "torch.FloatTensor\n",
      "(array([ 0.04799263,  0.2145991 , -0.02365079, -0.3084786 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.01467224, -0.03459332,  0.00228193,  0.03664847], dtype=float32), {})\n",
      "[ 0.01467224 -0.03459332  0.00228193  0.03664847]\n",
      "torch.FloatTensor\n",
      "(array([ 0.01398038, -0.22974792,  0.0030149 ,  0.3300505 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.03023367, -0.04452857, -0.01116211,  0.02390818], dtype=float32), {})\n",
      "[ 0.03023367 -0.04452857 -0.01116211  0.02390818]\n",
      "torch.FloatTensor\n",
      "(array([ 0.0293431 ,  0.15075167, -0.01068395, -0.2722755 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.00387128,  0.00827647, -0.04130031, -0.02162135], dtype=float32), {})\n",
      "[-0.00387128  0.00827647 -0.04130031 -0.02162135]\n",
      "torch.FloatTensor\n",
      "(array([-0.00370575,  0.20396562, -0.04173273, -0.32704362], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.009656  , -0.03181383, -0.02956345,  0.01895434], dtype=float32), {})\n",
      "[-0.009656   -0.03181383 -0.02956345  0.01895434]\n",
      "torch.FloatTensor\n",
      "(array([-0.01029227,  0.16371934, -0.02918437, -0.28290763], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.00456769,  0.04166994,  0.01836805, -0.00350484], dtype=float32), {})\n",
      "[ 0.00456769  0.04166994  0.01836805 -0.00350484]\n",
      "torch.FloatTensor\n",
      "(array([ 0.00540108, -0.15371056,  0.01829795,  0.29491636], dtype=float32), 1.0, False, False, {})\n",
      "Episode 80: Finished training\n",
      "(array([-0.02029461, -0.00646898, -0.02776189,  0.02526032], dtype=float32), {})\n",
      "[-0.02029461 -0.00646898 -0.02776189  0.02526032]\n",
      "torch.FloatTensor\n",
      "(array([-0.02042399,  0.18903987, -0.02725669, -0.2760509 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.02293193, -0.03037396, -0.01398576, -0.02112096], dtype=float32), {})\n",
      "[ 0.02293193 -0.03037396 -0.01398576 -0.02112096]\n",
      "torch.FloatTensor\n",
      "(array([ 0.02232445,  0.16494574, -0.01440818, -0.31818354], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.03206529, -0.02894873,  0.01902786, -0.00684923], dtype=float32), {})\n",
      "[ 0.03206529 -0.02894873  0.01902786 -0.00684923]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03148632,  0.16589524,  0.01889088, -0.29346842], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.04967216, -0.02712299,  0.01058585, -0.02610982], dtype=float32), {})\n",
      "[ 0.04967216 -0.02712299  0.01058585 -0.02610982]\n",
      "torch.FloatTensor\n",
      "(array([ 0.0491297 ,  0.16784556,  0.01006365, -0.31543407], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04468239,  0.00281125, -0.03951938, -0.01330747], dtype=float32), {})\n",
      "[-0.04468239  0.00281125 -0.03951938 -0.01330747]\n",
      "torch.FloatTensor\n",
      "(array([-0.04462617,  0.19847701, -0.03978553, -0.31819263], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.02218034, -0.03707255, -0.04530539, -0.04057222], dtype=float32), {})\n",
      "[-0.02218034 -0.03707255 -0.04530539 -0.04057222]\n",
      "torch.FloatTensor\n",
      "(array([-0.02292179,  0.1586688 , -0.04611683, -0.34719822], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.03571129,  0.03714047,  0.03536959, -0.01032524], dtype=float32), {})\n",
      "[-0.03571129  0.03714047  0.03536959 -0.01032524]\n",
      "torch.FloatTensor\n",
      "(array([-0.03496848,  0.23173779,  0.03516309, -0.29164216], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04870472, -0.03284289, -0.01584191, -0.003355  ], dtype=float32), {})\n",
      "[-0.04870472 -0.03284289 -0.01584191 -0.003355  ]\n",
      "torch.FloatTensor\n",
      "(array([-0.04936158,  0.16250263, -0.01590901, -0.30099383], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.02918428,  0.00613898, -0.01343709,  0.02395423], dtype=float32), {})\n",
      "[-0.02918428  0.00613898 -0.01343709  0.02395423]\n",
      "torch.FloatTensor\n",
      "(array([-0.0290615 ,  0.20145103, -0.01295801, -0.27293777], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.01731397, -0.00079892,  0.00568714, -0.04021297], dtype=float32), {})\n",
      "[-0.01731397 -0.00079892  0.00568714 -0.04021297]\n",
      "torch.FloatTensor\n",
      "(array([-0.01732995,  0.19424102,  0.00488288, -0.33109614], dtype=float32), 1.0, False, False, {})\n",
      "Episode 90: Finished training\n",
      "(array([ 0.01321251, -0.0337206 , -0.01062695,  0.01477396], dtype=float32), {})\n",
      "[ 0.01321251 -0.0337206  -0.01062695  0.01477396]\n",
      "torch.FloatTensor\n",
      "(array([ 0.0125381 , -0.22868855, -0.01033147,  0.3040851 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.01374136,  0.02139896,  0.03545192, -0.04462387], dtype=float32), {})\n",
      "[-0.01374136  0.02139896  0.03545192 -0.04462387]\n",
      "torch.FloatTensor\n",
      "(array([-0.01331338,  0.21599509,  0.03455944, -0.32591397], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.02650893, -0.03701423, -0.04569775,  0.01141158], dtype=float32), {})\n",
      "[-0.02650893 -0.03701423 -0.04569775  0.01141158]\n",
      "torch.FloatTensor\n",
      "(array([-0.02724921, -0.23145205, -0.04546952,  0.28933334], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.02942909, -0.02002032,  0.03762275,  0.00302211], dtype=float32), {})\n",
      "[-0.02942909 -0.02002032  0.03762275  0.00302211]\n",
      "torch.FloatTensor\n",
      "(array([-0.02982949,  0.17454243,  0.03768319, -0.27755702], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.03039264, -0.03462499, -0.01964219, -0.01164298], dtype=float32), {})\n",
      "[ 0.03039264 -0.03462499 -0.01964219 -0.01164298]\n",
      "torch.FloatTensor\n",
      "(array([ 0.02970014,  0.16077307, -0.01987505, -0.31045797], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.01555077,  0.02517887, -0.0341788 ,  0.02768232], dtype=float32), {})\n",
      "[-0.01555077  0.02517887 -0.0341788   0.02768232]\n",
      "torch.FloatTensor\n",
      "(array([-0.01504719,  0.22077388, -0.03362515, -0.27558544], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.02650717, -0.045163  ,  0.01239142,  0.03661355], dtype=float32), {})\n",
      "[ 0.02650717 -0.045163    0.01239142  0.03661355]\n",
      "torch.FloatTensor\n",
      "(array([ 0.02560391,  0.14977908,  0.01312369, -0.25213414], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.04685416,  0.02325122,  0.02006296, -0.03782851], dtype=float32), {})\n",
      "[ 0.04685416  0.02325122  0.02006296 -0.03782851]\n",
      "torch.FloatTensor\n",
      "(array([ 0.04731918,  0.2180798 ,  0.01930639, -0.32411447], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.00104839,  0.03298178,  0.04118901, -0.0218932 ], dtype=float32), {})\n",
      "[-0.00104839  0.03298178  0.04118901 -0.0218932 ]\n",
      "torch.FloatTensor\n",
      "(array([-0.00038875,  0.22748958,  0.04075115, -0.3013013 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04545508,  0.02549344, -0.00466869, -0.03801437], dtype=float32), {})\n",
      "[-0.04545508  0.02549344 -0.00466869 -0.03801437]\n",
      "torch.FloatTensor\n",
      "(array([-0.04494521,  0.22068202, -0.00542898, -0.33216664], dtype=float32), 1.0, False, False, {})\n",
      "Episode 100: Finished training\n",
      "(array([-0.0057409 , -0.02310732,  0.02899331, -0.01355994], dtype=float32), {})\n",
      "[-0.0057409  -0.02310732  0.02899331 -0.01355994]\n",
      "torch.FloatTensor\n",
      "(array([-0.00620305,  0.1715871 ,  0.02872211, -0.29695597], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.02770117, -0.04795896,  0.04638338,  0.03499772], dtype=float32), {})\n",
      "[-0.02770117 -0.04795896  0.04638338  0.03499772]\n",
      "torch.FloatTensor\n",
      "(array([-0.02866035,  0.14646822,  0.04708334, -0.24269755], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.03420087, -0.0074317 ,  0.03207322, -0.01085658], dtype=float32), {})\n",
      "[-0.03420087 -0.0074317   0.03207322 -0.01085658]\n",
      "torch.FloatTensor\n",
      "(array([-0.0343495 ,  0.18721594,  0.03185609, -0.29325   ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.01276112, -0.01437557,  0.01901784,  0.04312072], dtype=float32), {})\n",
      "[-0.01276112 -0.01437557  0.01901784  0.04312072]\n",
      "torch.FloatTensor\n",
      "(array([-0.01304863,  0.18046859,  0.01988025, -0.24350175], dtype=float32), 1.0, False, False, {})\n",
      "(array([0.04973315, 0.00447525, 0.03313773, 0.02049049], dtype=float32), {})\n",
      "[0.04973315 0.00447525 0.03313773 0.02049049]\n",
      "torch.FloatTensor\n",
      "(array([ 0.04982265, -0.19110587,  0.03354754,  0.32344183], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.00480317, -0.04418989,  0.03016469,  0.02063339], dtype=float32), {})\n",
      "[-0.00480317 -0.04418989  0.03016469  0.02063339]\n",
      "torch.FloatTensor\n",
      "(array([-0.00568696,  0.15048678,  0.03057736, -0.26238167], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.00117387, -0.00260298,  0.01611451,  0.03968215], dtype=float32), {})\n",
      "[-0.00117387 -0.00260298  0.01611451  0.03968215]\n",
      "torch.FloatTensor\n",
      "(array([-0.00122593,  0.19228423,  0.01690815, -0.24787325], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.03593937, -0.03744859, -0.02512973, -0.02634856], dtype=float32), {})\n",
      "[ 0.03593937 -0.03744859 -0.02512973 -0.02634856]\n",
      "torch.FloatTensor\n",
      "(array([ 0.0351904 ,  0.15802456, -0.0256567 , -0.32685307], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.01492958,  0.01189227, -0.02852581,  0.03637083], dtype=float32), {})\n",
      "[ 0.01492958  0.01189227 -0.02852581  0.03637083]\n",
      "torch.FloatTensor\n",
      "(array([ 0.01516743,  0.20741142, -0.0277984 , -0.26517403], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.01252427, -0.04600781, -0.0368751 , -0.0136636 ], dtype=float32), {})\n",
      "[-0.01252427 -0.04600781 -0.0368751  -0.0136636 ]\n",
      "torch.FloatTensor\n",
      "(array([-0.01344443,  0.14962304, -0.03714837, -0.3177492 ], dtype=float32), 1.0, False, False, {})\n",
      "Episode 110: Finished training\n",
      "(array([ 0.04305195, -0.00540761, -0.03209487, -0.01355317], dtype=float32), {})\n",
      "[ 0.04305195 -0.00540761 -0.03209487 -0.01355317]\n",
      "torch.FloatTensor\n",
      "(array([ 0.04294379,  0.19015957, -0.03236594, -0.31618714], dtype=float32), 1.0, False, False, {})\n",
      "(array([0.0371599 , 0.0414282 , 0.04407679, 0.0047392 ], dtype=float32), {})\n",
      "[0.0371599  0.0414282  0.04407679 0.0047392 ]\n",
      "torch.FloatTensor\n",
      "(array([ 0.03798846, -0.15429725,  0.04417157,  0.31099662], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.04221967, -0.00643002, -0.00845787, -0.01562093], dtype=float32), {})\n",
      "[-0.04221967 -0.00643002 -0.00845787 -0.01562093]\n",
      "torch.FloatTensor\n",
      "(array([-0.04234827,  0.1888122 , -0.00877029, -0.31096038], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.00808638, -0.04893995, -0.04003932, -0.0361344 ], dtype=float32), {})\n",
      "[-0.00808638 -0.04893995 -0.04003932 -0.0361344 ]\n",
      "torch.FloatTensor\n",
      "(array([-0.00906518,  0.14673261, -0.04076201, -0.34117642], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.02006379, -0.01915735, -0.01456328,  0.00469142], dtype=float32), {})\n",
      "[-0.02006379 -0.01915735 -0.01456328  0.00469142]\n",
      "torch.FloatTensor\n",
      "(array([-0.02044694,  0.17617041, -0.01446946, -0.2925506 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.03688173,  0.02998151,  0.02105996, -0.01646656], dtype=float32), {})\n",
      "[-0.03688173  0.02998151  0.02105996 -0.01646656]\n",
      "torch.FloatTensor\n",
      "(array([-0.0362821 ,  0.2247952 ,  0.02073063, -0.30243114], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.02231685, -0.00697987,  0.00763075,  0.04098114], dtype=float32), {})\n",
      "[ 0.02231685 -0.00697987  0.00763075  0.04098114]\n",
      "torch.FloatTensor\n",
      "(array([ 0.02217725,  0.18803184,  0.00845037, -0.24928448], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.00782005,  0.02663863,  0.03071915, -0.01559934], dtype=float32), {})\n",
      "[ 0.00782005  0.02663863  0.03071915 -0.01559934]\n",
      "torch.FloatTensor\n",
      "(array([ 0.00835282,  0.22130688,  0.03040716, -0.29843393], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.03049511,  0.01491351,  0.0164646 , -0.0201493 ], dtype=float32), {})\n",
      "[-0.03049511  0.01491351  0.0164646  -0.0201493 ]\n",
      "torch.FloatTensor\n",
      "(array([-0.03019684,  0.20979552,  0.01606161, -0.30759233], dtype=float32), 1.0, False, False, {})\n",
      "(array([0.04160578, 0.02985335, 0.04331933, 0.02741938], dtype=float32), {})\n",
      "[0.04160578 0.02985335 0.04331933 0.02741938]\n",
      "torch.FloatTensor\n",
      "(array([ 0.04220285,  0.22432816,  0.04386771, -0.25128728], dtype=float32), 1.0, False, False, {})\n",
      "Episode 120: Finished training\n",
      "(array([ 0.01396048, -0.04646868,  0.02655189,  0.01589052], dtype=float32), {})\n",
      "[ 0.01396048 -0.04646868  0.02655189  0.01589052]\n",
      "torch.FloatTensor\n",
      "(array([ 0.01303111,  0.14826262,  0.0268697 , -0.26829812], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.00822708, -0.04820257,  0.02350004, -0.01925156], dtype=float32), {})\n",
      "[ 0.00822708 -0.04820257  0.02350004 -0.01925156]\n",
      "torch.FloatTensor\n",
      "(array([ 0.00726303,  0.14657462,  0.02311501, -0.3044283 ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.02414439, -0.02216182,  0.00414922, -0.01969859], dtype=float32), {})\n",
      "[-0.02414439 -0.02216182  0.00414922 -0.01969859]\n",
      "torch.FloatTensor\n",
      "(array([-0.02458762, -0.21734303,  0.00375525,  0.27429056], dtype=float32), 1.0, False, False, {})\n",
      "(array([ 0.01373012, -0.02307262,  0.04835743, -0.02813892], dtype=float32), {})\n",
      "[ 0.01373012 -0.02307262  0.04835743 -0.02813892]\n",
      "torch.FloatTensor\n",
      "(array([ 0.01326867,  0.1713237 ,  0.04779465, -0.30518097], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.03129511, -0.03611622,  0.02052593, -0.02814092], dtype=float32), {})\n",
      "[-0.03129511 -0.03611622  0.02052593 -0.02814092]\n",
      "torch.FloatTensor\n",
      "(array([-0.03201743,  0.15870546,  0.01996311, -0.31427768], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.03539047,  0.03732421,  0.00027479, -0.03685183], dtype=float32), {})\n",
      "[-0.03539047  0.03732421  0.00027479 -0.03685183]\n",
      "torch.FloatTensor\n",
      "(array([-0.03464399,  0.23244222, -0.00046224, -0.32944804], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.01786426, -0.01970431,  0.04623674, -0.00565533], dtype=float32), {})\n",
      "[-0.01786426 -0.01970431  0.04623674 -0.00565533]\n",
      "torch.FloatTensor\n",
      "(array([-0.01825834,  0.1747251 ,  0.04612363, -0.283399  ], dtype=float32), 1.0, False, False, {})\n",
      "(array([-0.01673991,  0.03079244,  0.00970964, -0.01603621], dtype=float32), {})\n",
      "[-0.01673991  0.03079244  0.00970964 -0.01603621]\n",
      "torch.FloatTensor\n",
      "(array([-0.01612406,  0.2257738 ,  0.00938892, -0.3056399 ], dtype=float32), 1.0, False, False, {})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anshu\\miniconda3\\envs\\ml-zoomcamp\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:249: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x1 and 4x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m     batch \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(buffer, batch_size)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Update the agent's knowledge\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mnew_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Check if the episode has ended\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 44\u001b[0m, in \u001b[0;36mDQNAgent.learn\u001b[1;34m(self, experiences, gamma)\u001b[0m\n\u001b[0;32m     41\u001b[0m next_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39mvstack(next_states))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     42\u001b[0m dones \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39mvstack(dones)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m---> 44\u001b[0m Q_targets_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqnetwork_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     45\u001b[0m Q_targets \u001b[38;5;241m=\u001b[39m rewards \u001b[38;5;241m+\u001b[39m (gamma \u001b[38;5;241m*\u001b[39m Q_targets_next \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dones))\n\u001b[0;32m     47\u001b[0m Q_expected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnetwork_local(states)\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m1\u001b[39m, actions)\n",
      "File \u001b[1;32mc:\\Users\\anshu\\miniconda3\\envs\\ml-zoomcamp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anshu\\miniconda3\\envs\\ml-zoomcamp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m, in \u001b[0;36mQNetwork.forward\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[1;32m---> 10\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32mc:\\Users\\anshu\\miniconda3\\envs\\ml-zoomcamp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anshu\\miniconda3\\envs\\ml-zoomcamp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\anshu\\miniconda3\\envs\\ml-zoomcamp\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x1 and 4x64)"
     ]
    }
   ],
   "source": [
    "for episode in range(num_episodes):\n",
    "    # Reset the environment\n",
    "    state = env.reset()\n",
    "    epsilon = max(epsilon_end, epsilon_start * (epsilon_decay_rate ** episode))\n",
    "\n",
    "    # Run one episode\n",
    "    for step in range(max_steps_per_episode):\n",
    "        print(state)\n",
    "        # Choose and perform an action\n",
    "        state = state[0]\n",
    "        state = np.array(state)\n",
    "        print(state)\n",
    "        action = new_agent.act(state, epsilon)\n",
    "        print(env.step(action))\n",
    "        next_state, reward, done, _ = env.step(action)[0]\n",
    "        \n",
    "        buffer.append((state, action, reward, next_state, done))\n",
    "        \n",
    "        if len(buffer) >= batch_size:\n",
    "            batch = random.sample(buffer, batch_size)\n",
    "            # Update the agent's knowledge\n",
    "            new_agent.learn(batch, gamma)\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        # Check if the episode has ended\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    if (episode + 1) % update_frequency == 0:\n",
    "        print(f\"Episode {episode + 1}: Finished training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
