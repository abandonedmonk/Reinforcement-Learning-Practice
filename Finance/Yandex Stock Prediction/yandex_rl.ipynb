{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0951b718",
   "metadata": {},
   "source": [
    "# Using RL to predict Stock Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d494a",
   "metadata": {},
   "source": [
    "### Basic Data\n",
    "Using only the basic Open, Min, Max and Close to predict the prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52a3d98",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ef7f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4026ed04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>0.100178</td>\n",
       "      <td>0.100614</td>\n",
       "      <td>0.100178</td>\n",
       "      <td>0.100178</td>\n",
       "      <td>469033600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.094952</td>\n",
       "      <td>0.094952</td>\n",
       "      <td>175884800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.087983</td>\n",
       "      <td>0.087983</td>\n",
       "      <td>105728000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-12-17</td>\n",
       "      <td>0.090160</td>\n",
       "      <td>0.090596</td>\n",
       "      <td>0.090160</td>\n",
       "      <td>0.090160</td>\n",
       "      <td>86441600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-12-18</td>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.093210</td>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.092774</td>\n",
       "      <td>73449600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close     Volume  Dividends  \\\n",
       "0  1980-12-12  0.100178  0.100614  0.100178  0.100178  469033600        0.0   \n",
       "1  1980-12-15  0.095388  0.095388  0.094952  0.094952  175884800        0.0   \n",
       "2  1980-12-16  0.088418  0.088418  0.087983  0.087983  105728000        0.0   \n",
       "3  1980-12-17  0.090160  0.090596  0.090160  0.090160   86441600        0.0   \n",
       "4  1980-12-18  0.092774  0.093210  0.092774  0.092774   73449600        0.0   \n",
       "\n",
       "   Stock Splits  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"AAPL.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d90199",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Date', 'Volume', 'Dividends', 'Stock Splits'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c0c58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100178</td>\n",
       "      <td>0.100614</td>\n",
       "      <td>0.100178</td>\n",
       "      <td>0.100178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.094952</td>\n",
       "      <td>0.094952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.087983</td>\n",
       "      <td>0.087983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.090160</td>\n",
       "      <td>0.090596</td>\n",
       "      <td>0.090160</td>\n",
       "      <td>0.090160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.093210</td>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.092774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close\n",
       "0  0.100178  0.100614  0.100178  0.100178\n",
       "1  0.095388  0.095388  0.094952  0.094952\n",
       "2  0.088418  0.088418  0.087983  0.087983\n",
       "3  0.090160  0.090596  0.090160  0.090160\n",
       "4  0.092774  0.093210  0.092774  0.092774"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a16d5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10483 entries, 0 to 10482\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Open    10483 non-null  float64\n",
      " 1   High    10483 non-null  float64\n",
      " 2   Low     10483 non-null  float64\n",
      " 3   Close   10483 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 327.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "967c5895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anshu\\AppData\\Local\\Temp\\ipykernel_21528\\32999384.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df['remove'] = df.apply(lambda x: all([abs(i - x[0]) < 1e-8 for i in x[1:]]), axis = 1)\n"
     ]
    }
   ],
   "source": [
    "df['remove'] = df.apply(lambda x: all([abs(i - x[0]) < 1e-8 for i in x[1:]]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c991ebdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>remove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100178</td>\n",
       "      <td>0.100614</td>\n",
       "      <td>0.100178</td>\n",
       "      <td>0.100178</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.094952</td>\n",
       "      <td>0.094952</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.087983</td>\n",
       "      <td>0.087983</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.090160</td>\n",
       "      <td>0.090596</td>\n",
       "      <td>0.090160</td>\n",
       "      <td>0.090160</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.093210</td>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.092774</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close  remove\n",
       "0  0.100178  0.100614  0.100178  0.100178   False\n",
       "1  0.095388  0.095388  0.094952  0.094952   False\n",
       "2  0.088418  0.088418  0.087983  0.087983   False\n",
       "3  0.090160  0.090596  0.090160  0.090160   False\n",
       "4  0.092774  0.093210  0.092774  0.092774   False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7c92b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100178</td>\n",
       "      <td>0.100614</td>\n",
       "      <td>0.100178</td>\n",
       "      <td>0.100178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.094952</td>\n",
       "      <td>0.094952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.087983</td>\n",
       "      <td>0.087983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.090160</td>\n",
       "      <td>0.090596</td>\n",
       "      <td>0.090160</td>\n",
       "      <td>0.090160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.093210</td>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.092774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close\n",
       "0  0.100178  0.100614  0.100178  0.100178\n",
       "1  0.095388  0.095388  0.094952  0.094952\n",
       "2  0.088418  0.088418  0.087983  0.087983\n",
       "3  0.090160  0.090596  0.090160  0.090160\n",
       "4  0.092774  0.093210  0.092774  0.092774"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.query(\"remove == False\").reset_index(drop=True)\n",
    "df.drop(['remove'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61711f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100178</td>\n",
       "      <td>0.100614</td>\n",
       "      <td>0.100178</td>\n",
       "      <td>0.100178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.094952</td>\n",
       "      <td>0.094952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.087983</td>\n",
       "      <td>0.087983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.090160</td>\n",
       "      <td>0.090596</td>\n",
       "      <td>0.090160</td>\n",
       "      <td>0.090160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.093210</td>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.092774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10450</th>\n",
       "      <td>141.350006</td>\n",
       "      <td>144.119995</td>\n",
       "      <td>141.080002</td>\n",
       "      <td>142.919998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10451</th>\n",
       "      <td>143.289993</td>\n",
       "      <td>146.550003</td>\n",
       "      <td>143.279999</td>\n",
       "      <td>146.350006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10452</th>\n",
       "      <td>145.259995</td>\n",
       "      <td>147.550003</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>147.039993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10453</th>\n",
       "      <td>145.669998</td>\n",
       "      <td>146.639999</td>\n",
       "      <td>143.779999</td>\n",
       "      <td>144.869995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10454</th>\n",
       "      <td>145.759995</td>\n",
       "      <td>148.449997</td>\n",
       "      <td>145.050003</td>\n",
       "      <td>145.860001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10455 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open        High         Low       Close\n",
       "0        0.100178    0.100614    0.100178    0.100178\n",
       "1        0.095388    0.095388    0.094952    0.094952\n",
       "2        0.088418    0.088418    0.087983    0.087983\n",
       "3        0.090160    0.090596    0.090160    0.090160\n",
       "4        0.092774    0.093210    0.092774    0.092774\n",
       "...           ...         ...         ...         ...\n",
       "10450  141.350006  144.119995  141.080002  142.919998\n",
       "10451  143.289993  146.550003  143.279999  146.350006\n",
       "10452  145.259995  147.550003  145.000000  147.039993\n",
       "10453  145.669998  146.639999  143.779999  144.869995\n",
       "10454  145.759995  148.449997  145.050003  145.860001\n",
       "\n",
       "[10455 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a871dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the dataset\n",
    "df['High'] = (df['High'] - df['Open']) /df['Open']\n",
    "df['Low'] = (df['Low'] - df['Open']) /df['Open']\n",
    "df['Close'] = (df['Close'] - df['Open']) /df['Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80ed3cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100178</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004566</td>\n",
       "      <td>-0.004566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004926</td>\n",
       "      <td>-0.004926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.090160</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10450</th>\n",
       "      <td>141.350006</td>\n",
       "      <td>0.019597</td>\n",
       "      <td>-0.001910</td>\n",
       "      <td>0.011107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10451</th>\n",
       "      <td>143.289993</td>\n",
       "      <td>0.022751</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.021355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10452</th>\n",
       "      <td>145.259995</td>\n",
       "      <td>0.015765</td>\n",
       "      <td>-0.001790</td>\n",
       "      <td>0.012254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10453</th>\n",
       "      <td>145.669998</td>\n",
       "      <td>0.006659</td>\n",
       "      <td>-0.012975</td>\n",
       "      <td>-0.005492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10454</th>\n",
       "      <td>145.759995</td>\n",
       "      <td>0.018455</td>\n",
       "      <td>-0.004871</td>\n",
       "      <td>0.000686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10455 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open      High       Low     Close\n",
       "0        0.100178  0.004348  0.000000  0.000000\n",
       "1        0.095388  0.000000 -0.004566 -0.004566\n",
       "2        0.088418  0.000000 -0.004926 -0.004926\n",
       "3        0.090160  0.004831  0.000000  0.000000\n",
       "4        0.092774  0.004694  0.000000  0.000000\n",
       "...           ...       ...       ...       ...\n",
       "10450  141.350006  0.019597 -0.001910  0.011107\n",
       "10451  143.289993  0.022751 -0.000070  0.021355\n",
       "10452  145.259995  0.015765 -0.001790  0.012254\n",
       "10453  145.669998  0.006659 -0.012975 -0.005492\n",
       "10454  145.759995  0.018455 -0.004871  0.000686\n",
       "\n",
       "[10455 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f8f09",
   "metadata": {},
   "source": [
    "### Trading Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f5e3aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AAPL_env():\n",
    "    def __init__(self, data, obs_bars = 10, test = False, commission_perc=0.1):\n",
    "        self.data = data\n",
    "        self.obs_bars = obs_bars\n",
    "        self.have_position = False\n",
    "        self.open_price = 0\n",
    "        self.test = test\n",
    "        self.commission_perc = commission_perc\n",
    "        if test == False:\n",
    "            self.curr_step = np.random.choice(self.data.High.shape[0] - self.obs_bars*10) + self.obs_bars\n",
    "        else:\n",
    "            self.curr_step = self.obs_bars\n",
    "        \n",
    "        self.state = self.data[self.curr_step - self.obs_bars : self.curr_step]\n",
    "    \n",
    "    def step(self, action):\n",
    "        reward = 0.0\n",
    "        done = False\n",
    "        \n",
    "        # Handle special \"do_nothing\" action for initialization\n",
    "        if action == \"do_nothing\":\n",
    "            self.curr_step = self.obs_bars\n",
    "            self.state = self.data.iloc[self.curr_step - self.obs_bars : self.curr_step]\n",
    "            return self._get_state(), reward, done\n",
    "        \n",
    "        # Current prices (as in your original step method)\n",
    "        relative_close = self.state[\"Close\"].iloc[-1]\n",
    "        open_price = self.state[\"Open\"].iloc[-1]\n",
    "        close = open_price * (1 + relative_close)\n",
    "        \n",
    "        # Handle actions (buy, sell, close, hold)\n",
    "        if action == \"buy\" and self.have_position == 0:\n",
    "            self.have_position = 1\n",
    "            self.open_price = close\n",
    "            reward -= self.commission_perc\n",
    "        elif action == \"sell\" and self.have_position == 0:\n",
    "            self.have_position = -1\n",
    "            self.open_price = close\n",
    "            reward -= self.commission_perc\n",
    "        elif action == \"close\" and self.have_position != 0:\n",
    "            if self.have_position == 1:\n",
    "                reward += 100.0 * (close - self.open_price) / self.open_price - self.commission_perc\n",
    "            elif self.have_position == -1:\n",
    "                reward += 100.0 * (self.open_price - close) / self.open_price - self.commission_perc\n",
    "            self.have_position = 0\n",
    "            self.open_price = 0.0\n",
    "            if not self.test:\n",
    "                done = True\n",
    "        # 'hold' or invalid actions: do nothing\n",
    "        \n",
    "        # Advance step\n",
    "        self.curr_step += 1\n",
    "        self.state = self.data.iloc[self.curr_step - self.obs_bars : self.curr_step]\n",
    "        \n",
    "        # Check if episode is done\n",
    "        if self.curr_step >= len(self.data) - 1:\n",
    "            done = True\n",
    "        \n",
    "        return self._get_state(), reward, done\n",
    "\n",
    "    def _get_state(self):\n",
    "        \"\"\"Helper method to construct the state array.\"\"\"\n",
    "        state = np.zeros((5, self.obs_bars), dtype=np.float32)\n",
    "        state[0] = self.state[\"High\"].to_list()\n",
    "        state[1] = self.state[\"Low\"].to_list()\n",
    "        state[2] = self.state[\"Close\"].to_list()\n",
    "        state[3] = [self.have_position] * self.obs_bars\n",
    "        if self.have_position != 0:\n",
    "            relative_close = self.state[\"Close\"].iloc[-1]\n",
    "            open_price = self.state[\"Open\"].iloc[-1]\n",
    "            close = open_price * (1 + relative_close)\n",
    "            if self.have_position == 1:\n",
    "                state[4] = [(close - self.open_price) / self.open_price] * self.obs_bars\n",
    "            elif self.have_position == -1:\n",
    "                state[4] = [(self.open_price - close) / self.open_price] * self.obs_bars\n",
    "        else:\n",
    "            state[4] = [0.0] * self.obs_bars\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1064de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = {\n",
    "    0: \"do_nothing\",\n",
    "    1: \"buy\",\n",
    "    2: \"close\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2cfaa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL = AAPL_env(data=df, test=False, obs_bars=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f48fa151",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, reward, done = AAPL.step(\"do_nothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eed2536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4db48b",
   "metadata": {},
   "source": [
    "### DL Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c6fbdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingConv1DQNet(nn.Module):\n",
    "    def __init__(self, input_depth_length, obs_bars, output_shape):\n",
    "        super(DuelingConv1DQNet, self).__init__()\n",
    "        \n",
    "        # Convolutional layers for price data (High, Low, Close)\n",
    "        self.price_conv = nn.Sequential(\n",
    "            nn.Conv1d(3, 128, kernel_size=5, padding=2),  # in_channels=3\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 128, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # Dynamically compute the flattened size\n",
    "        self.flattened_size = 128 * obs_bars + 2\n",
    "        \n",
    "        # State value stream\n",
    "        self.state_value = nn.Sequential(\n",
    "            nn.Linear(self.flattened_size, 512),  # +2 for position and profit/loss\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "        \n",
    "        # Advantage stream\n",
    "        self.advantage = nn.Sequential(\n",
    "            nn.Linear(self.flattened_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        price_x = x[:, :3, :]  # Extract price channels: High, Low, Close\n",
    "        info_x = x[:, 3:, -1]  # Extract position and profit/loss from last time step\n",
    "        \n",
    "        # Process price data through convolutional layers\n",
    "        price_features = self.price_conv(price_x)\n",
    "        \n",
    "        # Concatenate with position and profit/loss\n",
    "        features = torch.cat([price_features, info_x], dim=1)\n",
    "        \n",
    "        # Compute state value and advantage\n",
    "        state_val = self.state_value(features)\n",
    "        advantage = self.advantage(features)\n",
    "        \n",
    "        # Combine using Dueling DQN formula\n",
    "        q_values = state_val + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        return q_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d9385b",
   "metadata": {},
   "source": [
    "### Training the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d0f118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15b002ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_state(state, add_noise=False):\n",
    "    if add_noise:\n",
    "        state += np.random.normal(0, 0.01, size=state.shape)\n",
    "    state_tensor = torch.from_numpy(state).float().unsqueeze(0)  # (1, 5, 50)\n",
    "    return state_tensor\n",
    "\n",
    "def get_action(q_values, num_actions, epsilon):\n",
    "    if np.random.random() < epsilon:\n",
    "        # Exploration: choose a random action\n",
    "        return np.random.randint(0, num_actions)\n",
    "    else:\n",
    "        # Exploitation: choose the action with the highest Q-value\n",
    "        return q_values.argmax().item()\n",
    "\n",
    "def get_batch_for_nsteps_dqn(replay, batch_size, nsteps, device, gamma=0.99):\n",
    "    if len(replay) < batch_size + nsteps:\n",
    "        raise ValueError(\"Not enough experiences in replay buffer\")\n",
    "\n",
    "    max_idx = len(replay) - nsteps\n",
    "    indices = np.random.randint(0, max_idx, size=batch_size)\n",
    "    \n",
    "    state1_batch = []\n",
    "    action1_batch = []\n",
    "    nsteps_next_state_batch = []\n",
    "    nsteps_reward_batch = []\n",
    "    nsteps_done_batch = []\n",
    "    \n",
    "    for idx in indices:\n",
    "        state, action, reward, next_state, done = replay[idx]\n",
    "        state = state.squeeze(0)\n",
    "        state1_batch.append(state.cpu().numpy())\n",
    "        \n",
    "        action1_batch.append(action)\n",
    "        \n",
    "        nstep_reward = reward\n",
    "        nstep_done = done\n",
    "        nstep_next_state = next_state\n",
    "        \n",
    "        for t in range(1, nsteps):\n",
    "            if nstep_done:\n",
    "                break\n",
    "            next_transition = replay[idx + t]\n",
    "            reward_t = next_transition[2]\n",
    "            nstep_done = next_transition[4]\n",
    "            nstep_next_state = next_transition[3]\n",
    "            nstep_reward += (gamma ** t) * reward_t\n",
    "        \n",
    "        nstep_next_state = nstep_next_state.squeeze(0)\n",
    "        nsteps_next_state_batch.append(nstep_next_state.cpu().numpy())\n",
    "        nsteps_reward_batch.append(nstep_reward)\n",
    "        nsteps_done_batch.append(nstep_done)\n",
    "    \n",
    "    # print(\"action1_batch before tensor:\", action1_batch)  # Debug\n",
    "    state1_batch = torch.tensor(np.array(state1_batch), dtype=torch.float32).to(device)\n",
    "    action1_batch = torch.tensor(action1_batch, dtype=torch.long).to(device)\n",
    "    # print(\"action1_batch after tensor:\", action1_batch.shape)  # Debug\n",
    "    nsteps_next_state_batch = torch.tensor(np.array(nsteps_next_state_batch), dtype=torch.float32).to(device)\n",
    "    nsteps_reward_batch = torch.tensor(nsteps_reward_batch, dtype=torch.float32).to(device)\n",
    "    nsteps_done_batch = torch.tensor(nsteps_done_batch, dtype=torch.float32).to(device)\n",
    "    \n",
    "    return state1_batch, action1_batch, nsteps_next_state_batch, nsteps_reward_batch, nsteps_done_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "29d64369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Initialization\n",
    "memory_size = 100000\n",
    "batch_size = 64\n",
    "replay = deque(maxlen=memory_size)\n",
    "gamma = 0.99\n",
    "lr = 0.0001\n",
    "sync_freq = 1000\n",
    "output_shape = len(actions)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a92b3998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Agent_NN = DuelingConv1DQNet(input_depth_length=5, obs_bars=50, output_shape=3)\n",
    "target_NN = DuelingConv1DQNet(input_depth_length=5, obs_bars=50, output_shape=3)\n",
    "target_NN.load_state_dict(Agent_NN.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f58a789c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DuelingConv1DQNet(\n",
       "  (price_conv): Sequential(\n",
       "    (0): Conv1d(3, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (state_value): Sequential(\n",
       "    (0): Linear(in_features=6402, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (advantage): Sequential(\n",
       "    (0): Linear(in_features=6402, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize parameters\n",
    "optimizer = torch.optim.RMSprop(Agent_NN.parameters(), lr=lr)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "all_rewards_list = []\n",
    "Q_losses = []\n",
    "obs_bars = 50\n",
    "epsilon = 1.0\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "k = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move networks to device\n",
    "Agent_NN.to(device)\n",
    "target_NN.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ff36eeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current step: 66\n",
      "Mean reward: 2.0382814687736204\n",
      "Loss: 6.4643144607543945\n",
      "Current step: 67\n",
      "Mean reward: 2.0382814687736204\n",
      "Loss: 117.43931579589844\n",
      "Current step: 68\n",
      "Mean reward: 2.169058431600299\n",
      "Loss: 8.930057525634766\n",
      "Current step: 69\n",
      "Mean reward: 2.169058431600299\n",
      "Loss: 4.177950382232666\n",
      "Current step: 70\n",
      "Mean reward: 2.169058431600299\n",
      "Loss: 4.130468845367432\n",
      "Current step: 71\n",
      "Mean reward: 2.169058431600299\n",
      "Loss: 4.862236022949219\n",
      "Current step: 72\n",
      "Mean reward: 2.7215774904670833\n",
      "Loss: 3.132418632507324\n",
      "Current step: 73\n",
      "Mean reward: 2.7215774904670833\n",
      "Loss: 5.896778583526611\n",
      "Current step: 74\n",
      "Mean reward: 2.7215774904670833\n",
      "Loss: 2.8508214950561523\n",
      "Current step: 75\n",
      "Mean reward: 2.7215774904670833\n",
      "Loss: 4.260993480682373\n",
      "Current step: 76\n",
      "Mean reward: 2.7215774904670833\n",
      "Loss: 6.050257682800293\n",
      "Current step: 77\n",
      "Mean reward: 2.4988575331362757\n",
      "Loss: 5.119801044464111\n",
      "Current step: 78\n",
      "Mean reward: 2.4988575331362757\n",
      "Loss: 5.545325756072998\n",
      "Current step: 79\n",
      "Mean reward: 2.8002336059192907\n",
      "Loss: 4.644546985626221\n",
      "Current step: 80\n",
      "Mean reward: 2.8002336059192907\n",
      "Loss: 3.9209794998168945\n",
      "Current step: 81\n",
      "Mean reward: 2.8002336059192907\n",
      "Loss: 6.134284973144531\n",
      "Current step: 82\n",
      "Mean reward: 2.8002336059192907\n",
      "Loss: 3.6158440113067627\n",
      "Current step: 83\n",
      "Mean reward: 3.460148974645615\n",
      "Loss: 4.540185451507568\n",
      "Current step: 84\n",
      "Mean reward: 3.460148974645615\n",
      "Loss: 6.417847156524658\n",
      "Current step: 85\n",
      "Mean reward: 3.460148974645615\n",
      "Loss: 4.5391340255737305\n",
      "Current step: 86\n",
      "Mean reward: 3.460148974645615\n",
      "Loss: 6.851020812988281\n",
      "Current step: 87\n",
      "Mean reward: 3.460148974645615\n",
      "Loss: 5.295433044433594\n",
      "Current step: 88\n",
      "Mean reward: 3.460148974645615\n",
      "Loss: 7.416409015655518\n",
      "Current step: 89\n",
      "Mean reward: 3.460148974645615\n",
      "Loss: 5.832961082458496\n",
      "Current step: 90\n",
      "Mean reward: 3.460148974645615\n",
      "Loss: 5.739722728729248\n",
      "Current step: 91\n",
      "Mean reward: 3.552358599097013\n",
      "Loss: 4.837391376495361\n",
      "Current step: 92\n",
      "Mean reward: 3.552358599097013\n",
      "Loss: 8.062056541442871\n",
      "Current step: 93\n",
      "Mean reward: 3.552358599097013\n",
      "Loss: 4.8798933029174805\n",
      "Current step: 94\n",
      "Mean reward: 3.552358599097013\n",
      "Loss: 7.036468982696533\n",
      "Current step: 95\n",
      "Mean reward: 3.552358599097013\n",
      "Loss: 4.309785842895508\n",
      "Current step: 96\n",
      "Mean reward: 3.552358599097013\n",
      "Loss: 3.6247992515563965\n",
      "Current step: 97\n",
      "Mean reward: 3.552358599097013\n",
      "Loss: 2.443080186843872\n",
      "Current step: 98\n",
      "Mean reward: 3.552358599097013\n",
      "Loss: 4.4545135498046875\n",
      "Current step: 99\n",
      "Mean reward: 4.074143585781313\n",
      "Loss: 7.843680381774902\n",
      "Current step: 100\n",
      "Mean reward: 4.074143585781313\n",
      "Loss: 6.33851432800293\n",
      "Current step: 101\n",
      "Mean reward: 4.201720262078259\n",
      "Loss: 9.958539009094238\n",
      "Current step: 102\n",
      "Mean reward: 4.201720262078259\n",
      "Loss: 5.729351997375488\n",
      "Current step: 103\n",
      "Mean reward: 4.201720262078259\n",
      "Loss: 4.639287948608398\n",
      "Current step: 104\n",
      "Mean reward: 4.201720262078259\n",
      "Loss: 5.446786880493164\n",
      "Current step: 105\n",
      "Mean reward: 4.201720262078259\n",
      "Loss: 5.239138126373291\n",
      "Current step: 106\n",
      "Mean reward: 4.201720262078259\n",
      "Loss: 8.606003761291504\n",
      "Current step: 107\n",
      "Mean reward: 3.512404121733371\n",
      "Loss: 7.046531677246094\n",
      "Current step: 108\n",
      "Mean reward: 3.512404121733371\n",
      "Loss: 5.76595401763916\n",
      "Current step: 109\n",
      "Mean reward: 3.512404121733371\n",
      "Loss: 7.871461391448975\n",
      "Current step: 110\n",
      "Mean reward: 3.512404121733371\n",
      "Loss: 8.326591491699219\n",
      "Current step: 111\n",
      "Mean reward: 3.512404121733371\n",
      "Loss: 6.262088775634766\n",
      "Current step: 112\n",
      "Mean reward: 3.512404121733371\n",
      "Loss: 6.344645023345947\n",
      "Current step: 113\n",
      "Mean reward: 3.657013359777765\n",
      "Loss: 6.188024044036865\n",
      "Current step: 114\n",
      "Mean reward: 3.657013359777765\n",
      "Loss: 7.070491790771484\n",
      "Current step: 115\n",
      "Mean reward: 3.657013359777765\n",
      "Loss: 5.411035537719727\n",
      "Current step: 116\n",
      "Mean reward: 3.786400572764854\n",
      "Loss: 7.183895111083984\n",
      "Current step: 117\n",
      "Mean reward: 3.786400572764854\n",
      "Loss: 11.647107124328613\n",
      "Current step: 118\n",
      "Mean reward: 3.786400572764854\n",
      "Loss: 6.711992263793945\n",
      "Current step: 119\n",
      "Mean reward: 3.786400572764854\n",
      "Loss: 8.389313697814941\n",
      "Current step: 120\n",
      "Mean reward: 4.166037214094687\n",
      "Loss: 8.624563217163086\n",
      "Current step: 121\n",
      "Mean reward: 4.166037214094687\n",
      "Loss: 6.824352264404297\n",
      "Current step: 122\n",
      "Mean reward: 4.166037214094687\n",
      "Loss: 9.715766906738281\n",
      "Current step: 123\n",
      "Mean reward: 4.166037214094687\n",
      "Loss: 9.162659645080566\n",
      "Current step: 124\n",
      "Mean reward: 4.166037214094687\n",
      "Loss: 10.13880729675293\n",
      "Current step: 125\n",
      "Mean reward: 4.334047300102947\n",
      "Loss: 7.702620506286621\n",
      "Current step: 126\n",
      "Mean reward: 4.334047300102947\n",
      "Loss: 5.306947231292725\n",
      "Current step: 127\n",
      "Mean reward: 4.334047300102947\n",
      "Loss: 5.656422138214111\n",
      "Current step: 128\n",
      "Mean reward: 4.334047300102947\n",
      "Loss: 7.521345138549805\n",
      "Current step: 129\n",
      "Mean reward: 4.334047300102947\n",
      "Loss: 8.813538551330566\n",
      "Current step: 130\n",
      "Mean reward: 4.334047300102947\n",
      "Loss: 9.296822547912598\n",
      "Current step: 131\n",
      "Mean reward: 4.238851576914148\n",
      "Loss: 7.275844573974609\n",
      "Current step: 132\n",
      "Mean reward: 4.238851576914148\n",
      "Loss: 9.334407806396484\n",
      "Current step: 133\n",
      "Mean reward: 4.238851576914148\n",
      "Loss: 8.102577209472656\n",
      "Current step: 134\n",
      "Mean reward: 4.238851576914148\n",
      "Loss: 7.047337532043457\n",
      "Current step: 135\n",
      "Mean reward: 4.238851576914148\n",
      "Loss: 5.383207321166992\n",
      "Current step: 136\n",
      "Mean reward: 4.320439352114945\n",
      "Loss: 7.761611461639404\n",
      "Current step: 137\n",
      "Mean reward: 4.320439352114945\n",
      "Loss: 8.574552536010742\n",
      "Current step: 138\n",
      "Mean reward: 4.320439352114945\n",
      "Loss: 8.513774871826172\n",
      "Current step: 139\n",
      "Mean reward: 4.320439352114945\n",
      "Loss: 10.104822158813477\n",
      "Current step: 140\n",
      "Mean reward: 4.395228146049006\n",
      "Loss: 10.491182327270508\n",
      "Current step: 141\n",
      "Mean reward: 4.395228146049006\n",
      "Loss: 6.177123069763184\n",
      "Current step: 142\n",
      "Mean reward: 4.464033836468344\n",
      "Loss: 6.010788440704346\n",
      "Current step: 143\n",
      "Mean reward: 4.464033836468344\n",
      "Loss: 9.031099319458008\n",
      "Current step: 144\n",
      "Mean reward: 4.52754678147081\n",
      "Loss: 8.477365493774414\n",
      "Current step: 145\n",
      "Mean reward: 4.52754678147081\n",
      "Loss: 7.092311859130859\n",
      "Current step: 146\n",
      "Mean reward: 4.586355063880501\n",
      "Loss: 8.760282516479492\n",
      "Current step: 147\n",
      "Mean reward: 4.586355063880501\n",
      "Loss: 7.202239036560059\n",
      "Current step: 148\n",
      "Mean reward: 4.640962754689499\n",
      "Loss: 6.722121238708496\n",
      "Current step: 149\n",
      "Mean reward: 4.640962754689499\n",
      "Loss: 6.804980278015137\n",
      "Current step: 150\n",
      "Mean reward: 4.640962754689499\n",
      "Loss: 9.960665702819824\n",
      "Current step: 151\n",
      "Mean reward: 4.640962754689499\n",
      "Loss: 5.127503871917725\n",
      "Current step: 152\n",
      "Mean reward: 4.873313466574741\n",
      "Loss: 10.306950569152832\n",
      "Current step: 153\n",
      "Mean reward: 4.873313466574741\n",
      "Loss: 7.832968235015869\n",
      "Current step: 154\n",
      "Mean reward: 4.914715364573332\n",
      "Loss: 8.803068161010742\n",
      "Current step: 155\n",
      "Mean reward: 4.914715364573332\n",
      "Loss: 9.923406600952148\n",
      "Current step: 156\n",
      "Mean reward: 4.953446172378466\n",
      "Loss: 6.657199859619141\n",
      "Current step: 157\n",
      "Mean reward: 4.953446172378466\n",
      "Loss: 6.719916343688965\n",
      "Current step: 158\n",
      "Mean reward: 4.989756304695776\n",
      "Loss: 6.824182987213135\n",
      "Current step: 159\n",
      "Mean reward: 4.989756304695776\n",
      "Loss: 7.162890434265137\n",
      "Current step: 160\n",
      "Mean reward: 5.023865822933251\n",
      "Loss: 8.310037612915039\n",
      "Current step: 161\n",
      "Mean reward: 5.023865822933251\n",
      "Loss: 4.246360778808594\n",
      "Current step: 162\n",
      "Mean reward: 5.023865822933251\n",
      "Loss: 8.209596633911133\n",
      "Current step: 163\n",
      "Mean reward: 5.023865822933251\n",
      "Loss: 9.795759201049805\n",
      "Current step: 164\n",
      "Mean reward: 5.023865822933251\n",
      "Loss: 9.044071197509766\n",
      "Current step: 165\n",
      "Mean reward: 5.015842819816544\n",
      "Loss: 7.883447647094727\n",
      "Current step: 166\n",
      "Mean reward: 5.015842819816544\n",
      "Loss: 6.167156219482422\n",
      "Current step: 167\n",
      "Mean reward: 5.047257893722713\n",
      "Loss: 8.193805694580078\n",
      "Current step: 168\n",
      "Mean reward: 5.047257893722713\n",
      "Loss: 7.143733978271484\n",
      "Current step: 169\n",
      "Mean reward: 5.076927685745206\n",
      "Loss: 7.865194797515869\n",
      "Current step: 170\n",
      "Mean reward: 5.076927685745206\n",
      "Loss: 8.3780517578125\n",
      "Current step: 171\n",
      "Mean reward: 5.104993705225942\n",
      "Loss: 6.959202289581299\n",
      "Current step: 172\n",
      "Mean reward: 5.104993705225942\n",
      "Loss: 10.330474853515625\n",
      "Current step: 173\n",
      "Mean reward: 5.1315825657866405\n",
      "Loss: 9.926430702209473\n",
      "Current step: 174\n",
      "Mean reward: 5.1315825657866405\n",
      "Loss: 7.202863693237305\n",
      "Current step: 175\n",
      "Mean reward: 5.1568078950365335\n",
      "Loss: 8.043901443481445\n",
      "Current step: 176\n",
      "Mean reward: 5.1568078950365335\n",
      "Loss: 6.197934150695801\n",
      "Current step: 177\n",
      "Mean reward: 5.18077195782393\n",
      "Loss: 6.6818461418151855\n",
      "Current step: 178\n",
      "Mean reward: 5.18077195782393\n",
      "Loss: 7.606200218200684\n",
      "Current step: 179\n",
      "Mean reward: 5.203567041938772\n",
      "Loss: 6.717025279998779\n",
      "Current step: 180\n",
      "Mean reward: 5.203567041938772\n",
      "Loss: 9.633328437805176\n",
      "Current step: 181\n",
      "Mean reward: 5.22527664585767\n",
      "Loss: 5.083097457885742\n",
      "Current step: 182\n",
      "Mean reward: 5.22527664585767\n",
      "Loss: 7.857032775878906\n",
      "Current step: 183\n",
      "Mean reward: 5.22527664585767\n",
      "Loss: 7.640486240386963\n",
      "Current step: 184\n",
      "Mean reward: 5.22527664585767\n",
      "Loss: 7.851867198944092\n",
      "Current step: 185\n",
      "Mean reward: 5.178532401400834\n",
      "Loss: 5.693788051605225\n",
      "Current step: 186\n",
      "Mean reward: 5.178532401400834\n",
      "Loss: 9.181349754333496\n",
      "Current step: 187\n",
      "Mean reward: 5.199824174244735\n",
      "Loss: 9.106178283691406\n",
      "Current step: 188\n",
      "Mean reward: 5.199824174244735\n",
      "Loss: 9.070160865783691\n",
      "Current step: 189\n",
      "Mean reward: 5.220169646073351\n",
      "Loss: 7.756155490875244\n",
      "Current step: 190\n",
      "Mean reward: 5.220169646073351\n",
      "Loss: 7.52394437789917\n",
      "Current step: 191\n",
      "Mean reward: 5.239630532170288\n",
      "Loss: 10.602513313293457\n",
      "Current step: 192\n",
      "Mean reward: 5.239630532170288\n",
      "Loss: 6.436601161956787\n",
      "Current step: 193\n",
      "Mean reward: 5.258263295454589\n",
      "Loss: 8.881373405456543\n",
      "Current step: 194\n",
      "Mean reward: 5.258263295454589\n",
      "Loss: 6.9089860916137695\n",
      "Current step: 195\n",
      "Mean reward: 5.276119693602045\n",
      "Loss: 6.303433895111084\n",
      "Current step: 196\n",
      "Mean reward: 5.276119693602045\n",
      "Loss: 8.135930061340332\n",
      "Current step: 197\n",
      "Mean reward: 5.276119693602045\n",
      "Loss: 8.45042610168457\n",
      "Current step: 198\n",
      "Mean reward: 5.276119693602045\n",
      "Loss: 5.981423854827881\n",
      "Current step: 199\n",
      "Mean reward: 5.276119693602045\n",
      "Loss: 5.714595317840576\n",
      "Current step: 200\n",
      "Mean reward: 5.293247259172054\n",
      "Loss: 7.919617652893066\n",
      "Current step: 201\n",
      "Mean reward: 5.293247259172054\n",
      "Loss: 10.406859397888184\n",
      "Current step: 202\n",
      "Mean reward: 5.309689722119262\n",
      "Loss: 7.492401123046875\n",
      "Current step: 203\n",
      "Mean reward: 5.309689722119262\n",
      "Loss: 6.873479843139648\n",
      "Current step: 204\n",
      "Mean reward: 5.325487382597951\n",
      "Loss: 5.646425724029541\n",
      "Current step: 205\n",
      "Mean reward: 5.325487382597951\n",
      "Loss: 6.90378475189209\n",
      "Current step: 206\n",
      "Mean reward: 5.340677440750539\n",
      "Loss: 8.44288444519043\n",
      "Current step: 207\n",
      "Mean reward: 5.340677440750539\n",
      "Loss: 8.497076988220215\n",
      "Current step: 208\n",
      "Mean reward: 5.340677440750539\n",
      "Loss: 4.469263076782227\n",
      "Current step: 209\n",
      "Mean reward: 5.340677440750539\n",
      "Loss: 7.9465742111206055\n",
      "Current step: 210\n",
      "Mean reward: 5.340677440750539\n",
      "Loss: 6.726789474487305\n",
      "Current step: 211\n",
      "Mean reward: 5.340677440750539\n",
      "Loss: 6.6632771492004395\n",
      "Current step: 212\n",
      "Mean reward: 5.340677440750539\n",
      "Loss: 6.336040496826172\n",
      "Current step: 213\n",
      "Mean reward: 5.454610572045086\n",
      "Loss: 6.129514217376709\n",
      "Current step: 214\n",
      "Mean reward: 5.454610572045086\n",
      "Loss: 8.187116622924805\n",
      "Current step: 215\n",
      "Mean reward: 5.466846865276334\n",
      "Loss: 9.78821849822998\n",
      "Current step: 216\n",
      "Mean reward: 5.466846865276334\n",
      "Loss: 8.063959121704102\n",
      "Current step: 217\n",
      "Mean reward: 5.478638202390081\n",
      "Loss: 6.669875621795654\n",
      "Current step: 218\n",
      "Mean reward: 5.478638202390081\n",
      "Loss: 8.705233573913574\n",
      "Current step: 219\n",
      "Mean reward: 5.490008420321194\n",
      "Loss: 7.3324875831604\n",
      "Current step: 220\n",
      "Mean reward: 5.490008420321194\n",
      "Loss: 7.677090167999268\n",
      "Current step: 221\n",
      "Mean reward: 5.490008420321194\n",
      "Loss: 7.506782531738281\n",
      "Current step: 222\n",
      "Mean reward: 5.490008420321194\n",
      "Loss: 6.655714511871338\n",
      "Current step: 223\n",
      "Mean reward: 5.490008420321194\n",
      "Loss: 7.261938095092773\n",
      "Current step: 224\n",
      "Mean reward: 5.490008420321194\n",
      "Loss: 6.257513523101807\n",
      "Current step: 225\n",
      "Mean reward: 5.500979683237182\n",
      "Loss: 5.485177040100098\n",
      "Current step: 226\n",
      "Mean reward: 5.500979683237182\n",
      "Loss: 6.35222864151001\n",
      "Current step: 227\n",
      "Mean reward: 5.500979683237182\n",
      "Loss: 6.43814754486084\n",
      "Current step: 228\n",
      "Mean reward: 5.500979683237182\n",
      "Loss: 9.598918914794922\n",
      "Current step: 229\n",
      "Mean reward: 5.4880504424393886\n",
      "Loss: 6.675954341888428\n",
      "Current step: 230\n",
      "Mean reward: 5.4880504424393886\n",
      "Loss: 5.647987365722656\n",
      "Current step: 231\n",
      "Mean reward: 5.498682984203677\n",
      "Loss: 5.468875408172607\n",
      "Current step: 232\n",
      "Mean reward: 5.498682984203677\n",
      "Loss: 7.480952739715576\n",
      "Current step: 233\n",
      "Mean reward: 5.498682984203677\n",
      "Loss: 6.7929768562316895\n",
      "Current step: 234\n",
      "Mean reward: 5.498682984203677\n",
      "Loss: 9.91827392578125\n",
      "Current step: 235\n",
      "Mean reward: 5.508961107909157\n",
      "Loss: 7.644852161407471\n",
      "Current step: 236\n",
      "Mean reward: 5.508961107909157\n",
      "Loss: 6.157427787780762\n",
      "Current step: 237\n",
      "Mean reward: 5.508961107909157\n",
      "Loss: 7.922702312469482\n",
      "Current step: 238\n",
      "Mean reward: 5.508961107909157\n",
      "Loss: 8.813268661499023\n",
      "Current step: 239\n",
      "Mean reward: 5.508961107909157\n",
      "Loss: 7.586390495300293\n",
      "Current step: 240\n",
      "Mean reward: 5.508961107909157\n",
      "Loss: 10.438643455505371\n",
      "Current step: 241\n",
      "Mean reward: 5.508961107909157\n",
      "Loss: 7.169992923736572\n",
      "Current step: 242\n",
      "Mean reward: 5.471359682110871\n",
      "Loss: 7.102386951446533\n",
      "Current step: 243\n",
      "Mean reward: 5.471359682110871\n",
      "Loss: 6.870275497436523\n",
      "Current step: 244\n",
      "Mean reward: 5.471359682110871\n",
      "Loss: 4.301875114440918\n",
      "Current step: 245\n",
      "Mean reward: 5.4817469518596065\n",
      "Loss: 5.513232707977295\n",
      "Current step: 246\n",
      "Mean reward: 5.4817469518596065\n",
      "Loss: 10.560164451599121\n",
      "Current step: 247\n",
      "Mean reward: 5.4817469518596065\n",
      "Loss: 7.001125812530518\n",
      "Current step: 248\n",
      "Mean reward: 5.4817469518596065\n",
      "Loss: 7.09726095199585\n",
      "Current step: 249\n",
      "Mean reward: 5.4817469518596065\n",
      "Loss: 9.613316535949707\n",
      "Current step: 250\n",
      "Mean reward: 5.4817469518596065\n",
      "Loss: 5.91232442855835\n",
      "Current step: 251\n",
      "Mean reward: 5.4817469518596065\n",
      "Loss: 6.675079822540283\n",
      "Current step: 252\n",
      "Mean reward: 5.4817469518596065\n",
      "Loss: 8.545198440551758\n",
      "Current step: 253\n",
      "Mean reward: 5.533573075618009\n",
      "Loss: 7.033674240112305\n",
      "Current step: 254\n",
      "Mean reward: 5.533573075618009\n",
      "Loss: 10.44985294342041\n",
      "Current step: 255\n",
      "Mean reward: 5.542663658913547\n",
      "Loss: 5.725338935852051\n",
      "Current step: 256\n",
      "Mean reward: 5.542663658913547\n",
      "Loss: 7.708892822265625\n",
      "Current step: 257\n",
      "Mean reward: 5.542663658913547\n",
      "Loss: 6.592108249664307\n",
      "Current step: 258\n",
      "Mean reward: 5.542663658913547\n",
      "Loss: 6.204738616943359\n",
      "Current step: 259\n",
      "Mean reward: 5.530485505960495\n",
      "Loss: 4.599220275878906\n",
      "Current step: 260\n",
      "Mean reward: 5.530485505960495\n",
      "Loss: 8.557879447937012\n",
      "Current step: 261\n",
      "Mean reward: 5.539347398393404\n",
      "Loss: 7.070500373840332\n",
      "Current step: 262\n",
      "Mean reward: 5.539347398393404\n",
      "Loss: 6.988170623779297\n",
      "Current step: 263\n",
      "Mean reward: 5.547944756723838\n",
      "Loss: 7.353549003601074\n",
      "Current step: 264\n",
      "Mean reward: 5.547944756723838\n",
      "Loss: 5.2831034660339355\n",
      "Current step: 265\n",
      "Mean reward: 5.547944756723838\n",
      "Loss: 6.002773761749268\n",
      "Current step: 266\n",
      "Mean reward: 5.4634161573602515\n",
      "Loss: 5.604960918426514\n",
      "Current step: 267\n",
      "Mean reward: 5.4634161573602515\n",
      "Loss: 8.497054100036621\n",
      "Current step: 268\n",
      "Mean reward: 5.4634161573602515\n",
      "Loss: 9.80212688446045\n",
      "Current step: 269\n",
      "Mean reward: 5.4634161573602515\n",
      "Loss: 8.43427562713623\n",
      "Current step: 270\n",
      "Mean reward: 5.4634161573602515\n",
      "Loss: 8.150059700012207\n",
      "Current step: 271\n",
      "Mean reward: 5.4634161573602515\n",
      "Loss: 7.281146049499512\n",
      "Current step: 272\n",
      "Mean reward: 5.472864769667096\n",
      "Loss: 4.341055870056152\n",
      "Current step: 273\n",
      "Mean reward: 5.472864769667096\n",
      "Loss: 7.169710636138916\n",
      "Current step: 274\n",
      "Mean reward: 5.482043421622315\n",
      "Loss: 7.872192859649658\n",
      "Current step: 275\n",
      "Mean reward: 5.482043421622315\n",
      "Loss: 5.554439544677734\n",
      "Current step: 276\n",
      "Mean reward: 5.490963520001332\n",
      "Loss: 8.483052253723145\n",
      "Current step: 277\n",
      "Mean reward: 5.490963520001332\n",
      "Loss: 5.161123752593994\n",
      "Current step: 278\n",
      "Mean reward: 5.499635837869819\n",
      "Loss: 6.176311492919922\n",
      "Current step: 279\n",
      "Mean reward: 5.499635837869819\n",
      "Loss: 6.953957557678223\n",
      "Current step: 280\n",
      "Mean reward: 5.508070557988486\n",
      "Loss: 6.710110187530518\n",
      "Current step: 281\n",
      "Mean reward: 5.508070557988486\n",
      "Loss: 7.5185322761535645\n",
      "Current step: 282\n",
      "Mean reward: 5.51627731269854\n",
      "Loss: 9.172077178955078\n",
      "Current step: 283\n",
      "Mean reward: 5.51627731269854\n",
      "Loss: 7.725549697875977\n",
      "Current step: 284\n",
      "Mean reward: 5.524265220616325\n",
      "Loss: 5.453245639801025\n",
      "Current step: 285\n",
      "Mean reward: 5.524265220616325\n",
      "Loss: 8.413039207458496\n",
      "Current step: 286\n",
      "Mean reward: 5.532042920431011\n",
      "Loss: 7.384876728057861\n",
      "Current step: 287\n",
      "Mean reward: 5.532042920431011\n",
      "Loss: 7.181763172149658\n",
      "Current step: 288\n",
      "Mean reward: 5.539618602068692\n",
      "Loss: 7.040889739990234\n",
      "Current step: 289\n",
      "Mean reward: 5.539618602068692\n",
      "Loss: 7.775238990783691\n",
      "Current step: 290\n",
      "Mean reward: 5.547000035459253\n",
      "Loss: 6.748558044433594\n",
      "Current step: 291\n",
      "Mean reward: 5.547000035459253\n",
      "Loss: 6.662107944488525\n",
      "Current step: 292\n",
      "Mean reward: 5.554194597118408\n",
      "Loss: 5.894977569580078\n",
      "Current step: 293\n",
      "Mean reward: 5.554194597118408\n",
      "Loss: 6.564732551574707\n",
      "Current step: 294\n",
      "Mean reward: 5.5612092947360825\n",
      "Loss: 7.444936752319336\n",
      "Current step: 295\n",
      "Mean reward: 5.5612092947360825\n",
      "Loss: 7.616737365722656\n",
      "Current step: 296\n",
      "Mean reward: 5.568050789943445\n",
      "Loss: 7.772806167602539\n",
      "Current step: 297\n",
      "Mean reward: 5.568050789943445\n",
      "Loss: 8.64201545715332\n",
      "Current step: 298\n",
      "Mean reward: 5.568050789943445\n",
      "Loss: 5.589560508728027\n",
      "Current step: 299\n",
      "Mean reward: 5.568050789943445\n",
      "Loss: 4.779397487640381\n",
      "Current step: 300\n",
      "Mean reward: 5.568050789943445\n",
      "Loss: 12.017975807189941\n",
      "Current step: 301\n",
      "Mean reward: 5.568050789943445\n",
      "Loss: 7.9764509201049805\n",
      "Current step: 302\n",
      "Mean reward: 5.574725419414043\n",
      "Loss: 7.879756927490234\n",
      "Current step: 303\n",
      "Mean reward: 5.574725419414043\n",
      "Loss: 6.310817241668701\n",
      "Current step: 304\n",
      "Mean reward: 5.581239214439566\n",
      "Loss: 7.670388698577881\n",
      "Current step: 305\n",
      "Mean reward: 5.581239214439566\n",
      "Loss: 5.725388526916504\n",
      "Current step: 306\n",
      "Mean reward: 5.581239214439566\n",
      "Loss: 8.701984405517578\n",
      "Current step: 307\n",
      "Mean reward: 5.51241493807719\n",
      "Loss: 5.419137954711914\n",
      "Current step: 308\n",
      "Mean reward: 5.51241493807719\n",
      "Loss: 6.412774085998535\n",
      "Current step: 309\n",
      "Mean reward: 5.519508531823723\n",
      "Loss: 6.79718017578125\n",
      "Current step: 310\n",
      "Mean reward: 5.519508531823723\n",
      "Loss: 7.276882648468018\n",
      "Current step: 311\n",
      "Mean reward: 5.526437158273825\n",
      "Loss: 7.078229904174805\n",
      "Current step: 312\n",
      "Mean reward: 5.526437158273825\n",
      "Loss: 7.396997451782227\n",
      "Current step: 313\n",
      "Mean reward: 5.533206505954958\n",
      "Loss: 5.589327812194824\n",
      "Current step: 314\n",
      "Mean reward: 5.533206505954958\n",
      "Loss: 8.820162773132324\n",
      "Current step: 315\n",
      "Mean reward: 5.539822004825157\n",
      "Loss: 6.237325191497803\n",
      "Current step: 316\n",
      "Mean reward: 5.539822004825157\n",
      "Loss: 7.745910167694092\n",
      "Current step: 317\n",
      "Mean reward: 5.546288840799397\n",
      "Loss: 9.63380241394043\n",
      "Current step: 318\n",
      "Mean reward: 5.546288840799397\n",
      "Loss: 6.380374908447266\n",
      "Current step: 319\n",
      "Mean reward: 5.5526119693075415\n",
      "Loss: 7.553216934204102\n",
      "Current step: 320\n",
      "Mean reward: 5.5526119693075415\n",
      "Loss: 7.75628662109375\n",
      "Current step: 321\n",
      "Mean reward: 5.558796127958365\n",
      "Loss: 6.131833076477051\n",
      "Current step: 322\n",
      "Mean reward: 5.558796127958365\n",
      "Loss: 6.6293792724609375\n",
      "Current step: 323\n",
      "Mean reward: 5.564845848377649\n",
      "Loss: 7.095776557922363\n",
      "Current step: 324\n",
      "Mean reward: 5.564845848377649\n",
      "Loss: 6.686673164367676\n",
      "Current step: 325\n",
      "Mean reward: 5.570765467282539\n",
      "Loss: 6.729283809661865\n",
      "Current step: 326\n",
      "Mean reward: 5.570765467282539\n",
      "Loss: 4.593143939971924\n",
      "Current step: 327\n",
      "Mean reward: 5.570765467282539\n",
      "Loss: 8.187472343444824\n",
      "Current step: 328\n",
      "Mean reward: 5.570765467282539\n",
      "Loss: 7.09356689453125\n",
      "Current step: 329\n",
      "Mean reward: 5.570765467282539\n",
      "Loss: 5.556173801422119\n",
      "Current step: 330\n",
      "Mean reward: 5.570765467282539\n",
      "Loss: 6.197900772094727\n",
      "Current step: 331\n",
      "Mean reward: 5.621359341790072\n",
      "Loss: 5.663279056549072\n",
      "Current step: 332\n",
      "Mean reward: 5.621359341790072\n",
      "Loss: 5.555112361907959\n",
      "Current step: 333\n",
      "Mean reward: 5.626559458261044\n",
      "Loss: 7.402379035949707\n",
      "Current step: 334\n",
      "Mean reward: 5.626559458261044\n",
      "Loss: 4.6816086769104\n",
      "Current step: 335\n",
      "Mean reward: 5.631651238972204\n",
      "Loss: 5.658947944641113\n",
      "Current step: 336\n",
      "Mean reward: 5.631651238972204\n",
      "Loss: 6.564831256866455\n",
      "Current step: 337\n",
      "Mean reward: 5.636638034514062\n",
      "Loss: 8.043837547302246\n",
      "Current step: 338\n",
      "Mean reward: 5.636638034514062\n",
      "Loss: 7.009370803833008\n",
      "Current step: 339\n",
      "Mean reward: 5.641523058718331\n",
      "Loss: 6.130364418029785\n",
      "Current step: 340\n",
      "Mean reward: 5.641523058718331\n",
      "Loss: 8.9817476272583\n",
      "Current step: 341\n",
      "Mean reward: 5.646309395564938\n",
      "Loss: 6.165857315063477\n",
      "Current step: 342\n",
      "Mean reward: 5.646309395564938\n",
      "Loss: 5.395167350769043\n",
      "Current step: 343\n",
      "Mean reward: 5.651000005674613\n",
      "Loss: 6.483673095703125\n",
      "Current step: 344\n",
      "Mean reward: 5.651000005674613\n",
      "Loss: 5.633236408233643\n",
      "Current step: 345\n",
      "Mean reward: 5.651000005674613\n",
      "Loss: 8.561697959899902\n",
      "Current step: 346\n",
      "Mean reward: 5.651000005674613\n",
      "Loss: 5.414200782775879\n",
      "Current step: 347\n",
      "Mean reward: 5.655597732415779\n",
      "Loss: 6.925642490386963\n",
      "Current step: 348\n",
      "Mean reward: 5.655597732415779\n",
      "Loss: 6.4436774253845215\n",
      "Current step: 349\n",
      "Mean reward: 5.660105307652216\n",
      "Loss: 5.72873592376709\n",
      "Current step: 350\n",
      "Mean reward: 5.660105307652216\n",
      "Loss: 4.711758613586426\n",
      "Current step: 351\n",
      "Mean reward: 5.664525357155908\n",
      "Loss: 4.52930212020874\n",
      "Current step: 352\n",
      "Mean reward: 5.664525357155908\n",
      "Loss: 5.226312160491943\n",
      "Current step: 353\n",
      "Mean reward: 5.66886040570761\n",
      "Loss: 8.168110847473145\n",
      "Current step: 354\n",
      "Mean reward: 5.66886040570761\n",
      "Loss: 7.5888872146606445\n",
      "Current step: 355\n",
      "Mean reward: 5.673112881905942\n",
      "Loss: 5.379291534423828\n",
      "Current step: 356\n",
      "Mean reward: 5.673112881905942\n",
      "Loss: 7.085249900817871\n",
      "Current step: 357\n",
      "Mean reward: 5.677285122704305\n",
      "Loss: 6.389156341552734\n",
      "Current step: 358\n",
      "Mean reward: 5.677285122704305\n",
      "Loss: 5.317208766937256\n",
      "Current step: 359\n",
      "Mean reward: 5.681379377693352\n",
      "Loss: 5.324914932250977\n",
      "Current step: 360\n",
      "Mean reward: 5.681379377693352\n",
      "Loss: 4.438266754150391\n",
      "Current step: 361\n",
      "Mean reward: 5.681379377693352\n",
      "Loss: 7.0563154220581055\n",
      "Current step: 362\n",
      "Mean reward: 5.681379377693352\n",
      "Loss: 5.815395832061768\n",
      "Current step: 363\n",
      "Mean reward: 5.658545069883355\n",
      "Loss: 8.864076614379883\n",
      "Current step: 364\n",
      "Mean reward: 5.658545069883355\n",
      "Loss: 7.643215179443359\n",
      "Current step: 365\n",
      "Mean reward: 5.662736128017751\n",
      "Loss: 5.580257415771484\n",
      "Current step: 366\n",
      "Mean reward: 5.662736128017751\n",
      "Loss: 7.857619285583496\n",
      "Current step: 367\n",
      "Mean reward: 5.666850985095157\n",
      "Loss: 6.955212593078613\n",
      "Current step: 368\n",
      "Mean reward: 5.666850985095157\n",
      "Loss: 6.101217269897461\n",
      "Current step: 369\n",
      "Mean reward: 5.6708917006036\n",
      "Loss: 6.267645835876465\n",
      "Current step: 370\n",
      "Mean reward: 5.6708917006036\n",
      "Loss: 6.527701377868652\n",
      "Current step: 371\n",
      "Mean reward: 5.674860260477968\n",
      "Loss: 7.057833671569824\n",
      "Current step: 372\n",
      "Mean reward: 5.674860260477968\n",
      "Loss: 6.408608436584473\n",
      "Current step: 373\n",
      "Mean reward: 5.678758580354556\n",
      "Loss: 6.7946248054504395\n",
      "Current step: 374\n",
      "Mean reward: 5.678758580354556\n",
      "Loss: 5.024623870849609\n",
      "Current step: 375\n",
      "Mean reward: 5.682588508654361\n",
      "Loss: 4.445793628692627\n",
      "Current step: 376\n",
      "Mean reward: 5.682588508654361\n",
      "Loss: 7.087883472442627\n",
      "Current step: 377\n",
      "Mean reward: 5.686351829505474\n",
      "Loss: 7.9891862869262695\n",
      "Current step: 378\n",
      "Mean reward: 5.686351829505474\n",
      "Loss: 5.886101722717285\n",
      "Current step: 379\n",
      "Mean reward: 5.690050265514327\n",
      "Loss: 7.8582682609558105\n",
      "Current step: 380\n",
      "Mean reward: 5.690050265514327\n",
      "Loss: 7.142961502075195\n",
      "Current step: 381\n",
      "Mean reward: 5.693685480394824\n",
      "Loss: 6.742446422576904\n",
      "Current step: 382\n",
      "Mean reward: 5.693685480394824\n",
      "Loss: 7.4062700271606445\n",
      "Current step: 383\n",
      "Mean reward: 5.697259081463787\n",
      "Loss: 5.724726676940918\n",
      "Current step: 384\n",
      "Mean reward: 5.697259081463787\n",
      "Loss: 7.488508701324463\n",
      "Current step: 385\n",
      "Mean reward: 5.700772622010581\n",
      "Loss: 6.0591959953308105\n",
      "Current step: 386\n",
      "Mean reward: 5.700772622010581\n",
      "Loss: 3.852391481399536\n",
      "Current step: 387\n",
      "Mean reward: 5.704227603548267\n",
      "Loss: 5.647034168243408\n",
      "Current step: 388\n",
      "Mean reward: 5.704227603548267\n",
      "Loss: 5.205375671386719\n",
      "Current step: 389\n",
      "Mean reward: 5.707625477953095\n",
      "Loss: 7.1923418045043945\n",
      "Current step: 390\n",
      "Mean reward: 5.707625477953095\n",
      "Loss: 5.85555362701416\n",
      "Current step: 391\n",
      "Mean reward: 5.710967649498827\n",
      "Loss: 7.3116984367370605\n",
      "Current step: 392\n",
      "Mean reward: 5.710967649498827\n",
      "Loss: 5.456444263458252\n",
      "Current step: 393\n",
      "Mean reward: 5.714255476791783\n",
      "Loss: 7.1941819190979\n",
      "Current step: 394\n",
      "Mean reward: 5.714255476791783\n",
      "Loss: 4.867737293243408\n",
      "Current step: 395\n",
      "Mean reward: 5.717490274612271\n",
      "Loss: 4.48579216003418\n",
      "Current step: 396\n",
      "Mean reward: 5.717490274612271\n",
      "Loss: 6.555570602416992\n",
      "Current step: 397\n",
      "Mean reward: 5.717490274612271\n",
      "Loss: 5.430532455444336\n",
      "Current step: 398\n",
      "Mean reward: 5.717490274612271\n",
      "Loss: 4.931023597717285\n",
      "Current step: 399\n",
      "Mean reward: 5.6974725454890836\n",
      "Loss: 6.515081405639648\n",
      "Current step: 400\n",
      "Mean reward: 5.6974725454890836\n",
      "Loss: 6.24149751663208\n",
      "Current step: 401\n",
      "Mean reward: 5.700789195179903\n",
      "Loss: 6.286666393280029\n",
      "Current step: 402\n",
      "Mean reward: 5.700789195179903\n",
      "Loss: 4.910282611846924\n",
      "Current step: 403\n",
      "Mean reward: 5.704053614166931\n",
      "Loss: 5.228080749511719\n",
      "Current step: 404\n",
      "Mean reward: 5.704053614166931\n",
      "Loss: 6.2728705406188965\n",
      "Current step: 405\n",
      "Mean reward: 5.707267026607289\n",
      "Loss: 5.277015686035156\n",
      "Current step: 406\n",
      "Mean reward: 5.707267026607289\n",
      "Loss: 6.375942230224609\n",
      "Current step: 407\n",
      "Mean reward: 5.71043061869973\n",
      "Loss: 7.380407810211182\n",
      "Current step: 408\n",
      "Mean reward: 5.71043061869973\n",
      "Loss: 7.88485050201416\n",
      "Current step: 409\n",
      "Mean reward: 5.713545540144598\n",
      "Loss: 5.277742385864258\n",
      "Current step: 410\n",
      "Mean reward: 5.713545540144598\n",
      "Loss: 5.5071940422058105\n",
      "Current step: 411\n",
      "Mean reward: 5.716612905536873\n",
      "Loss: 4.924747943878174\n",
      "Current step: 412\n",
      "Mean reward: 5.716612905536873\n",
      "Loss: 4.860743999481201\n",
      "Current step: 413\n",
      "Mean reward: 5.71963379569593\n",
      "Loss: 5.5902323722839355\n",
      "Current step: 414\n",
      "Mean reward: 5.71963379569593\n",
      "Loss: 4.38383674621582\n",
      "Current step: 415\n",
      "Mean reward: 5.722609258935302\n",
      "Loss: 6.772415637969971\n",
      "Current step: 416\n",
      "Mean reward: 5.722609258935302\n",
      "Loss: 4.0824456214904785\n",
      "Current step: 417\n",
      "Mean reward: 5.725540312275579\n",
      "Loss: 5.686984539031982\n",
      "Current step: 418\n",
      "Mean reward: 5.725540312275579\n",
      "Loss: 5.7646589279174805\n",
      "Current step: 419\n",
      "Mean reward: 5.728427942603409\n",
      "Loss: 4.976888179779053\n",
      "Current step: 420\n",
      "Mean reward: 5.728427942603409\n",
      "Loss: 8.768120765686035\n",
      "Current step: 421\n",
      "Mean reward: 5.728427942603409\n",
      "Loss: 5.9979634284973145\n",
      "Current step: 422\n",
      "Mean reward: 5.731273107779356\n",
      "Loss: 6.598973751068115\n",
      "Current step: 423\n",
      "Mean reward: 5.731273107779356\n",
      "Loss: 6.532992362976074\n",
      "Current step: 424\n",
      "Mean reward: 5.731273107779356\n",
      "Loss: 4.994577884674072\n",
      "Current step: 425\n",
      "Mean reward: 5.734076737697262\n",
      "Loss: 6.379550457000732\n",
      "Current step: 426\n",
      "Mean reward: 5.734076737697262\n",
      "Loss: 6.356405258178711\n",
      "Current step: 427\n",
      "Mean reward: 5.736839735297517\n",
      "Loss: 4.634097099304199\n",
      "Current step: 428\n",
      "Mean reward: 5.736839735297517\n",
      "Loss: 6.036657333374023\n",
      "Current step: 429\n",
      "Mean reward: 5.736839735297517\n",
      "Loss: 5.744749069213867\n",
      "Current step: 430\n",
      "Mean reward: 5.736839735297517\n",
      "Loss: 5.865513324737549\n",
      "Current step: 431\n",
      "Mean reward: 5.736839735297517\n",
      "Loss: 7.060708999633789\n",
      "Current step: 432\n",
      "Mean reward: 5.736839735297517\n",
      "Loss: 5.0790252685546875\n",
      "Current step: 433\n",
      "Mean reward: 5.777431776046179\n",
      "Loss: 5.982395648956299\n",
      "Current step: 434\n",
      "Mean reward: 5.777431776046179\n",
      "Loss: 6.232694625854492\n",
      "Current step: 435\n",
      "Mean reward: 5.779845623406795\n",
      "Loss: 8.551356315612793\n",
      "Current step: 436\n",
      "Mean reward: 5.779845623406795\n",
      "Loss: 5.63553524017334\n",
      "Current step: 437\n",
      "Mean reward: 5.782225231797757\n",
      "Loss: 6.865729331970215\n",
      "Current step: 438\n",
      "Mean reward: 5.782225231797757\n",
      "Loss: 5.678388595581055\n",
      "Current step: 439\n",
      "Mean reward: 5.78457132457758\n",
      "Loss: 5.1827826499938965\n",
      "Current step: 440\n",
      "Mean reward: 5.78457132457758\n",
      "Loss: 8.319009780883789\n",
      "Current step: 441\n",
      "Mean reward: 5.78688460487097\n",
      "Loss: 3.9362401962280273\n",
      "Current step: 442\n",
      "Mean reward: 5.78688460487097\n",
      "Loss: 5.924528121948242\n",
      "Current step: 443\n",
      "Mean reward: 5.789165756271397\n",
      "Loss: 6.613977432250977\n",
      "Current step: 444\n",
      "Mean reward: 5.789165756271397\n",
      "Loss: 6.52957820892334\n",
      "Current step: 445\n",
      "Mean reward: 5.791415443514577\n",
      "Loss: 6.458338737487793\n",
      "Current step: 446\n",
      "Mean reward: 5.791415443514577\n",
      "Loss: 5.702077388763428\n",
      "Current step: 447\n",
      "Mean reward: 5.793634313124289\n",
      "Loss: 7.2312469482421875\n",
      "Current step: 448\n",
      "Mean reward: 5.793634313124289\n",
      "Loss: 7.608349323272705\n",
      "Current step: 449\n",
      "Mean reward: 5.795822994031827\n",
      "Loss: 7.369046211242676\n",
      "Current step: 450\n",
      "Mean reward: 5.795822994031827\n",
      "Loss: 6.533473014831543\n",
      "Current step: 451\n",
      "Mean reward: 5.797982098170345\n",
      "Loss: 5.271029949188232\n",
      "Current step: 452\n",
      "Mean reward: 5.797982098170345\n",
      "Loss: 6.107796669006348\n",
      "Current step: 453\n",
      "Mean reward: 5.800112221045259\n",
      "Loss: 7.102436065673828\n",
      "Current step: 454\n",
      "Mean reward: 5.800112221045259\n",
      "Loss: 4.330277919769287\n",
      "Current step: 455\n",
      "Mean reward: 5.80221394228184\n",
      "Loss: 6.100030899047852\n",
      "Current step: 456\n",
      "Mean reward: 5.80221394228184\n",
      "Loss: 5.056698322296143\n",
      "Current step: 457\n",
      "Mean reward: 5.80221394228184\n",
      "Loss: 4.893375396728516\n",
      "Current step: 458\n",
      "Mean reward: 5.80221394228184\n",
      "Loss: 6.781759262084961\n",
      "Current step: 459\n",
      "Mean reward: 5.804287826151049\n",
      "Loss: 4.468038082122803\n",
      "Current step: 460\n",
      "Mean reward: 5.804287826151049\n",
      "Loss: 2.2204747200012207\n",
      "Current step: 461\n",
      "Mean reward: 5.8063344220746105\n",
      "Loss: 4.182988166809082\n",
      "Current step: 462\n",
      "Mean reward: 5.8063344220746105\n",
      "Loss: 5.131732940673828\n",
      "Current step: 463\n",
      "Mean reward: 5.8083542651102835\n",
      "Loss: 5.485130310058594\n",
      "Current step: 464\n",
      "Mean reward: 5.8083542651102835\n",
      "Loss: 7.020451068878174\n",
      "Current step: 465\n",
      "Mean reward: 5.810347876418219\n",
      "Loss: 5.803178310394287\n",
      "Current step: 466\n",
      "Mean reward: 5.810347876418219\n",
      "Loss: 4.953244209289551\n",
      "Current step: 467\n",
      "Mean reward: 5.812315763709279\n",
      "Loss: 6.996616840362549\n",
      "Current step: 468\n",
      "Mean reward: 5.812315763709279\n",
      "Loss: 8.269222259521484\n",
      "Current step: 469\n",
      "Mean reward: 5.814258421676095\n",
      "Loss: 4.357572078704834\n",
      "Current step: 470\n",
      "Mean reward: 5.814258421676095\n",
      "Loss: 3.8134846687316895\n",
      "Current step: 471\n",
      "Mean reward: 5.816176332407663\n",
      "Loss: 5.324980735778809\n",
      "Current step: 472\n",
      "Mean reward: 5.816176332407663\n",
      "Loss: 3.341292381286621\n",
      "Current step: 473\n",
      "Mean reward: 5.818069965788199\n",
      "Loss: 5.666561126708984\n",
      "Current step: 474\n",
      "Mean reward: 5.818069965788199\n",
      "Loss: 4.167475700378418\n",
      "Current step: 475\n",
      "Mean reward: 5.81993977988093\n",
      "Loss: 6.215360164642334\n",
      "Current step: 476\n",
      "Mean reward: 5.81993977988093\n",
      "Loss: 5.723352432250977\n",
      "Current step: 477\n",
      "Mean reward: 5.8217862212975025\n",
      "Loss: 5.207400798797607\n",
      "Current step: 478\n",
      "Mean reward: 5.8217862212975025\n",
      "Loss: 7.468923091888428\n",
      "Current step: 479\n",
      "Mean reward: 5.8217862212975025\n",
      "Loss: 5.233518123626709\n",
      "Current step: 480\n",
      "Mean reward: 5.8217862212975025\n",
      "Loss: 6.256024360656738\n",
      "Current step: 481\n",
      "Mean reward: 5.805596705228659\n",
      "Loss: 4.304131507873535\n",
      "Current step: 482\n",
      "Mean reward: 5.805596705228659\n",
      "Loss: 6.749199390411377\n",
      "Current step: 483\n",
      "Mean reward: 5.807508888570041\n",
      "Loss: 4.025860786437988\n",
      "Current step: 484\n",
      "Mean reward: 5.807508888570041\n",
      "Loss: 4.04721736907959\n",
      "Current step: 485\n",
      "Mean reward: 5.809397609539135\n",
      "Loss: 4.3578362464904785\n",
      "Current step: 486\n",
      "Mean reward: 5.809397609539135\n",
      "Loss: 2.85683012008667\n",
      "Current step: 487\n",
      "Mean reward: 5.81126329732568\n",
      "Loss: 6.635377407073975\n",
      "Current step: 488\n",
      "Mean reward: 5.81126329732568\n",
      "Loss: 5.15968132019043\n",
      "Current step: 489\n",
      "Mean reward: 5.813106370714812\n",
      "Loss: 5.802858829498291\n",
      "Current step: 490\n",
      "Mean reward: 5.813106370714812\n",
      "Loss: 6.788445472717285\n",
      "Current step: 491\n",
      "Mean reward: 5.81492723840046\n",
      "Loss: 4.266006946563721\n",
      "Current step: 492\n",
      "Mean reward: 5.81492723840046\n",
      "Loss: 6.374074935913086\n",
      "Current step: 493\n",
      "Mean reward: 5.81492723840046\n",
      "Loss: 5.857580184936523\n",
      "Current step: 494\n",
      "Mean reward: 5.81492723840046\n",
      "Loss: 3.920311212539673\n",
      "Current step: 495\n",
      "Mean reward: 5.8167262992874775\n",
      "Loss: 4.439631938934326\n",
      "Current step: 496\n",
      "Mean reward: 5.8167262992874775\n",
      "Loss: 4.793513298034668\n",
      "Current step: 497\n",
      "Mean reward: 5.818503942782984\n",
      "Loss: 3.706667900085449\n",
      "Current step: 498\n",
      "Mean reward: 5.818503942782984\n",
      "Loss: 5.113578796386719\n",
      "Current step: 499\n",
      "Mean reward: 5.82026054907736\n",
      "Loss: 3.7730016708374023\n",
      "Current step: 500\n",
      "Mean reward: 5.82026054907736\n",
      "Loss: 5.64910888671875\n",
      "Current step: 501\n",
      "Mean reward: 5.82199648941533\n",
      "Loss: 7.376948356628418\n",
      "Current step: 502\n",
      "Mean reward: 5.82199648941533\n",
      "Loss: 6.593436241149902\n",
      "Current step: 503\n",
      "Mean reward: 5.8237121263575355\n",
      "Loss: 6.418304920196533\n",
      "Current step: 504\n",
      "Mean reward: 5.8237121263575355\n",
      "Loss: 4.448005676269531\n",
      "Current step: 505\n",
      "Mean reward: 5.825407814032971\n",
      "Loss: 8.743850708007812\n",
      "Current step: 506\n",
      "Mean reward: 5.825407814032971\n",
      "Loss: 5.366333484649658\n",
      "Current step: 507\n",
      "Mean reward: 5.8270838983826785\n",
      "Loss: 3.9005541801452637\n",
      "Current step: 508\n",
      "Mean reward: 5.8270838983826785\n",
      "Loss: 9.796113014221191\n",
      "Current step: 509\n",
      "Mean reward: 5.828740717395033\n",
      "Loss: 5.075886249542236\n",
      "Current step: 510\n",
      "Mean reward: 5.828740717395033\n",
      "Loss: 4.283490180969238\n",
      "Current step: 511\n",
      "Mean reward: 5.830378601332961\n",
      "Loss: 4.26853609085083\n",
      "Current step: 512\n",
      "Mean reward: 5.830378601332961\n",
      "Loss: 4.290448188781738\n",
      "Current step: 513\n",
      "Mean reward: 5.831997872953415\n",
      "Loss: 5.142725467681885\n",
      "Current step: 514\n",
      "Mean reward: 5.831997872953415\n",
      "Loss: 5.514404773712158\n",
      "Current step: 515\n",
      "Mean reward: 5.833598847719399\n",
      "Loss: 6.904332637786865\n",
      "Current step: 516\n",
      "Mean reward: 5.833598847719399\n",
      "Loss: 6.587852478027344\n",
      "Current step: 517\n",
      "Mean reward: 5.835181834004866\n",
      "Loss: 3.5134239196777344\n",
      "Current step: 518\n",
      "Mean reward: 5.835181834004866\n",
      "Loss: 5.56593656539917\n",
      "Current step: 519\n",
      "Mean reward: 5.836747133292729\n",
      "Loss: 6.458611011505127\n",
      "Current step: 520\n",
      "Mean reward: 5.836747133292729\n",
      "Loss: 6.806687355041504\n",
      "Current step: 521\n",
      "Mean reward: 5.838295040366281\n",
      "Loss: 4.213644504547119\n",
      "Current step: 522\n",
      "Mean reward: 5.838295040366281\n",
      "Loss: 7.181962490081787\n",
      "Current step: 523\n",
      "Mean reward: 5.839825843494272\n",
      "Loss: 5.053092002868652\n",
      "Current step: 524\n",
      "Mean reward: 5.839825843494272\n",
      "Loss: 7.200163841247559\n",
      "Current step: 525\n",
      "Mean reward: 5.841339824609866\n",
      "Loss: 6.247977256774902\n",
      "Current step: 526\n",
      "Mean reward: 5.841339824609866\n",
      "Loss: 6.3596625328063965\n",
      "Current step: 527\n",
      "Mean reward: 5.842837259483759\n",
      "Loss: 4.20742130279541\n",
      "Current step: 528\n",
      "Mean reward: 5.842837259483759\n",
      "Loss: 3.4849236011505127\n",
      "Current step: 529\n",
      "Mean reward: 5.8443184178916345\n",
      "Loss: 6.121838092803955\n",
      "Current step: 530\n",
      "Mean reward: 5.8443184178916345\n",
      "Loss: 7.577969551086426\n",
      "Current step: 531\n",
      "Mean reward: 5.8443184178916345\n",
      "Loss: 4.098949909210205\n",
      "Current step: 532\n",
      "Mean reward: 5.8443184178916345\n",
      "Loss: 5.6981916427612305\n",
      "Current step: 533\n",
      "Mean reward: 5.8443184178916345\n",
      "Loss: 3.727921962738037\n",
      "Current step: 534\n",
      "Mean reward: 5.8457835637761795\n",
      "Loss: 4.750201225280762\n",
      "Current step: 535\n",
      "Mean reward: 5.8457835637761795\n",
      "Loss: 4.689194202423096\n",
      "Current step: 536\n",
      "Mean reward: 5.847232955403902\n",
      "Loss: 4.452197074890137\n",
      "Current step: 537\n",
      "Mean reward: 5.847232955403902\n",
      "Loss: 7.453459739685059\n",
      "Current step: 538\n",
      "Mean reward: 5.848666845516888\n",
      "Loss: 3.946512222290039\n",
      "Current step: 539\n",
      "Mean reward: 5.848666845516888\n",
      "Loss: 5.27104377746582\n",
      "Current step: 540\n",
      "Mean reward: 5.850085481479736\n",
      "Loss: 3.5549094676971436\n",
      "Current step: 541\n",
      "Mean reward: 5.850085481479736\n",
      "Loss: 5.422214508056641\n",
      "Current step: 542\n",
      "Mean reward: 5.851489105421814\n",
      "Loss: 6.805514335632324\n",
      "Current step: 543\n",
      "Mean reward: 5.851489105421814\n",
      "Loss: 2.58634877204895\n",
      "Current step: 544\n",
      "Mean reward: 5.852877954375028\n",
      "Loss: 4.959172248840332\n",
      "Current step: 545\n",
      "Mean reward: 5.852877954375028\n",
      "Loss: 5.098762512207031\n",
      "Current step: 546\n",
      "Mean reward: 5.854252260407265\n",
      "Loss: 3.4314489364624023\n",
      "Current step: 547\n",
      "Mean reward: 5.854252260407265\n",
      "Loss: 5.352104663848877\n",
      "Current step: 548\n",
      "Mean reward: 5.854252260407265\n",
      "Loss: 6.445519924163818\n",
      "Current step: 549\n",
      "Mean reward: 5.854252260407265\n",
      "Loss: 6.892508506774902\n",
      "Current step: 550\n",
      "Mean reward: 5.855612250751669\n",
      "Loss: 4.182417869567871\n",
      "Current step: 551\n",
      "Mean reward: 5.855612250751669\n",
      "Loss: 3.510834217071533\n",
      "Current step: 552\n",
      "Mean reward: 5.85695814793188\n",
      "Loss: 4.9438700675964355\n",
      "Current step: 553\n",
      "Mean reward: 5.85695814793188\n",
      "Loss: 5.097929000854492\n",
      "Current step: 554\n",
      "Mean reward: 5.858290169883428\n",
      "Loss: 3.5716476440429688\n",
      "Current step: 555\n",
      "Mean reward: 5.858290169883428\n",
      "Loss: 3.9724173545837402\n",
      "Current step: 556\n",
      "Mean reward: 5.859608530071372\n",
      "Loss: 5.329468250274658\n",
      "Current step: 557\n",
      "Mean reward: 5.859608530071372\n",
      "Loss: 6.117525100708008\n",
      "Current step: 558\n",
      "Mean reward: 5.860913437604337\n",
      "Loss: 4.109767436981201\n",
      "Current step: 559\n",
      "Mean reward: 5.860913437604337\n",
      "Loss: 4.7006449699401855\n",
      "Current step: 560\n",
      "Mean reward: 5.862205097345088\n",
      "Loss: 4.593377113342285\n",
      "Current step: 561\n",
      "Mean reward: 5.862205097345088\n",
      "Loss: 4.665053844451904\n",
      "Current step: 562\n",
      "Mean reward: 5.863483710017751\n",
      "Loss: 4.537346839904785\n",
      "Current step: 563\n",
      "Mean reward: 5.863483710017751\n",
      "Loss: 7.155874252319336\n",
      "Current step: 564\n",
      "Mean reward: 5.864749472311795\n",
      "Loss: 3.440764904022217\n",
      "Current step: 565\n",
      "Mean reward: 5.864749472311795\n",
      "Loss: 4.763077735900879\n",
      "Current step: 566\n",
      "Mean reward: 5.8660025769829005\n",
      "Loss: 7.114013671875\n",
      "Current step: 567\n",
      "Mean reward: 5.8660025769829005\n",
      "Loss: 6.719839572906494\n",
      "Current step: 568\n",
      "Mean reward: 5.867243212950808\n",
      "Loss: 7.164556503295898\n",
      "Current step: 569\n",
      "Mean reward: 5.867243212950808\n",
      "Loss: 5.3575286865234375\n",
      "Current step: 570\n",
      "Mean reward: 5.868471565394281\n",
      "Loss: 4.4644880294799805\n",
      "Current step: 571\n",
      "Mean reward: 5.868471565394281\n",
      "Loss: 5.392822742462158\n",
      "Current step: 572\n",
      "Mean reward: 5.869687815843238\n",
      "Loss: 5.388790130615234\n",
      "Current step: 573\n",
      "Mean reward: 5.869687815843238\n",
      "Loss: 5.943212509155273\n",
      "Current step: 574\n",
      "Mean reward: 5.870892142268185\n",
      "Loss: 6.159061908721924\n",
      "Current step: 575\n",
      "Mean reward: 5.870892142268185\n",
      "Loss: 5.202308654785156\n",
      "Current step: 576\n",
      "Mean reward: 5.8720847191670345\n",
      "Loss: 3.580573797225952\n",
      "Current step: 577\n",
      "Mean reward: 5.8720847191670345\n",
      "Loss: 6.4930009841918945\n",
      "Current step: 578\n",
      "Mean reward: 5.8720847191670345\n",
      "Loss: 6.794266223907471\n",
      "Current step: 579\n",
      "Mean reward: 5.8720847191670345\n",
      "Loss: 5.090173721313477\n",
      "Current step: 580\n",
      "Mean reward: 5.859187580405126\n",
      "Loss: 6.3165106773376465\n",
      "Current step: 581\n",
      "Mean reward: 5.859187580405126\n",
      "Loss: 3.677657127380371\n",
      "Current step: 582\n",
      "Mean reward: 5.860425178598977\n",
      "Loss: 4.564919948577881\n",
      "Current step: 583\n",
      "Mean reward: 5.860425178598977\n",
      "Loss: 4.111327171325684\n",
      "Current step: 584\n",
      "Mean reward: 5.861650876810198\n",
      "Loss: 6.218135833740234\n",
      "Current step: 585\n",
      "Mean reward: 5.861650876810198\n",
      "Loss: 3.9298949241638184\n",
      "Current step: 586\n",
      "Mean reward: 5.862864845851932\n",
      "Loss: 4.336345672607422\n",
      "Current step: 587\n",
      "Mean reward: 5.862864845851932\n",
      "Loss: 4.928041934967041\n",
      "Current step: 588\n",
      "Mean reward: 5.864067253283743\n",
      "Loss: 3.807774066925049\n",
      "Current step: 589\n",
      "Mean reward: 5.864067253283743\n",
      "Loss: 5.991129398345947\n",
      "Current step: 590\n",
      "Mean reward: 5.8652582634887125\n",
      "Loss: 4.83408784866333\n",
      "Current step: 591\n",
      "Mean reward: 5.8652582634887125\n",
      "Loss: 5.5153117179870605\n",
      "Current step: 592\n",
      "Mean reward: 5.8664380377483525\n",
      "Loss: 3.595893383026123\n",
      "Current step: 593\n",
      "Mean reward: 5.8664380377483525\n",
      "Loss: 1.6776515245437622\n",
      "Current step: 594\n",
      "Mean reward: 5.867606734315414\n",
      "Loss: 5.416431903839111\n",
      "Current step: 595\n",
      "Mean reward: 5.867606734315414\n",
      "Loss: 7.270135402679443\n",
      "Current step: 596\n",
      "Mean reward: 5.868764508484652\n",
      "Loss: 4.009998798370361\n",
      "Current step: 597\n",
      "Mean reward: 5.868764508484652\n",
      "Loss: 4.351120948791504\n",
      "Current step: 598\n",
      "Mean reward: 5.868764508484652\n",
      "Loss: 4.595105171203613\n",
      "Current step: 599\n",
      "Mean reward: 5.868764508484652\n",
      "Loss: 2.7865915298461914\n",
      "Current step: 600\n",
      "Mean reward: 5.869911512661618\n",
      "Loss: 4.699154376983643\n",
      "Current step: 601\n",
      "Mean reward: 5.869911512661618\n",
      "Loss: 4.416659832000732\n",
      "Current step: 602\n",
      "Mean reward: 5.871047896429541\n",
      "Loss: 3.9311609268188477\n",
      "Current step: 603\n",
      "Mean reward: 5.871047896429541\n",
      "Loss: 5.933574676513672\n",
      "Current step: 604\n",
      "Mean reward: 5.872173806614347\n",
      "Loss: 6.837409973144531\n",
      "Current step: 605\n",
      "Mean reward: 5.872173806614347\n",
      "Loss: 4.070801258087158\n",
      "Current step: 606\n",
      "Mean reward: 5.873289387347916\n",
      "Loss: 4.0139994621276855\n",
      "Current step: 607\n",
      "Mean reward: 5.873289387347916\n",
      "Loss: 2.0470948219299316\n",
      "Current step: 608\n",
      "Mean reward: 5.87439478012958\n",
      "Loss: 7.965622901916504\n",
      "Current step: 609\n",
      "Mean reward: 5.87439478012958\n",
      "Loss: 6.90053653717041\n",
      "Current step: 610\n",
      "Mean reward: 5.875490123885957\n",
      "Loss: 3.754487991333008\n",
      "Current step: 611\n",
      "Mean reward: 5.875490123885957\n",
      "Loss: 2.7778520584106445\n",
      "Current step: 612\n",
      "Mean reward: 5.876575555029154\n",
      "Loss: 7.716029167175293\n",
      "Current step: 613\n",
      "Mean reward: 5.876575555029154\n",
      "Loss: 4.962956428527832\n",
      "Current step: 614\n",
      "Mean reward: 5.877651207513402\n",
      "Loss: 3.890406608581543\n",
      "Current step: 615\n",
      "Mean reward: 5.877651207513402\n",
      "Loss: 5.0641632080078125\n",
      "Current step: 616\n",
      "Mean reward: 5.878717212890169\n",
      "Loss: 5.139142990112305\n",
      "Current step: 617\n",
      "Mean reward: 5.878717212890169\n",
      "Loss: 5.384140491485596\n",
      "Current step: 618\n",
      "Mean reward: 5.879773700361787\n",
      "Loss: 4.168010711669922\n",
      "Current step: 619\n",
      "Mean reward: 5.879773700361787\n",
      "Loss: 3.361760377883911\n",
      "Current step: 620\n",
      "Mean reward: 5.880820796833657\n",
      "Loss: 5.1643242835998535\n",
      "Current step: 621\n",
      "Mean reward: 5.880820796833657\n",
      "Loss: 3.4193859100341797\n",
      "Current step: 622\n",
      "Mean reward: 5.881858626965068\n",
      "Loss: 3.8735876083374023\n",
      "Current step: 623\n",
      "Mean reward: 5.881858626965068\n",
      "Loss: 4.5175862312316895\n",
      "Current step: 624\n",
      "Mean reward: 5.882887313218668\n",
      "Loss: 5.65209436416626\n",
      "Current step: 625\n",
      "Mean reward: 5.882887313218668\n",
      "Loss: 4.316425800323486\n",
      "Current step: 626\n",
      "Mean reward: 5.883906975908641\n",
      "Loss: 6.6971049308776855\n",
      "Current step: 627\n",
      "Mean reward: 5.883906975908641\n",
      "Loss: 5.018622875213623\n",
      "Current step: 628\n",
      "Mean reward: 5.884917733247609\n",
      "Loss: 3.418290376663208\n",
      "Current step: 629\n",
      "Mean reward: 5.884917733247609\n",
      "Loss: 7.431335926055908\n",
      "Current step: 630\n",
      "Mean reward: 5.885919701392326\n",
      "Loss: 3.9335837364196777\n",
      "Current step: 631\n",
      "Mean reward: 5.885919701392326\n",
      "Loss: 3.728419065475464\n",
      "Current step: 632\n",
      "Mean reward: 5.88691299448817\n",
      "Loss: 4.1520233154296875\n",
      "Current step: 633\n",
      "Mean reward: 5.88691299448817\n",
      "Loss: 4.854265213012695\n",
      "Current step: 634\n",
      "Mean reward: 5.8878977247125\n",
      "Loss: 5.477252960205078\n",
      "Current step: 635\n",
      "Mean reward: 5.8878977247125\n",
      "Loss: 5.4210309982299805\n",
      "Current step: 636\n",
      "Mean reward: 5.888874002316878\n",
      "Loss: 4.170694828033447\n",
      "Current step: 637\n",
      "Mean reward: 5.888874002316878\n",
      "Loss: 2.101435422897339\n",
      "Current step: 638\n",
      "Mean reward: 5.889841935668227\n",
      "Loss: 4.648847579956055\n",
      "Current step: 639\n",
      "Mean reward: 5.889841935668227\n",
      "Loss: 3.3007049560546875\n",
      "Current step: 640\n",
      "Mean reward: 5.890801631288925\n",
      "Loss: 3.1818370819091797\n",
      "Current step: 641\n",
      "Mean reward: 5.890801631288925\n",
      "Loss: 5.715459823608398\n",
      "Current step: 642\n",
      "Mean reward: 5.891753193895888\n",
      "Loss: 6.143828868865967\n",
      "Current step: 643\n",
      "Mean reward: 5.891753193895888\n",
      "Loss: 6.388758659362793\n",
      "Current step: 644\n",
      "Mean reward: 5.892696726438659\n",
      "Loss: 5.210655212402344\n",
      "Current step: 645\n",
      "Mean reward: 5.892696726438659\n",
      "Loss: 4.487621784210205\n",
      "Current step: 646\n",
      "Mean reward: 5.8936323301365325\n",
      "Loss: 5.396539211273193\n",
      "Current step: 647\n",
      "Mean reward: 5.8936323301365325\n",
      "Loss: 3.946776866912842\n",
      "Current step: 648\n",
      "Mean reward: 5.894560104514757\n",
      "Loss: 4.888648509979248\n",
      "Current step: 649\n",
      "Mean reward: 5.894560104514757\n",
      "Loss: 6.888740062713623\n",
      "Current step: 650\n",
      "Mean reward: 5.895480147439832\n",
      "Loss: 2.1826364994049072\n",
      "Current step: 651\n",
      "Mean reward: 5.895480147439832\n",
      "Loss: 5.710336685180664\n",
      "Current step: 652\n",
      "Mean reward: 5.89639255515391\n",
      "Loss: 5.072384357452393\n",
      "Current step: 653\n",
      "Mean reward: 5.89639255515391\n",
      "Loss: 4.846491813659668\n",
      "Current step: 654\n",
      "Mean reward: 5.897297422308367\n",
      "Loss: 5.861670017242432\n",
      "Current step: 655\n",
      "Mean reward: 5.897297422308367\n",
      "Loss: 2.7481212615966797\n",
      "Current step: 656\n",
      "Mean reward: 5.898194841996531\n",
      "Loss: 6.395930290222168\n",
      "Current step: 657\n",
      "Mean reward: 5.898194841996531\n",
      "Loss: 4.98448371887207\n",
      "Current step: 658\n",
      "Mean reward: 5.899084905785612\n",
      "Loss: 3.783174991607666\n",
      "Current step: 659\n",
      "Mean reward: 5.899084905785612\n",
      "Loss: 6.345600128173828\n",
      "Current step: 660\n",
      "Mean reward: 5.899967703747844\n",
      "Loss: 5.868439197540283\n",
      "Current step: 661\n",
      "Mean reward: 5.899967703747844\n",
      "Loss: 6.642545223236084\n",
      "Current step: 662\n",
      "Mean reward: 5.900843324490872\n",
      "Loss: 4.732759952545166\n",
      "Current step: 663\n",
      "Mean reward: 5.900843324490872\n",
      "Loss: 4.867054462432861\n",
      "Current step: 664\n",
      "Mean reward: 5.901711855187395\n",
      "Loss: 3.7729718685150146\n",
      "Current step: 665\n",
      "Mean reward: 5.901711855187395\n",
      "Loss: 3.1313652992248535\n",
      "Current step: 666\n",
      "Mean reward: 5.90257338160411\n",
      "Loss: 5.298024654388428\n",
      "Current step: 667\n",
      "Mean reward: 5.90257338160411\n",
      "Loss: 6.1679229736328125\n",
      "Current step: 668\n",
      "Mean reward: 5.903427988129927\n",
      "Loss: 4.881931304931641\n",
      "Current step: 669\n",
      "Mean reward: 5.903427988129927\n",
      "Loss: 4.178646564483643\n",
      "Current step: 670\n",
      "Mean reward: 5.904275757803538\n",
      "Loss: 4.536791801452637\n",
      "Current step: 671\n",
      "Mean reward: 5.904275757803538\n",
      "Loss: 5.537778854370117\n",
      "Current step: 672\n",
      "Mean reward: 5.905116772340306\n",
      "Loss: 4.337874889373779\n",
      "Current step: 673\n",
      "Mean reward: 5.905116772340306\n",
      "Loss: 3.6066126823425293\n",
      "Current step: 674\n",
      "Mean reward: 5.905951112158528\n",
      "Loss: 4.111753463745117\n",
      "Current step: 675\n",
      "Mean reward: 5.905951112158528\n",
      "Loss: 5.667691707611084\n",
      "Current step: 676\n",
      "Mean reward: 5.905951112158528\n",
      "Loss: 3.88588285446167\n",
      "Current step: 677\n",
      "Mean reward: 5.905951112158528\n",
      "Loss: 3.6757216453552246\n",
      "Current step: 678\n",
      "Mean reward: 5.895316025289182\n",
      "Loss: 5.390746116638184\n",
      "Current step: 679\n",
      "Mean reward: 5.895316025289182\n",
      "Loss: 6.400911331176758\n",
      "Current step: 680\n",
      "Mean reward: 5.896182381120848\n",
      "Loss: 3.618946075439453\n",
      "Current step: 681\n",
      "Mean reward: 5.896182381120848\n",
      "Loss: 2.7709033489227295\n",
      "Current step: 682\n",
      "Mean reward: 5.897041942004815\n",
      "Loss: 3.4119534492492676\n",
      "Current step: 683\n",
      "Mean reward: 5.897041942004815\n",
      "Loss: 5.2890191078186035\n",
      "Current step: 684\n",
      "Mean reward: 5.897894787569377\n",
      "Loss: 6.138829231262207\n",
      "Current step: 685\n",
      "Mean reward: 5.897894787569377\n",
      "Loss: 3.1945831775665283\n",
      "Current step: 686\n",
      "Mean reward: 5.898740996203474\n",
      "Loss: 4.928464412689209\n",
      "Current step: 687\n",
      "Mean reward: 5.898740996203474\n",
      "Loss: 4.680208206176758\n",
      "Current step: 688\n",
      "Mean reward: 5.899580645080718\n",
      "Loss: 4.048381328582764\n",
      "Current step: 689\n",
      "Mean reward: 5.899580645080718\n",
      "Loss: 5.271955490112305\n",
      "Current step: 690\n",
      "Mean reward: 5.900413810182848\n",
      "Loss: 2.9101061820983887\n",
      "Current step: 691\n",
      "Mean reward: 5.900413810182848\n",
      "Loss: 4.384403228759766\n",
      "Current step: 692\n",
      "Mean reward: 5.901240566322655\n",
      "Loss: 2.7090399265289307\n",
      "Current step: 693\n",
      "Mean reward: 5.901240566322655\n",
      "Loss: 3.563772439956665\n",
      "Current step: 694\n",
      "Mean reward: 5.9020609871663705\n",
      "Loss: 4.796700954437256\n",
      "Current step: 695\n",
      "Mean reward: 5.9020609871663705\n",
      "Loss: 6.895629405975342\n",
      "Current step: 696\n",
      "Mean reward: 5.902875145255554\n",
      "Loss: 3.390845775604248\n",
      "Current step: 697\n",
      "Mean reward: 5.902875145255554\n",
      "Loss: 6.031647682189941\n",
      "Current step: 698\n",
      "Mean reward: 5.90368311202847\n",
      "Loss: 5.494372844696045\n",
      "Current step: 699\n",
      "Mean reward: 5.90368311202847\n",
      "Loss: 4.614336013793945\n",
      "Current step: 700\n",
      "Mean reward: 5.90368311202847\n",
      "Loss: 3.5404951572418213\n",
      "Current step: 701\n",
      "Mean reward: 5.90368311202847\n",
      "Loss: 3.404456853866577\n",
      "Current step: 702\n",
      "Mean reward: 5.893499744688262\n",
      "Loss: 5.577962875366211\n",
      "Current step: 703\n",
      "Mean reward: 5.893499744688262\n",
      "Loss: 5.463513374328613\n",
      "Current step: 704\n",
      "Mean reward: 5.894336992468807\n",
      "Loss: 6.655966281890869\n",
      "Current step: 705\n",
      "Mean reward: 5.894336992468807\n",
      "Loss: 5.281553268432617\n",
      "Current step: 706\n",
      "Mean reward: 5.895167945153256\n",
      "Loss: 5.8407087326049805\n",
      "Current step: 707\n",
      "Mean reward: 5.895167945153256\n",
      "Loss: 4.952949047088623\n",
      "Current step: 708\n",
      "Mean reward: 5.895992673473028\n",
      "Loss: 5.94128942489624\n",
      "Current step: 709\n",
      "Mean reward: 5.895992673473028\n",
      "Loss: 4.394579887390137\n",
      "Current step: 710\n",
      "Mean reward: 5.896811247103847\n",
      "Loss: 2.9366607666015625\n",
      "Current step: 711\n",
      "Mean reward: 5.896811247103847\n",
      "Loss: 4.771888256072998\n",
      "Current step: 712\n",
      "Mean reward: 5.897623734685366\n",
      "Loss: 8.203851699829102\n",
      "Current step: 713\n",
      "Mean reward: 5.897623734685366\n",
      "Loss: 5.1430439949035645\n",
      "Current step: 714\n",
      "Mean reward: 5.898430203840356\n",
      "Loss: 5.064519882202148\n",
      "Current step: 715\n",
      "Mean reward: 5.898430203840356\n",
      "Loss: 4.97052526473999\n",
      "Current step: 716\n",
      "Mean reward: 5.8992307211934625\n",
      "Loss: 5.328307628631592\n",
      "Current step: 717\n",
      "Mean reward: 5.8992307211934625\n",
      "Loss: 5.972227573394775\n",
      "Current step: 718\n",
      "Mean reward: 5.900025352389561\n",
      "Loss: 5.632691860198975\n",
      "Current step: 719\n",
      "Mean reward: 5.900025352389561\n",
      "Loss: 3.340390205383301\n",
      "Current step: 720\n",
      "Mean reward: 5.900814162111697\n",
      "Loss: 2.7659764289855957\n",
      "Current step: 721\n",
      "Mean reward: 5.900814162111697\n",
      "Loss: 5.667625427246094\n",
      "Current step: 722\n",
      "Mean reward: 5.901597214098634\n",
      "Loss: 4.243826389312744\n",
      "Current step: 723\n",
      "Mean reward: 5.901597214098634\n",
      "Loss: 5.205902576446533\n",
      "Current step: 724\n",
      "Mean reward: 5.90237457116203\n",
      "Loss: 3.423241376876831\n",
      "Current step: 725\n",
      "Mean reward: 5.90237457116203\n",
      "Loss: 4.805628776550293\n",
      "Current step: 726\n",
      "Mean reward: 5.903146295203227\n",
      "Loss: 4.752083778381348\n",
      "Current step: 727\n",
      "Mean reward: 5.903146295203227\n",
      "Loss: 2.570089340209961\n",
      "Current step: 728\n",
      "Mean reward: 5.903912447229686\n",
      "Loss: 4.591193199157715\n",
      "Current step: 729\n",
      "Mean reward: 5.903912447229686\n",
      "Loss: 3.9580883979797363\n",
      "Current step: 730\n",
      "Mean reward: 5.904673087371062\n",
      "Loss: 4.0029296875\n",
      "Current step: 731\n",
      "Mean reward: 5.904673087371062\n",
      "Loss: 2.905508518218994\n",
      "Current step: 732\n",
      "Mean reward: 5.9054282748949385\n",
      "Loss: 3.5987210273742676\n",
      "Current step: 733\n",
      "Mean reward: 5.9054282748949385\n",
      "Loss: 5.299095630645752\n",
      "Current step: 734\n",
      "Mean reward: 5.906178068222216\n",
      "Loss: 4.401350021362305\n",
      "Current step: 735\n",
      "Mean reward: 5.906178068222216\n",
      "Loss: 2.941685676574707\n",
      "Current step: 736\n",
      "Mean reward: 5.90692252494218\n",
      "Loss: 3.2003471851348877\n",
      "Current step: 737\n",
      "Mean reward: 5.90692252494218\n",
      "Loss: 5.33236837387085\n",
      "Current step: 738\n",
      "Mean reward: 5.907661701827252\n",
      "Loss: 4.064442157745361\n",
      "Current step: 739\n",
      "Mean reward: 5.907661701827252\n",
      "Loss: 3.8111813068389893\n",
      "Current step: 740\n",
      "Mean reward: 5.908395654847412\n",
      "Loss: 6.288463115692139\n",
      "Current step: 741\n",
      "Mean reward: 5.908395654847412\n",
      "Loss: 4.454513072967529\n",
      "Current step: 742\n",
      "Mean reward: 5.909124439184332\n",
      "Loss: 5.674953937530518\n",
      "Current step: 743\n",
      "Mean reward: 5.909124439184332\n",
      "Loss: 5.144211769104004\n",
      "Current step: 744\n",
      "Mean reward: 5.909124439184332\n",
      "Loss: 5.23845100402832\n",
      "Current step: 745\n",
      "Mean reward: 5.909848109245202\n",
      "Loss: 4.921895503997803\n",
      "Current step: 746\n",
      "Mean reward: 5.909848109245202\n",
      "Loss: 3.9316935539245605\n",
      "Current step: 747\n",
      "Mean reward: 5.909848109245202\n",
      "Loss: 3.9419045448303223\n",
      "Current step: 748\n",
      "Mean reward: 5.910566718676277\n",
      "Loss: 2.9035110473632812\n",
      "Current step: 749\n",
      "Mean reward: 5.910566718676277\n",
      "Loss: 5.571643352508545\n",
      "Current step: 750\n",
      "Mean reward: 5.911280320376124\n",
      "Loss: 2.283600091934204\n",
      "Current step: 751\n",
      "Mean reward: 5.911280320376124\n",
      "Loss: 2.6882920265197754\n",
      "Current step: 752\n",
      "Mean reward: 5.911988966508612\n",
      "Loss: 4.585672855377197\n",
      "Current step: 753\n",
      "Mean reward: 5.911988966508612\n",
      "Loss: 4.452263355255127\n",
      "Current step: 754\n",
      "Mean reward: 5.912692708515614\n",
      "Loss: 4.64809513092041\n",
      "Current step: 755\n",
      "Mean reward: 5.912692708515614\n",
      "Loss: 3.376993179321289\n",
      "Current step: 756\n",
      "Mean reward: 5.913391597129466\n",
      "Loss: 3.2679834365844727\n",
      "Current step: 757\n",
      "Mean reward: 5.913391597129466\n",
      "Loss: 3.174518346786499\n",
      "Current step: 758\n",
      "Mean reward: 5.914085682385146\n",
      "Loss: 5.1262898445129395\n",
      "Current step: 759\n",
      "Mean reward: 5.914085682385146\n",
      "Loss: 3.837294101715088\n",
      "Current step: 760\n",
      "Mean reward: 5.914775013632225\n",
      "Loss: 3.761021614074707\n",
      "Current step: 761\n",
      "Mean reward: 5.914775013632225\n",
      "Loss: 4.617606163024902\n",
      "Current step: 762\n",
      "Mean reward: 5.914775013632225\n",
      "Loss: 4.7478132247924805\n",
      "Current step: 763\n",
      "Mean reward: 5.915459639546561\n",
      "Loss: 6.236464500427246\n",
      "Current step: 764\n",
      "Mean reward: 5.915459639546561\n",
      "Loss: 3.8211278915405273\n",
      "Current step: 765\n",
      "Mean reward: 5.9161396081417505\n",
      "Loss: 3.430805206298828\n",
      "Current step: 766\n",
      "Mean reward: 5.9161396081417505\n",
      "Loss: 4.141469478607178\n",
      "Current step: 767\n",
      "Mean reward: 5.916814966780364\n",
      "Loss: 3.6422183513641357\n",
      "Current step: 768\n",
      "Mean reward: 5.916814966780364\n",
      "Loss: 4.774753093719482\n",
      "Current step: 769\n",
      "Mean reward: 5.917485762184931\n",
      "Loss: 4.279383659362793\n",
      "Current step: 770\n",
      "Mean reward: 5.917485762184931\n",
      "Loss: 3.712867021560669\n",
      "Current step: 771\n",
      "Mean reward: 5.918152040448728\n",
      "Loss: 4.191851615905762\n",
      "Current step: 772\n",
      "Mean reward: 5.918152040448728\n",
      "Loss: 3.7096383571624756\n",
      "Current step: 773\n",
      "Mean reward: 5.918813847046325\n",
      "Loss: 3.347036600112915\n",
      "Current step: 774\n",
      "Mean reward: 5.918813847046325\n",
      "Loss: 4.733258247375488\n",
      "Current step: 775\n",
      "Mean reward: 5.919471226843937\n",
      "Loss: 3.369703769683838\n",
      "Current step: 776\n",
      "Mean reward: 5.919471226843937\n",
      "Loss: 2.663357973098755\n",
      "Current step: 777\n",
      "Mean reward: 5.920124224109565\n",
      "Loss: 4.27282190322876\n",
      "Current step: 778\n",
      "Mean reward: 5.920124224109565\n",
      "Loss: 4.916172981262207\n",
      "Current step: 779\n",
      "Mean reward: 5.92077288252293\n",
      "Loss: 5.099973201751709\n",
      "Current step: 780\n",
      "Mean reward: 5.92077288252293\n",
      "Loss: 1.6438792943954468\n",
      "Current step: 781\n",
      "Mean reward: 5.9214172451852125\n",
      "Loss: 3.781437397003174\n",
      "Current step: 782\n",
      "Mean reward: 5.9214172451852125\n",
      "Loss: 3.1270267963409424\n",
      "Current step: 783\n",
      "Mean reward: 5.9220573546286035\n",
      "Loss: 2.999755620956421\n",
      "Current step: 784\n",
      "Mean reward: 5.9220573546286035\n",
      "Loss: 2.592599868774414\n",
      "Current step: 785\n",
      "Mean reward: 5.922693252825655\n",
      "Loss: 1.9320425987243652\n",
      "Current step: 786\n",
      "Mean reward: 5.922693252825655\n",
      "Loss: 4.110199451446533\n",
      "Current step: 787\n",
      "Mean reward: 5.923324981198465\n",
      "Loss: 3.470938205718994\n",
      "Current step: 788\n",
      "Mean reward: 5.923324981198465\n",
      "Loss: 4.4372711181640625\n",
      "Current step: 789\n",
      "Mean reward: 5.923952580627661\n",
      "Loss: 6.9613118171691895\n",
      "Current step: 790\n",
      "Mean reward: 5.923952580627661\n",
      "Loss: 4.568503379821777\n",
      "Current step: 791\n",
      "Mean reward: 5.924576091461228\n",
      "Loss: 3.9043455123901367\n",
      "Current step: 792\n",
      "Mean reward: 5.924576091461228\n",
      "Loss: 3.3400423526763916\n",
      "Current step: 793\n",
      "Mean reward: 5.925195553523147\n",
      "Loss: 3.0803093910217285\n",
      "Current step: 794\n",
      "Mean reward: 5.925195553523147\n",
      "Loss: 2.9658262729644775\n",
      "Current step: 795\n",
      "Mean reward: 5.925811006121882\n",
      "Loss: 4.384841442108154\n",
      "Current step: 796\n",
      "Mean reward: 5.925811006121882\n",
      "Loss: 4.907649517059326\n",
      "Current step: 797\n",
      "Mean reward: 5.92642248805869\n",
      "Loss: 1.4768165349960327\n",
      "Current step: 798\n",
      "Mean reward: 5.92642248805869\n",
      "Loss: 3.764974355697632\n",
      "Current step: 799\n",
      "Mean reward: 5.9270300376357765\n",
      "Loss: 1.9207462072372437\n",
      "Current step: 800\n",
      "Mean reward: 5.9270300376357765\n",
      "Loss: 3.2100372314453125\n",
      "Current step: 801\n",
      "Mean reward: 5.927633692664291\n",
      "Loss: 4.17642879486084\n",
      "Current step: 802\n",
      "Mean reward: 5.927633692664291\n",
      "Loss: 3.675929546356201\n",
      "Current step: 803\n",
      "Mean reward: 5.928233490472177\n",
      "Loss: 3.715484142303467\n",
      "Current step: 804\n",
      "Mean reward: 5.928233490472177\n",
      "Loss: 5.4515910148620605\n",
      "Current step: 805\n",
      "Mean reward: 5.928829467911859\n",
      "Loss: 3.2019264698028564\n",
      "Current step: 806\n",
      "Mean reward: 5.928829467911859\n",
      "Loss: 4.076186656951904\n",
      "Current step: 807\n",
      "Mean reward: 5.929421661367798\n",
      "Loss: 3.3891706466674805\n",
      "Current step: 808\n",
      "Mean reward: 5.929421661367798\n",
      "Loss: 2.848423957824707\n",
      "Current step: 809\n",
      "Mean reward: 5.930010106763889\n",
      "Loss: 5.199376583099365\n",
      "Current step: 810\n",
      "Mean reward: 5.930010106763889\n",
      "Loss: 5.338048934936523\n",
      "Current step: 811\n",
      "Mean reward: 5.9305948395707295\n",
      "Loss: 5.044175624847412\n",
      "Current step: 812\n",
      "Mean reward: 5.9305948395707295\n",
      "Loss: 3.9927892684936523\n",
      "Current step: 813\n",
      "Mean reward: 5.931175894812747\n",
      "Loss: 4.637118816375732\n",
      "Current step: 814\n",
      "Mean reward: 5.931175894812747\n",
      "Loss: 2.9779675006866455\n",
      "Current step: 815\n",
      "Mean reward: 5.9317533070751916\n",
      "Loss: 2.09255313873291\n",
      "Current step: 816\n",
      "Mean reward: 5.9317533070751916\n",
      "Loss: 4.2483367919921875\n",
      "Current step: 817\n",
      "Mean reward: 5.932327110510995\n",
      "Loss: 0.7661131620407104\n",
      "Current step: 818\n",
      "Mean reward: 5.932327110510995\n",
      "Loss: 5.216585159301758\n",
      "Current step: 819\n",
      "Mean reward: 5.9328973388475115\n",
      "Loss: 4.2656731605529785\n",
      "Current step: 820\n",
      "Mean reward: 5.9328973388475115\n",
      "Loss: 4.884440898895264\n",
      "Current step: 821\n",
      "Mean reward: 5.933464025393117\n",
      "Loss: 5.028138160705566\n",
      "Current step: 822\n",
      "Mean reward: 5.933464025393117\n",
      "Loss: 3.9966859817504883\n",
      "Current step: 823\n",
      "Mean reward: 5.933464025393117\n",
      "Loss: 5.329355239868164\n",
      "Current step: 824\n",
      "Mean reward: 5.933464025393117\n",
      "Loss: 4.8651652336120605\n",
      "Current step: 825\n",
      "Mean reward: 5.934027203043702\n",
      "Loss: 3.509432077407837\n",
      "Current step: 826\n",
      "Mean reward: 5.934027203043702\n",
      "Loss: 2.516158103942871\n",
      "Current step: 827\n",
      "Mean reward: 5.934586904289039\n",
      "Loss: 3.925926923751831\n",
      "Current step: 828\n",
      "Mean reward: 5.934586904289039\n",
      "Loss: 4.1881632804870605\n",
      "Current step: 829\n",
      "Mean reward: 5.935143161219018\n",
      "Loss: 3.401766061782837\n",
      "Current step: 830\n",
      "Mean reward: 5.935143161219018\n",
      "Loss: 6.374082088470459\n",
      "Current step: 831\n",
      "Mean reward: 5.935696005529795\n",
      "Loss: 4.332517623901367\n",
      "Current step: 832\n",
      "Mean reward: 5.935696005529795\n",
      "Loss: 3.0231986045837402\n",
      "Current step: 833\n",
      "Mean reward: 5.936245468529803\n",
      "Loss: 3.2608375549316406\n",
      "Current step: 834\n",
      "Mean reward: 5.936245468529803\n",
      "Loss: 5.1338605880737305\n",
      "Current step: 835\n",
      "Mean reward: 5.936791581145665\n",
      "Loss: 3.02158260345459\n",
      "Current step: 836\n",
      "Mean reward: 5.936791581145665\n",
      "Loss: 4.0236735343933105\n",
      "Current step: 837\n",
      "Mean reward: 5.936791581145665\n",
      "Loss: 4.280569076538086\n",
      "Current step: 838\n",
      "Mean reward: 5.936791581145665\n",
      "Loss: 5.101218223571777\n",
      "Current step: 839\n",
      "Mean reward: 5.953333653541459\n",
      "Loss: 4.027620792388916\n",
      "Current step: 840\n",
      "Mean reward: 5.953333653541459\n",
      "Loss: 4.645913600921631\n",
      "Current step: 841\n",
      "Mean reward: 5.953824674005068\n",
      "Loss: 3.812995195388794\n",
      "Current step: 842\n",
      "Mean reward: 5.953824674005068\n",
      "Loss: 3.646796464920044\n",
      "Current step: 843\n",
      "Mean reward: 5.9543127275776575\n",
      "Loss: 3.0475897789001465\n",
      "Current step: 844\n",
      "Mean reward: 5.9543127275776575\n",
      "Loss: 1.8052223920822144\n",
      "Current step: 845\n",
      "Mean reward: 5.954797841068484\n",
      "Loss: 1.7381260395050049\n",
      "Current step: 846\n",
      "Mean reward: 5.954797841068484\n",
      "Loss: 1.6699167490005493\n",
      "Current step: 847\n",
      "Mean reward: 5.955280040964774\n",
      "Loss: 5.679218769073486\n",
      "Current step: 848\n",
      "Mean reward: 5.955280040964774\n",
      "Loss: 5.433243751525879\n",
      "Current step: 849\n",
      "Mean reward: 5.955759353436533\n",
      "Loss: 4.661278247833252\n",
      "Current step: 850\n",
      "Mean reward: 5.955759353436533\n",
      "Loss: 5.78692102432251\n",
      "Current step: 851\n",
      "Mean reward: 5.956235804341296\n",
      "Loss: 3.9932167530059814\n",
      "Current step: 852\n",
      "Mean reward: 5.956235804341296\n",
      "Loss: 4.4428277015686035\n",
      "Current step: 853\n",
      "Mean reward: 5.956709419228771\n",
      "Loss: 1.818152666091919\n",
      "Current step: 854\n",
      "Mean reward: 5.956709419228771\n",
      "Loss: 3.7363955974578857\n",
      "Current step: 855\n",
      "Mean reward: 5.957180223345398\n",
      "Loss: 5.520371437072754\n",
      "Current step: 856\n",
      "Mean reward: 5.957180223345398\n",
      "Loss: 3.9363656044006348\n",
      "Current step: 857\n",
      "Mean reward: 5.957648241638851\n",
      "Loss: 3.6476545333862305\n",
      "Current step: 858\n",
      "Mean reward: 5.957648241638851\n",
      "Loss: 4.063959121704102\n",
      "Current step: 859\n",
      "Mean reward: 5.958113498762431\n",
      "Loss: 3.317681312561035\n",
      "Current step: 860\n",
      "Mean reward: 5.958113498762431\n",
      "Loss: 3.672961473464966\n",
      "Current step: 861\n",
      "Mean reward: 5.958576019079402\n",
      "Loss: 2.7235403060913086\n",
      "Current step: 862\n",
      "Mean reward: 5.958576019079402\n",
      "Loss: 3.188751220703125\n",
      "Current step: 863\n",
      "Mean reward: 5.95903582666724\n",
      "Loss: 2.144998550415039\n",
      "Current step: 864\n",
      "Mean reward: 5.95903582666724\n",
      "Loss: 3.0879311561584473\n",
      "Current step: 865\n",
      "Mean reward: 5.959492945321816\n",
      "Loss: 3.7875561714172363\n",
      "Current step: 866\n",
      "Mean reward: 5.959492945321816\n",
      "Loss: 4.356785774230957\n",
      "Current step: 867\n",
      "Mean reward: 5.959947398561498\n",
      "Loss: 6.708408832550049\n",
      "Current step: 868\n",
      "Mean reward: 5.959947398561498\n",
      "Loss: 5.4140167236328125\n",
      "Current step: 869\n",
      "Mean reward: 5.960399209631182\n",
      "Loss: 4.808709144592285\n",
      "Current step: 870\n",
      "Mean reward: 5.960399209631182\n",
      "Loss: 5.506557464599609\n",
      "Current step: 871\n",
      "Mean reward: 5.960848401506258\n",
      "Loss: 1.5807836055755615\n",
      "Current step: 872\n",
      "Mean reward: 5.960848401506258\n",
      "Loss: 3.6227939128875732\n",
      "Current step: 873\n",
      "Mean reward: 5.961294996896506\n",
      "Loss: 3.9675538539886475\n",
      "Current step: 874\n",
      "Mean reward: 5.961294996896506\n",
      "Loss: 4.576804161071777\n",
      "Current step: 875\n",
      "Mean reward: 5.961739018249924\n",
      "Loss: 6.104796886444092\n",
      "Current step: 876\n",
      "Mean reward: 5.961739018249924\n",
      "Loss: 5.1917009353637695\n",
      "Current step: 877\n",
      "Mean reward: 5.962180487756483\n",
      "Loss: 4.2731781005859375\n",
      "Current step: 878\n",
      "Mean reward: 5.962180487756483\n",
      "Loss: 3.9398436546325684\n",
      "Current step: 879\n",
      "Mean reward: 5.96261942735183\n",
      "Loss: 3.954404830932617\n",
      "Current step: 880\n",
      "Mean reward: 5.96261942735183\n",
      "Loss: 3.0372328758239746\n",
      "Current step: 881\n",
      "Mean reward: 5.963055858720916\n",
      "Loss: 4.719968795776367\n",
      "Current step: 882\n",
      "Mean reward: 5.963055858720916\n",
      "Loss: 5.415897369384766\n",
      "Current step: 883\n",
      "Mean reward: 5.963489803301577\n",
      "Loss: 2.6094160079956055\n",
      "Current step: 884\n",
      "Mean reward: 5.963489803301577\n",
      "Loss: 5.8409743309021\n",
      "Current step: 885\n",
      "Mean reward: 5.963921282288029\n",
      "Loss: 3.3176872730255127\n",
      "Current step: 886\n",
      "Mean reward: 5.963921282288029\n",
      "Loss: 2.2966675758361816\n",
      "Current step: 887\n",
      "Mean reward: 5.964350316634331\n",
      "Loss: 3.154700756072998\n",
      "Current step: 888\n",
      "Mean reward: 5.964350316634331\n",
      "Loss: 2.3622591495513916\n",
      "Current step: 889\n",
      "Mean reward: 5.964776927057771\n",
      "Loss: 3.9217708110809326\n",
      "Current step: 890\n",
      "Mean reward: 5.964776927057771\n",
      "Loss: 3.1783077716827393\n",
      "Current step: 891\n",
      "Mean reward: 5.965201134042207\n",
      "Loss: 3.1291630268096924\n",
      "Current step: 892\n",
      "Mean reward: 5.965201134042207\n",
      "Loss: 5.574833869934082\n",
      "Current step: 893\n",
      "Mean reward: 5.965622957841337\n",
      "Loss: 4.995718479156494\n",
      "Current step: 894\n",
      "Mean reward: 5.965622957841337\n",
      "Loss: 2.273280143737793\n",
      "Current step: 895\n",
      "Mean reward: 5.966042418481928\n",
      "Loss: 3.938823699951172\n",
      "Current step: 896\n",
      "Mean reward: 5.966042418481928\n",
      "Loss: 4.081545829772949\n",
      "Current step: 897\n",
      "Mean reward: 5.966459535766986\n",
      "Loss: 1.366905689239502\n",
      "Current step: 898\n",
      "Mean reward: 5.966459535766986\n",
      "Loss: 3.5261616706848145\n",
      "Current step: 899\n",
      "Mean reward: 5.966874329278867\n",
      "Loss: 3.652100086212158\n",
      "Current step: 900\n",
      "Mean reward: 5.966874329278867\n",
      "Loss: 4.25316858291626\n",
      "Current step: 901\n",
      "Mean reward: 5.96728681838235\n",
      "Loss: 3.7095165252685547\n",
      "Current step: 902\n",
      "Mean reward: 5.96728681838235\n",
      "Loss: 4.97746467590332\n",
      "Current step: 903\n",
      "Mean reward: 5.96769702222764\n",
      "Loss: 1.7649412155151367\n",
      "Current step: 904\n",
      "Mean reward: 5.96769702222764\n",
      "Loss: 3.832441806793213\n",
      "Current step: 905\n",
      "Mean reward: 5.9681049597533455\n",
      "Loss: 3.7367594242095947\n",
      "Current step: 906\n",
      "Mean reward: 5.9681049597533455\n",
      "Loss: 3.3367490768432617\n",
      "Current step: 907\n",
      "Mean reward: 5.968510649689375\n",
      "Loss: 2.9045252799987793\n",
      "Current step: 908\n",
      "Mean reward: 5.968510649689375\n",
      "Loss: 3.1001906394958496\n",
      "Current step: 909\n",
      "Mean reward: 5.968914110559823\n",
      "Loss: 2.8542330265045166\n",
      "Current step: 910\n",
      "Mean reward: 5.968914110559823\n",
      "Loss: 1.1330714225769043\n",
      "Current step: 911\n",
      "Mean reward: 5.969315360685775\n",
      "Loss: 3.345567226409912\n",
      "Current step: 912\n",
      "Mean reward: 5.969315360685775\n",
      "Loss: 2.4888036251068115\n",
      "Current step: 913\n",
      "Mean reward: 5.969714418188088\n",
      "Loss: 4.108074188232422\n",
      "Current step: 914\n",
      "Mean reward: 5.969714418188088\n",
      "Loss: 4.330833911895752\n",
      "Current step: 915\n",
      "Mean reward: 5.970111300990117\n",
      "Loss: 4.565922737121582\n",
      "Current step: 916\n",
      "Mean reward: 5.970111300990117\n",
      "Loss: 4.491287708282471\n",
      "Current step: 917\n",
      "Mean reward: 5.970506026820396\n",
      "Loss: 4.326107978820801\n",
      "Current step: 918\n",
      "Mean reward: 5.970506026820396\n",
      "Loss: 3.711740493774414\n",
      "Current step: 919\n",
      "Mean reward: 5.9708986132152795\n",
      "Loss: 3.8061797618865967\n",
      "Current step: 920\n",
      "Mean reward: 5.9708986132152795\n",
      "Loss: 2.703834056854248\n",
      "Current step: 921\n",
      "Mean reward: 5.971289077521542\n",
      "Loss: 5.476809024810791\n",
      "Current step: 922\n",
      "Mean reward: 5.971289077521542\n",
      "Loss: 4.908830642700195\n",
      "Current step: 923\n",
      "Mean reward: 5.97167743689893\n",
      "Loss: 5.363253116607666\n",
      "Current step: 924\n",
      "Mean reward: 5.97167743689893\n",
      "Loss: 3.9937024116516113\n",
      "Current step: 925\n",
      "Mean reward: 5.9720637083226755\n",
      "Loss: 4.219979286193848\n",
      "Current step: 926\n",
      "Mean reward: 5.9720637083226755\n",
      "Loss: 0.8387330770492554\n",
      "Current step: 927\n",
      "Mean reward: 5.9724479085859725\n",
      "Loss: 7.8572797775268555\n",
      "Current step: 928\n",
      "Mean reward: 5.9724479085859725\n",
      "Loss: 6.241062641143799\n",
      "Current step: 929\n",
      "Mean reward: 5.972830054302407\n",
      "Loss: 3.677649736404419\n",
      "Current step: 930\n",
      "Mean reward: 5.972830054302407\n",
      "Loss: 1.964339256286621\n",
      "Current step: 931\n",
      "Mean reward: 5.973210161908354\n",
      "Loss: 3.83235502243042\n",
      "Current step: 932\n",
      "Mean reward: 5.973210161908354\n",
      "Loss: 4.260993957519531\n",
      "Current step: 933\n",
      "Mean reward: 5.973588247665334\n",
      "Loss: 4.307692527770996\n",
      "Current step: 934\n",
      "Mean reward: 5.973588247665334\n",
      "Loss: 4.2463884353637695\n",
      "Current step: 935\n",
      "Mean reward: 5.973964327662328\n",
      "Loss: 4.550061225891113\n",
      "Current step: 936\n",
      "Mean reward: 5.973964327662328\n",
      "Loss: 3.131499767303467\n",
      "Current step: 937\n",
      "Mean reward: 5.97433841781807\n",
      "Loss: 4.429206848144531\n",
      "Current step: 938\n",
      "Mean reward: 5.97433841781807\n",
      "Loss: 4.129329204559326\n",
      "Current step: 939\n",
      "Mean reward: 5.974710533883279\n",
      "Loss: 2.7381319999694824\n",
      "Current step: 940\n",
      "Mean reward: 5.974710533883279\n",
      "Loss: 2.4872195720672607\n",
      "Current step: 941\n",
      "Mean reward: 5.975080691442882\n",
      "Loss: 3.035506010055542\n",
      "Current step: 942\n",
      "Mean reward: 5.975080691442882\n",
      "Loss: 2.4065561294555664\n",
      "Current step: 943\n",
      "Mean reward: 5.975448905918182\n",
      "Loss: 3.699824810028076\n",
      "Current step: 944\n",
      "Mean reward: 5.975448905918182\n",
      "Loss: 3.495382785797119\n",
      "Current step: 945\n",
      "Mean reward: 5.975815192569004\n",
      "Loss: 4.416647911071777\n",
      "Current step: 946\n",
      "Mean reward: 5.975815192569004\n",
      "Loss: 4.131266117095947\n",
      "Current step: 947\n",
      "Mean reward: 5.976179566495802\n",
      "Loss: 4.08316707611084\n",
      "Current step: 948\n",
      "Mean reward: 5.976179566495802\n",
      "Loss: 2.6529037952423096\n",
      "Current step: 949\n",
      "Mean reward: 5.976542042641732\n",
      "Loss: 5.690648078918457\n",
      "Current step: 950\n",
      "Mean reward: 5.976542042641732\n",
      "Loss: 4.125089645385742\n",
      "Current step: 951\n",
      "Mean reward: 5.976902635794695\n",
      "Loss: 3.860215663909912\n",
      "Current step: 952\n",
      "Mean reward: 5.976902635794695\n",
      "Loss: 3.155428886413574\n",
      "Current step: 953\n",
      "Mean reward: 5.977261360589352\n",
      "Loss: 3.2162327766418457\n",
      "Current step: 954\n",
      "Mean reward: 5.977261360589352\n",
      "Loss: 3.6067538261413574\n",
      "Current step: 955\n",
      "Mean reward: 5.977618231509102\n",
      "Loss: 2.481904983520508\n",
      "Current step: 956\n",
      "Mean reward: 5.977618231509102\n",
      "Loss: 3.7374744415283203\n",
      "Current step: 957\n",
      "Mean reward: 5.977973262888028\n",
      "Loss: 5.319113731384277\n",
      "Current step: 958\n",
      "Mean reward: 5.977973262888028\n",
      "Loss: 4.061339378356934\n",
      "Current step: 959\n",
      "Mean reward: 5.977973262888028\n",
      "Loss: 3.4714550971984863\n",
      "Current step: 960\n",
      "Mean reward: 5.977973262888028\n",
      "Loss: 2.524407386779785\n",
      "Current step: 961\n",
      "Mean reward: 5.991857993315981\n",
      "Loss: 4.103150367736816\n",
      "Current step: 962\n",
      "Mean reward: 5.991857993315981\n",
      "Loss: 3.3953685760498047\n",
      "Current step: 963\n",
      "Mean reward: 5.992174691811408\n",
      "Loss: 4.448261260986328\n",
      "Current step: 964\n",
      "Mean reward: 5.992174691811408\n",
      "Loss: 3.3646318912506104\n",
      "Current step: 965\n",
      "Mean reward: 5.9924897703656805\n",
      "Loss: 3.870654582977295\n",
      "Current step: 966\n",
      "Mean reward: 5.9924897703656805\n",
      "Loss: 3.892153263092041\n",
      "Current step: 967\n",
      "Mean reward: 5.992803241376311\n",
      "Loss: 3.5727555751800537\n",
      "Current step: 968\n",
      "Mean reward: 5.992803241376311\n",
      "Loss: 3.8527698516845703\n",
      "Current step: 969\n",
      "Mean reward: 5.9931151171146215\n",
      "Loss: 4.2726850509643555\n",
      "Current step: 970\n",
      "Mean reward: 5.9931151171146215\n",
      "Loss: 4.362485408782959\n",
      "Current step: 971\n",
      "Mean reward: 5.993425409727356\n",
      "Loss: 1.8481864929199219\n",
      "Current step: 972\n",
      "Mean reward: 5.993425409727356\n",
      "Loss: 2.8320908546447754\n",
      "Current step: 973\n",
      "Mean reward: 5.993734131238257\n",
      "Loss: 2.5564770698547363\n",
      "Current step: 974\n",
      "Mean reward: 5.993734131238257\n",
      "Loss: 4.146822929382324\n",
      "Current step: 975\n",
      "Mean reward: 5.994041293549604\n",
      "Loss: 2.888906240463257\n",
      "Current step: 976\n",
      "Mean reward: 5.994041293549604\n",
      "Loss: 3.2223658561706543\n",
      "Current step: 977\n",
      "Mean reward: 5.9943469084437675\n",
      "Loss: 2.385484218597412\n",
      "Current step: 978\n",
      "Mean reward: 5.9943469084437675\n",
      "Loss: 3.537916898727417\n",
      "Current step: 979\n",
      "Mean reward: 5.994650987584695\n",
      "Loss: 2.4436492919921875\n",
      "Current step: 980\n",
      "Mean reward: 5.994650987584695\n",
      "Loss: 4.077142715454102\n",
      "Current step: 981\n",
      "Mean reward: 5.994953542519401\n",
      "Loss: 2.752624988555908\n",
      "Current step: 982\n",
      "Mean reward: 5.994953542519401\n",
      "Loss: 2.444716215133667\n",
      "Current step: 983\n",
      "Mean reward: 5.995254584679434\n",
      "Loss: 3.2945921421051025\n",
      "Current step: 984\n",
      "Mean reward: 5.995254584679434\n",
      "Loss: 3.3546228408813477\n",
      "Current step: 985\n",
      "Mean reward: 5.995554125382309\n",
      "Loss: 2.9326441287994385\n",
      "Current step: 986\n",
      "Mean reward: 5.995554125382309\n",
      "Loss: 4.351859092712402\n",
      "Current step: 987\n",
      "Mean reward: 5.9958521758329315\n",
      "Loss: 3.0806498527526855\n",
      "Current step: 988\n",
      "Mean reward: 5.9958521758329315\n",
      "Loss: 2.278752565383911\n",
      "Current step: 989\n",
      "Mean reward: 5.99614874712499\n",
      "Loss: 4.485681533813477\n",
      "Current step: 990\n",
      "Mean reward: 5.99614874712499\n",
      "Loss: 5.241698741912842\n",
      "Current step: 991\n",
      "Mean reward: 5.9964438502423345\n",
      "Loss: 3.350799560546875\n",
      "Current step: 992\n",
      "Mean reward: 5.9964438502423345\n",
      "Loss: 4.623852252960205\n",
      "Current step: 993\n",
      "Mean reward: 5.996737496060335\n",
      "Loss: 1.9488682746887207\n",
      "Current step: 994\n",
      "Mean reward: 5.996737496060335\n",
      "Loss: 4.903539657592773\n",
      "Current step: 995\n",
      "Mean reward: 5.997029695347211\n",
      "Loss: 3.543642997741699\n",
      "Current step: 996\n",
      "Mean reward: 5.997029695347211\n",
      "Loss: 3.776799201965332\n",
      "Current step: 997\n",
      "Mean reward: 5.9973204587653575\n",
      "Loss: 3.233621120452881\n",
      "Current step: 998\n",
      "Mean reward: 5.9973204587653575\n",
      "Loss: 2.0187270641326904\n",
      "Current step: 999\n",
      "Mean reward: 5.997609796872631\n",
      "Loss: 4.362897872924805\n",
      "Current step: 1000\n",
      "Mean reward: 5.997609796872631\n",
      "Loss: 4.176482200622559\n",
      "Current step: 1001\n",
      "Mean reward: 5.997897720123632\n",
      "Loss: 5.598592281341553\n",
      "Current step: 1002\n",
      "Mean reward: 5.997897720123632\n",
      "Loss: 3.1023573875427246\n",
      "Current step: 1003\n",
      "Mean reward: 5.99818423887097\n",
      "Loss: 2.6819424629211426\n",
      "Current step: 1004\n",
      "Mean reward: 5.99818423887097\n",
      "Loss: 4.485332012176514\n",
      "Current step: 1005\n",
      "Mean reward: 5.998469363366498\n",
      "Loss: 2.97501277923584\n",
      "Current step: 1006\n",
      "Mean reward: 5.998469363366498\n",
      "Loss: 2.187424659729004\n",
      "Current step: 1007\n",
      "Mean reward: 5.998753103762532\n",
      "Loss: 3.4346704483032227\n",
      "Current step: 1008\n",
      "Mean reward: 5.998753103762532\n",
      "Loss: 4.197343826293945\n",
      "Current step: 1009\n",
      "Mean reward: 5.999035470113063\n",
      "Loss: 3.493412494659424\n",
      "Current step: 1010\n",
      "Mean reward: 5.999035470113063\n",
      "Loss: 3.1223373413085938\n",
      "Current step: 1011\n",
      "Mean reward: 5.999316472374947\n",
      "Loss: 2.653552532196045\n",
      "Current step: 1012\n",
      "Mean reward: 5.999316472374947\n",
      "Loss: 3.619575023651123\n",
      "Current step: 1013\n",
      "Mean reward: 5.999596120409061\n",
      "Loss: 3.848179817199707\n",
      "Current step: 1014\n",
      "Mean reward: 5.999596120409061\n",
      "Loss: 2.66212797164917\n",
      "Current step: 1015\n",
      "Mean reward: 5.999874423981473\n",
      "Loss: 3.1310644149780273\n",
      "Current step: 1016\n",
      "Mean reward: 5.999874423981473\n",
      "Loss: 2.6187005043029785\n",
      "Current step: 1017\n",
      "Mean reward: 6.000151392764569\n",
      "Loss: 2.9200944900512695\n",
      "Current step: 1018\n",
      "Mean reward: 6.000151392764569\n",
      "Loss: 3.430215835571289\n",
      "Current step: 1019\n",
      "Mean reward: 6.000427036338177\n",
      "Loss: 2.601693630218506\n",
      "Current step: 1020\n",
      "Mean reward: 6.000427036338177\n",
      "Loss: 2.5122389793395996\n",
      "Current step: 1021\n",
      "Mean reward: 6.000701364190668\n",
      "Loss: 3.2874233722686768\n",
      "Current step: 1022\n",
      "Mean reward: 6.000701364190668\n",
      "Loss: 2.4016072750091553\n",
      "Current step: 1023\n",
      "Mean reward: 6.0009743857200535\n",
      "Loss: 1.508253812789917\n",
      "Current step: 1024\n",
      "Mean reward: 6.0009743857200535\n",
      "Loss: 1.8662018775939941\n",
      "Current step: 1025\n",
      "Mean reward: 6.001246110235049\n",
      "Loss: 2.3671321868896484\n",
      "Current step: 1026\n",
      "Mean reward: 6.001246110235049\n",
      "Loss: 3.802426338195801\n",
      "Current step: 1027\n",
      "Mean reward: 6.001516546956131\n",
      "Loss: 5.744683265686035\n",
      "Current step: 1028\n",
      "Mean reward: 6.001516546956131\n",
      "Loss: 1.6990768909454346\n",
      "Current step: 1029\n",
      "Mean reward: 6.001785705016595\n",
      "Loss: 3.331127882003784\n",
      "Current step: 1030\n",
      "Mean reward: 6.001785705016595\n",
      "Loss: 3.696392774581909\n",
      "Current step: 1031\n",
      "Mean reward: 6.002053593463567\n",
      "Loss: 3.855834484100342\n",
      "Current step: 1032\n",
      "Mean reward: 6.002053593463567\n",
      "Loss: 1.9072288274765015\n",
      "Current step: 1033\n",
      "Mean reward: 6.0023202212590245\n",
      "Loss: 2.7395923137664795\n",
      "Current step: 1034\n",
      "Mean reward: 6.0023202212590245\n",
      "Loss: 5.686791896820068\n",
      "Current step: 1035\n",
      "Mean reward: 6.002585597280792\n",
      "Loss: 5.010984420776367\n",
      "Current step: 1036\n",
      "Mean reward: 6.002585597280792\n",
      "Loss: 4.020820617675781\n",
      "Current step: 1037\n",
      "Mean reward: 6.002849730323536\n",
      "Loss: 4.152607440948486\n",
      "Current step: 1038\n",
      "Mean reward: 6.002849730323536\n",
      "Loss: 2.964484453201294\n",
      "Current step: 1039\n",
      "Mean reward: 6.003112629099725\n",
      "Loss: 4.495828151702881\n",
      "Current step: 1040\n",
      "Mean reward: 6.003112629099725\n",
      "Loss: 4.040334224700928\n",
      "Current step: 1041\n",
      "Mean reward: 6.003374302240593\n",
      "Loss: 5.747952938079834\n",
      "Current step: 1042\n",
      "Mean reward: 6.003374302240593\n",
      "Loss: 4.387831211090088\n",
      "Current step: 1043\n",
      "Mean reward: 6.003634758297087\n",
      "Loss: 3.2286901473999023\n",
      "Current step: 1044\n",
      "Mean reward: 6.003634758297087\n",
      "Loss: 3.7046542167663574\n",
      "Current step: 1045\n",
      "Mean reward: 6.003894005740787\n",
      "Loss: 5.101428508758545\n",
      "Current step: 1046\n",
      "Mean reward: 6.003894005740787\n",
      "Loss: 3.337599754333496\n",
      "Current step: 1047\n",
      "Mean reward: 6.0041520529648436\n",
      "Loss: 2.0560226440429688\n",
      "Current step: 1048\n",
      "Mean reward: 6.0041520529648436\n",
      "Loss: 1.842858910560608\n",
      "Current step: 1049\n",
      "Mean reward: 6.00440890828486\n",
      "Loss: 3.410085678100586\n",
      "Current step: 1050\n",
      "Mean reward: 6.00440890828486\n",
      "Loss: 1.0682607889175415\n",
      "Current step: 1051\n",
      "Mean reward: 6.00440890828486\n",
      "Loss: 4.982077598571777\n",
      "Current step: 1052\n",
      "Mean reward: 6.00440890828486\n",
      "Loss: 6.642582893371582\n",
      "Current step: 1053\n",
      "Mean reward: 6.016793066098401\n",
      "Loss: 3.043896436691284\n",
      "Current step: 1054\n",
      "Mean reward: 6.016793066098401\n",
      "Loss: 4.311473846435547\n",
      "Current step: 1055\n",
      "Mean reward: 6.017019680674112\n",
      "Loss: 4.558135032653809\n",
      "Current step: 1056\n",
      "Mean reward: 6.017019680674112\n",
      "Loss: 2.8373584747314453\n",
      "Current step: 1057\n",
      "Mean reward: 6.017245255733421\n",
      "Loss: 2.7930448055267334\n",
      "Current step: 1058\n",
      "Mean reward: 6.017245255733421\n",
      "Loss: 5.172033786773682\n",
      "Current step: 1059\n",
      "Mean reward: 6.017469798412593\n",
      "Loss: 2.7865965366363525\n",
      "Current step: 1060\n",
      "Mean reward: 6.017469798412593\n",
      "Loss: 3.35835862159729\n",
      "Current step: 1061\n",
      "Mean reward: 6.017693315782731\n",
      "Loss: 1.4256893396377563\n",
      "Current step: 1062\n",
      "Mean reward: 6.017693315782731\n",
      "Loss: 3.9652786254882812\n",
      "Current step: 1063\n",
      "Mean reward: 6.017915814850498\n",
      "Loss: 2.3607795238494873\n",
      "Current step: 1064\n",
      "Mean reward: 6.017915814850498\n",
      "Loss: 2.079479694366455\n",
      "Current step: 1065\n",
      "Mean reward: 6.018137302558866\n",
      "Loss: 5.473529815673828\n",
      "Current step: 1066\n",
      "Mean reward: 6.018137302558866\n",
      "Loss: 4.301912784576416\n",
      "Current step: 1067\n",
      "Mean reward: 6.018357785787831\n",
      "Loss: 3.495467185974121\n",
      "Current step: 1068\n",
      "Mean reward: 6.018357785787831\n",
      "Loss: 2.2252070903778076\n",
      "Current step: 1069\n",
      "Mean reward: 6.018577271355127\n",
      "Loss: 2.31457257270813\n",
      "Current step: 1070\n",
      "Mean reward: 6.018577271355127\n",
      "Loss: 4.712803840637207\n",
      "Current step: 1071\n",
      "Mean reward: 6.018795766016925\n",
      "Loss: 2.878817558288574\n",
      "Current step: 1072\n",
      "Mean reward: 6.018795766016925\n",
      "Loss: 1.0364104509353638\n",
      "Current step: 1073\n",
      "Mean reward: 6.019013276468538\n",
      "Loss: 4.447098731994629\n",
      "Current step: 1074\n",
      "Mean reward: 6.019013276468538\n",
      "Loss: 2.802680492401123\n",
      "Current step: 1075\n",
      "Mean reward: 6.019229809345086\n",
      "Loss: 3.9035515785217285\n",
      "Current step: 1076\n",
      "Mean reward: 6.019229809345086\n",
      "Loss: 3.4016387462615967\n",
      "Current step: 1077\n",
      "Mean reward: 6.0194453712221865\n",
      "Loss: 3.4081737995147705\n",
      "Current step: 1078\n",
      "Mean reward: 6.0194453712221865\n",
      "Loss: 4.441043376922607\n",
      "Current step: 1079\n",
      "Mean reward: 6.019659968616618\n",
      "Loss: 3.3549673557281494\n",
      "Current step: 1080\n",
      "Mean reward: 6.019659968616618\n",
      "Loss: 3.919600486755371\n",
      "Current step: 1081\n",
      "Mean reward: 6.019873607986966\n",
      "Loss: 3.285634994506836\n",
      "Current step: 1082\n",
      "Mean reward: 6.019873607986966\n",
      "Loss: 1.9936212301254272\n",
      "Current step: 1083\n",
      "Mean reward: 6.020086295734283\n",
      "Loss: 2.194014549255371\n",
      "Current step: 1084\n",
      "Mean reward: 6.020086295734283\n",
      "Loss: 4.095056056976318\n",
      "Current step: 1085\n",
      "Mean reward: 6.020298038202723\n",
      "Loss: 2.446106195449829\n",
      "Current step: 1086\n",
      "Mean reward: 6.020298038202723\n",
      "Loss: 2.0054545402526855\n",
      "Current step: 1087\n",
      "Mean reward: 6.020508841680173\n",
      "Loss: 2.420452117919922\n",
      "Current step: 1088\n",
      "Mean reward: 6.020508841680173\n",
      "Loss: 2.367504119873047\n",
      "Current step: 1089\n",
      "Mean reward: 6.020718712398873\n",
      "Loss: 3.7514123916625977\n",
      "Current step: 1090\n",
      "Mean reward: 6.020718712398873\n",
      "Loss: 5.054861068725586\n",
      "Current step: 1091\n",
      "Mean reward: 6.020927656536032\n",
      "Loss: 3.616556406021118\n",
      "Current step: 1092\n",
      "Mean reward: 6.020927656536032\n",
      "Loss: 2.6976404190063477\n",
      "Current step: 1093\n",
      "Mean reward: 6.021135680214439\n",
      "Loss: 5.021173000335693\n",
      "Current step: 1094\n",
      "Mean reward: 6.021135680214439\n",
      "Loss: 1.7976469993591309\n",
      "Current step: 1095\n",
      "Mean reward: 6.021342789503049\n",
      "Loss: 1.8038893938064575\n",
      "Current step: 1096\n",
      "Mean reward: 6.021342789503049\n",
      "Loss: 2.425554037094116\n",
      "Current step: 1097\n",
      "Mean reward: 6.021548990417589\n",
      "Loss: 4.682845592498779\n",
      "Current step: 1098\n",
      "Mean reward: 6.021548990417589\n",
      "Loss: 4.254208564758301\n",
      "Current step: 1099\n",
      "Mean reward: 6.021754288921122\n",
      "Loss: 2.3889548778533936\n",
      "Current step: 1100\n",
      "Mean reward: 6.021754288921122\n",
      "Loss: 2.471461772918701\n",
      "Current step: 1101\n",
      "Mean reward: 6.02195869092464\n",
      "Loss: 4.2862467765808105\n",
      "Current step: 1102\n",
      "Mean reward: 6.02195869092464\n",
      "Loss: 3.258981704711914\n",
      "Current step: 1103\n",
      "Mean reward: 6.022162202287619\n",
      "Loss: 1.7732446193695068\n",
      "Current step: 1104\n",
      "Mean reward: 6.022162202287619\n",
      "Loss: 3.645894765853882\n",
      "Current step: 1105\n",
      "Mean reward: 6.022364828818588\n",
      "Loss: 2.509103536605835\n",
      "Current step: 1106\n",
      "Mean reward: 6.022364828818588\n",
      "Loss: 0.8319615721702576\n",
      "Current step: 1107\n",
      "Mean reward: 6.022566576275667\n",
      "Loss: 2.7813658714294434\n",
      "Current step: 1108\n",
      "Mean reward: 6.022566576275667\n",
      "Loss: 4.691381931304932\n",
      "Current step: 1109\n",
      "Mean reward: 6.022767450367131\n",
      "Loss: 2.5625452995300293\n",
      "Current step: 1110\n",
      "Mean reward: 6.022767450367131\n",
      "Loss: 2.872819185256958\n",
      "Current step: 1111\n",
      "Mean reward: 6.022767450367131\n",
      "Loss: 3.841867685317993\n",
      "Current step: 1112\n",
      "Mean reward: 6.022767450367131\n",
      "Loss: 3.048067569732666\n",
      "Current step: 1113\n",
      "Mean reward: 6.016703749900278\n",
      "Loss: 3.7121660709381104\n",
      "Current step: 1114\n",
      "Mean reward: 6.016703749900278\n",
      "Loss: 3.8795690536499023\n",
      "Current step: 1115\n",
      "Mean reward: 6.016916393556813\n",
      "Loss: 5.1902265548706055\n",
      "Current step: 1116\n",
      "Mean reward: 6.016916393556813\n",
      "Loss: 3.121487617492676\n",
      "Current step: 1117\n",
      "Mean reward: 6.017128122616976\n",
      "Loss: 2.5223498344421387\n",
      "Current step: 1118\n",
      "Mean reward: 6.017128122616976\n",
      "Loss: 3.5096774101257324\n",
      "Current step: 1119\n",
      "Mean reward: 6.017338942968726\n",
      "Loss: 2.4708096981048584\n",
      "Current step: 1120\n",
      "Mean reward: 6.017338942968726\n",
      "Loss: 4.449728965759277\n",
      "Current step: 1121\n",
      "Mean reward: 6.01754886044959\n",
      "Loss: 2.2988498210906982\n",
      "Current step: 1122\n",
      "Mean reward: 6.01754886044959\n",
      "Loss: 4.693105697631836\n",
      "Current step: 1123\n",
      "Mean reward: 6.017757880847203\n",
      "Loss: 3.791537284851074\n",
      "Current step: 1124\n",
      "Mean reward: 6.017757880847203\n",
      "Loss: 4.172469615936279\n",
      "Current step: 1125\n",
      "Mean reward: 6.017966009899837\n",
      "Loss: 2.7389426231384277\n",
      "Current step: 1126\n",
      "Mean reward: 6.017966009899837\n",
      "Loss: 2.4787919521331787\n",
      "Current step: 1127\n",
      "Mean reward: 6.018173253296927\n",
      "Loss: 3.1472294330596924\n",
      "Current step: 1128\n",
      "Mean reward: 6.018173253296927\n",
      "Loss: 3.214235305786133\n",
      "Current step: 1129\n",
      "Mean reward: 6.018379616679593\n",
      "Loss: 3.855107307434082\n",
      "Current step: 1130\n",
      "Mean reward: 6.018379616679593\n",
      "Loss: 2.8057408332824707\n",
      "Current step: 1131\n",
      "Mean reward: 6.018585105641146\n",
      "Loss: 2.558248281478882\n",
      "Current step: 1132\n",
      "Mean reward: 6.018585105641146\n",
      "Loss: 3.2255027294158936\n",
      "Current step: 1133\n",
      "Mean reward: 6.018789725727598\n",
      "Loss: 4.215837001800537\n",
      "Current step: 1134\n",
      "Mean reward: 6.018789725727598\n",
      "Loss: 1.6828421354293823\n",
      "Current step: 1135\n",
      "Mean reward: 6.018993482438156\n",
      "Loss: 2.9792747497558594\n",
      "Current step: 1136\n",
      "Mean reward: 6.018993482438156\n",
      "Loss: 4.215744495391846\n",
      "Current step: 1137\n",
      "Mean reward: 6.019196381225723\n",
      "Loss: 3.2249562740325928\n",
      "Current step: 1138\n",
      "Mean reward: 6.019196381225723\n",
      "Loss: 4.870008945465088\n",
      "Current step: 1139\n",
      "Mean reward: 6.019398427497375\n",
      "Loss: 2.317157745361328\n",
      "Current step: 1140\n",
      "Mean reward: 6.019398427497375\n",
      "Loss: 1.179251790046692\n",
      "Current step: 1141\n",
      "Mean reward: 6.019599626614849\n",
      "Loss: 2.221550226211548\n",
      "Current step: 1142\n",
      "Mean reward: 6.019599626614849\n",
      "Loss: 3.376295328140259\n",
      "Current step: 1143\n",
      "Mean reward: 6.019799983895012\n",
      "Loss: 3.7500393390655518\n",
      "Current step: 1144\n",
      "Mean reward: 6.019799983895012\n",
      "Loss: 5.058916091918945\n",
      "Current step: 1145\n",
      "Mean reward: 6.01999950461033\n",
      "Loss: 4.188027381896973\n",
      "Current step: 1146\n",
      "Mean reward: 6.01999950461033\n",
      "Loss: 2.4613142013549805\n",
      "Current step: 1147\n",
      "Mean reward: 6.0201981939893345\n",
      "Loss: 2.945831537246704\n",
      "Current step: 1148\n",
      "Mean reward: 6.0201981939893345\n",
      "Loss: 3.7117433547973633\n",
      "Current step: 1149\n",
      "Mean reward: 6.0203960572170745\n",
      "Loss: 3.8101940155029297\n",
      "Current step: 1150\n",
      "Mean reward: 6.0203960572170745\n",
      "Loss: 4.489400863647461\n",
      "Current step: 1151\n",
      "Mean reward: 6.0205930994355725\n",
      "Loss: 2.9487242698669434\n",
      "Current step: 1152\n",
      "Mean reward: 6.0205930994355725\n",
      "Loss: 1.796342134475708\n",
      "Current step: 1153\n",
      "Mean reward: 6.020789325744261\n",
      "Loss: 0.6906270384788513\n",
      "Current step: 1154\n",
      "Mean reward: 6.020789325744261\n",
      "Loss: 2.365373373031616\n",
      "Current step: 1155\n",
      "Mean reward: 6.020984741200435\n",
      "Loss: 3.482365369796753\n",
      "Current step: 1156\n",
      "Mean reward: 6.020984741200435\n",
      "Loss: 3.6551990509033203\n",
      "Current step: 1157\n",
      "Mean reward: 6.0211793508196765\n",
      "Loss: 3.2530324459075928\n",
      "Current step: 1158\n",
      "Mean reward: 6.0211793508196765\n",
      "Loss: 2.889873743057251\n",
      "Current step: 1159\n",
      "Mean reward: 6.021373159576287\n",
      "Loss: 1.626675009727478\n",
      "Current step: 1160\n",
      "Mean reward: 6.021373159576287\n",
      "Loss: 4.505170822143555\n",
      "Current step: 1161\n",
      "Mean reward: 6.021566172403712\n",
      "Loss: 3.6528565883636475\n",
      "Current step: 1162\n",
      "Mean reward: 6.021566172403712\n",
      "Loss: 3.4464502334594727\n",
      "Current step: 1163\n",
      "Mean reward: 6.0217583941949595\n",
      "Loss: 2.8465616703033447\n",
      "Current step: 1164\n",
      "Mean reward: 6.0217583941949595\n",
      "Loss: 4.09512996673584\n",
      "Current step: 1165\n",
      "Mean reward: 6.021949829803011\n",
      "Loss: 3.924502372741699\n",
      "Current step: 1166\n",
      "Mean reward: 6.021949829803011\n",
      "Loss: 5.099291801452637\n",
      "Current step: 1167\n",
      "Mean reward: 6.022140484041235\n",
      "Loss: 2.2260849475860596\n",
      "Current step: 1168\n",
      "Mean reward: 6.022140484041235\n",
      "Loss: 4.398895740509033\n",
      "Current step: 1169\n",
      "Mean reward: 6.0223303616837836\n",
      "Loss: 2.377793312072754\n",
      "Current step: 1170\n",
      "Mean reward: 6.0223303616837836\n",
      "Loss: 1.5967121124267578\n",
      "Current step: 1171\n",
      "Mean reward: 6.022519467465996\n",
      "Loss: 2.032076120376587\n",
      "Current step: 1172\n",
      "Mean reward: 6.022519467465996\n",
      "Loss: 1.8197729587554932\n",
      "Current step: 1173\n",
      "Mean reward: 6.022707806084791\n",
      "Loss: 3.274230480194092\n",
      "Current step: 1174\n",
      "Mean reward: 6.022707806084791\n",
      "Loss: 3.72493577003479\n",
      "Current step: 1175\n",
      "Mean reward: 6.022895382199059\n",
      "Loss: 2.650059223175049\n",
      "Current step: 1176\n",
      "Mean reward: 6.022895382199059\n",
      "Loss: 2.7152786254882812\n",
      "Current step: 1177\n",
      "Mean reward: 6.023082200430035\n",
      "Loss: 3.0077731609344482\n",
      "Current step: 1178\n",
      "Mean reward: 6.023082200430035\n",
      "Loss: 2.949321985244751\n",
      "Current step: 1179\n",
      "Mean reward: 6.023268265361694\n",
      "Loss: 4.255681991577148\n",
      "Current step: 1180\n",
      "Mean reward: 6.023268265361694\n",
      "Loss: 2.817202568054199\n",
      "Current step: 1181\n",
      "Mean reward: 6.023453581541111\n",
      "Loss: 1.4866005182266235\n",
      "Current step: 1182\n",
      "Mean reward: 6.023453581541111\n",
      "Loss: 2.208677053451538\n",
      "Current step: 1183\n",
      "Mean reward: 6.023638153478845\n",
      "Loss: 3.3298776149749756\n",
      "Current step: 1184\n",
      "Mean reward: 6.023638153478845\n",
      "Loss: 3.227536201477051\n",
      "Current step: 1185\n",
      "Mean reward: 6.023821985649294\n",
      "Loss: 2.215547800064087\n",
      "Current step: 1186\n",
      "Mean reward: 6.023821985649294\n",
      "Loss: 3.160907506942749\n",
      "Current step: 1187\n",
      "Mean reward: 6.024005082491059\n",
      "Loss: 3.29140305519104\n",
      "Current step: 1188\n",
      "Mean reward: 6.024005082491059\n",
      "Loss: 3.4512267112731934\n",
      "Current step: 1189\n",
      "Mean reward: 6.024187448407311\n",
      "Loss: 4.289567470550537\n",
      "Current step: 1190\n",
      "Mean reward: 6.024187448407311\n",
      "Loss: 3.94439697265625\n",
      "Current step: 1191\n",
      "Mean reward: 6.024369087766125\n",
      "Loss: 5.526871204376221\n",
      "Current step: 1192\n",
      "Mean reward: 6.024369087766125\n",
      "Loss: 2.3078670501708984\n",
      "Current step: 1193\n",
      "Mean reward: 6.024550004900849\n",
      "Loss: 2.7862939834594727\n",
      "Current step: 1194\n",
      "Mean reward: 6.024550004900849\n",
      "Loss: 2.893242120742798\n",
      "Current step: 1195\n",
      "Mean reward: 6.024730204110436\n",
      "Loss: 2.758082866668701\n",
      "Current step: 1196\n",
      "Mean reward: 6.024730204110436\n",
      "Loss: 2.8051445484161377\n",
      "Current step: 1197\n",
      "Mean reward: 6.024909689659786\n",
      "Loss: 3.462564468383789\n",
      "Current step: 1198\n",
      "Mean reward: 6.024909689659786\n",
      "Loss: 3.8030495643615723\n",
      "Current step: 1199\n",
      "Mean reward: 6.025088465780088\n",
      "Loss: 2.447725296020508\n",
      "Current step: 1200\n",
      "Mean reward: 6.025088465780088\n",
      "Loss: 2.6927342414855957\n",
      "Current step: 1201\n",
      "Mean reward: 6.025266536669147\n",
      "Loss: 2.6417689323425293\n",
      "Current step: 1202\n",
      "Mean reward: 6.025266536669147\n",
      "Loss: 1.4809978008270264\n",
      "Current step: 1203\n",
      "Mean reward: 6.025443906491711\n",
      "Loss: 5.249924182891846\n",
      "Current step: 1204\n",
      "Mean reward: 6.025443906491711\n",
      "Loss: 1.6516714096069336\n",
      "Current step: 1205\n",
      "Mean reward: 6.025620579379807\n",
      "Loss: 3.108210325241089\n",
      "Current step: 1206\n",
      "Mean reward: 6.025620579379807\n",
      "Loss: 1.8029392957687378\n",
      "Current step: 1207\n",
      "Mean reward: 6.025796559433048\n",
      "Loss: 3.1150968074798584\n",
      "Current step: 1208\n",
      "Mean reward: 6.025796559433048\n",
      "Loss: 2.6863646507263184\n",
      "Current step: 1209\n",
      "Mean reward: 6.025971850718957\n",
      "Loss: 2.4010345935821533\n",
      "Current step: 1210\n",
      "Mean reward: 6.025971850718957\n",
      "Loss: 3.3563528060913086\n",
      "Current step: 1211\n",
      "Mean reward: 6.026146457273281\n",
      "Loss: 2.5872535705566406\n",
      "Current step: 1212\n",
      "Mean reward: 6.026146457273281\n",
      "Loss: 2.120366334915161\n",
      "Current step: 1213\n",
      "Mean reward: 6.026320383100296\n",
      "Loss: 3.8930885791778564\n",
      "Current step: 1214\n",
      "Mean reward: 6.026320383100296\n",
      "Loss: 3.3469183444976807\n",
      "Current step: 1215\n",
      "Mean reward: 6.026493632173122\n",
      "Loss: 3.0503129959106445\n",
      "Current step: 1216\n",
      "Mean reward: 6.026493632173122\n",
      "Loss: 2.6178250312805176\n",
      "Current step: 1217\n",
      "Mean reward: 6.026666208434013\n",
      "Loss: 2.2835471630096436\n",
      "Current step: 1218\n",
      "Mean reward: 6.026666208434013\n",
      "Loss: 3.5197765827178955\n",
      "Current step: 1219\n",
      "Mean reward: 6.026838115794669\n",
      "Loss: 1.4682714939117432\n",
      "Current step: 1220\n",
      "Mean reward: 6.026838115794669\n",
      "Loss: 2.5600552558898926\n",
      "Current step: 1221\n",
      "Mean reward: 6.027009358136522\n",
      "Loss: 4.390285491943359\n",
      "Current step: 1222\n",
      "Mean reward: 6.027009358136522\n",
      "Loss: 0.6806308031082153\n",
      "Current step: 1223\n",
      "Mean reward: 6.02717993931103\n",
      "Loss: 4.265100955963135\n",
      "Current step: 1224\n",
      "Mean reward: 6.02717993931103\n",
      "Loss: 3.6153225898742676\n",
      "Current step: 1225\n",
      "Mean reward: 6.027349863139974\n",
      "Loss: 3.0924131870269775\n",
      "Current step: 1226\n",
      "Mean reward: 6.027349863139974\n",
      "Loss: 2.1865367889404297\n",
      "Current step: 1227\n",
      "Mean reward: 6.027519133415729\n",
      "Loss: 2.876296281814575\n",
      "Current step: 1228\n",
      "Mean reward: 6.027519133415729\n",
      "Loss: 2.913465738296509\n",
      "Current step: 1229\n",
      "Mean reward: 6.0276877539015565\n",
      "Loss: 1.9712791442871094\n",
      "Current step: 1230\n",
      "Mean reward: 6.0276877539015565\n",
      "Loss: 3.4340147972106934\n",
      "Current step: 1231\n",
      "Mean reward: 6.027855728331884\n",
      "Loss: 3.054842472076416\n",
      "Current step: 1232\n",
      "Mean reward: 6.027855728331884\n",
      "Loss: 4.322237491607666\n",
      "Current step: 1233\n",
      "Mean reward: 6.028023060412575\n",
      "Loss: 5.504980087280273\n",
      "Current step: 1234\n",
      "Mean reward: 6.028023060412575\n",
      "Loss: 3.403435468673706\n",
      "Current step: 1235\n",
      "Mean reward: 6.0281897538212\n",
      "Loss: 1.6776795387268066\n",
      "Current step: 1236\n",
      "Mean reward: 6.0281897538212\n",
      "Loss: 3.662252902984619\n",
      "Current step: 1237\n",
      "Mean reward: 6.028355812207317\n",
      "Loss: 2.845393180847168\n",
      "Current step: 1238\n",
      "Mean reward: 6.028355812207317\n",
      "Loss: 1.5187633037567139\n",
      "Current step: 1239\n",
      "Mean reward: 6.028521239192726\n",
      "Loss: 3.114140272140503\n",
      "Current step: 1240\n",
      "Mean reward: 6.028521239192726\n",
      "Loss: 2.5549681186676025\n",
      "Current step: 1241\n",
      "Mean reward: 6.028686038371739\n",
      "Loss: 2.3527181148529053\n",
      "Current step: 1242\n",
      "Mean reward: 6.028686038371739\n",
      "Loss: 1.460817575454712\n",
      "Current step: 1243\n",
      "Mean reward: 6.028850213311436\n",
      "Loss: 3.064561367034912\n",
      "Current step: 1244\n",
      "Mean reward: 6.028850213311436\n",
      "Loss: 1.4924633502960205\n",
      "Current step: 1245\n",
      "Mean reward: 6.02901376755193\n",
      "Loss: 2.255460023880005\n",
      "Current step: 1246\n",
      "Mean reward: 6.02901376755193\n",
      "Loss: 3.3637609481811523\n",
      "Current step: 1247\n",
      "Mean reward: 6.02917670460661\n",
      "Loss: 2.549821615219116\n",
      "Current step: 1248\n",
      "Mean reward: 6.02917670460661\n",
      "Loss: 3.4482836723327637\n",
      "Current step: 1249\n",
      "Mean reward: 6.029339027962402\n",
      "Loss: 3.1083295345306396\n",
      "Current step: 1250\n",
      "Mean reward: 6.029339027962402\n",
      "Loss: 3.595457077026367\n",
      "Current step: 1251\n",
      "Mean reward: 6.0295007410800165\n",
      "Loss: 3.2783684730529785\n",
      "Current step: 1252\n",
      "Mean reward: 6.0295007410800165\n",
      "Loss: 2.38535475730896\n",
      "Current step: 1253\n",
      "Mean reward: 6.0295007410800165\n",
      "Loss: 1.7687089443206787\n",
      "Current step: 1254\n",
      "Mean reward: 6.0295007410800165\n",
      "Loss: 4.024315357208252\n",
      "Current step: 1255\n",
      "Mean reward: 6.039537575335704\n",
      "Loss: 3.519487142562866\n",
      "Current step: 1256\n",
      "Mean reward: 6.039537575335704\n",
      "Loss: 3.398209571838379\n",
      "Current step: 1257\n",
      "Mean reward: 6.039679584382889\n",
      "Loss: 3.514178514480591\n",
      "Current step: 1258\n",
      "Mean reward: 6.039679584382889\n",
      "Loss: 3.76345157623291\n",
      "Current step: 1259\n",
      "Mean reward: 6.039821062555131\n",
      "Loss: 3.4638068675994873\n",
      "Current step: 1260\n",
      "Mean reward: 6.039821062555131\n",
      "Loss: 3.653646469116211\n",
      "Current step: 1261\n",
      "Mean reward: 6.039962012823745\n",
      "Loss: 2.9677886962890625\n",
      "Current step: 1262\n",
      "Mean reward: 6.039962012823745\n",
      "Loss: 3.5186643600463867\n",
      "Current step: 1263\n",
      "Mean reward: 6.040102438137913\n",
      "Loss: 3.5315847396850586\n",
      "Current step: 1264\n",
      "Mean reward: 6.040102438137913\n",
      "Loss: 2.880603790283203\n",
      "Current step: 1265\n",
      "Mean reward: 6.040242341424892\n",
      "Loss: 2.5026450157165527\n",
      "Current step: 1266\n",
      "Mean reward: 6.040242341424892\n",
      "Loss: 1.7080858945846558\n",
      "Current step: 1267\n",
      "Mean reward: 6.040381725590213\n",
      "Loss: 2.1680397987365723\n",
      "Current step: 1268\n",
      "Mean reward: 6.040381725590213\n",
      "Loss: 2.9433553218841553\n",
      "Current step: 1269\n",
      "Mean reward: 6.040520593517882\n",
      "Loss: 2.3149473667144775\n",
      "Current step: 1270\n",
      "Mean reward: 6.040520593517882\n",
      "Loss: 3.156181812286377\n",
      "Current step: 1271\n",
      "Mean reward: 6.04065894807059\n",
      "Loss: 3.434246301651001\n",
      "Current step: 1272\n",
      "Mean reward: 6.04065894807059\n",
      "Loss: 2.6484508514404297\n",
      "Current step: 1273\n",
      "Mean reward: 6.040796792089893\n",
      "Loss: 3.2432453632354736\n",
      "Current step: 1274\n",
      "Mean reward: 6.040796792089893\n",
      "Loss: 3.275886058807373\n",
      "Current step: 1275\n",
      "Mean reward: 6.040934128396416\n",
      "Loss: 2.5547449588775635\n",
      "Current step: 1276\n",
      "Mean reward: 6.040934128396416\n",
      "Loss: 2.03739333152771\n",
      "Current step: 1277\n",
      "Mean reward: 6.041070959790049\n",
      "Loss: 2.1541850566864014\n",
      "Current step: 1278\n",
      "Mean reward: 6.041070959790049\n",
      "Loss: 2.938889980316162\n",
      "Current step: 1279\n",
      "Mean reward: 6.041207289050126\n",
      "Loss: 2.908749580383301\n",
      "Current step: 1280\n",
      "Mean reward: 6.041207289050126\n",
      "Loss: 2.834805965423584\n",
      "Current step: 1281\n",
      "Mean reward: 6.041343118935625\n",
      "Loss: 2.799316167831421\n",
      "Current step: 1282\n",
      "Mean reward: 6.041343118935625\n",
      "Loss: 1.8151181936264038\n",
      "Current step: 1283\n",
      "Mean reward: 6.041478452185345\n",
      "Loss: 4.677628993988037\n",
      "Current step: 1284\n",
      "Mean reward: 6.041478452185345\n",
      "Loss: 3.0576062202453613\n",
      "Current step: 1285\n",
      "Mean reward: 6.041613291518095\n",
      "Loss: 1.8178186416625977\n",
      "Current step: 1286\n",
      "Mean reward: 6.041613291518095\n",
      "Loss: 3.4101734161376953\n",
      "Current step: 1287\n",
      "Mean reward: 6.0417476396328755\n",
      "Loss: 3.0530126094818115\n",
      "Current step: 1288\n",
      "Mean reward: 6.0417476396328755\n",
      "Loss: 0.9853630065917969\n",
      "Current step: 1289\n",
      "Mean reward: 6.041881499209056\n",
      "Loss: 2.793045997619629\n",
      "Current step: 1290\n",
      "Mean reward: 6.041881499209056\n",
      "Loss: 3.5436551570892334\n",
      "Current step: 1291\n",
      "Mean reward: 6.042014872906559\n",
      "Loss: 2.0111234188079834\n",
      "Current step: 1292\n",
      "Mean reward: 6.042014872906559\n",
      "Loss: 1.643559217453003\n",
      "Current step: 1293\n",
      "Mean reward: 6.042147763366025\n",
      "Loss: 4.311907768249512\n",
      "Current step: 1294\n",
      "Mean reward: 6.042147763366025\n",
      "Loss: 1.50984787940979\n",
      "Current step: 1295\n",
      "Mean reward: 6.042280173209003\n",
      "Loss: 1.5050243139266968\n",
      "Current step: 1296\n",
      "Mean reward: 6.042280173209003\n",
      "Loss: 2.418030261993408\n",
      "Current step: 1297\n",
      "Mean reward: 6.042412105038107\n",
      "Loss: 4.093106269836426\n",
      "Current step: 1298\n",
      "Mean reward: 6.042412105038107\n",
      "Loss: 4.272958278656006\n",
      "Current step: 1299\n",
      "Mean reward: 6.042543561437196\n",
      "Loss: 2.3022897243499756\n",
      "Current step: 1300\n",
      "Mean reward: 6.042543561437196\n",
      "Loss: 2.6087605953216553\n",
      "Current step: 1301\n",
      "Mean reward: 6.042674544971539\n",
      "Loss: 3.4653162956237793\n",
      "Current step: 1302\n",
      "Mean reward: 6.042674544971539\n",
      "Loss: 3.1482326984405518\n",
      "Current step: 1303\n",
      "Mean reward: 6.042805058187986\n",
      "Loss: 1.7392711639404297\n",
      "Current step: 1304\n",
      "Mean reward: 6.042805058187986\n",
      "Loss: 1.5002715587615967\n",
      "Current step: 1305\n",
      "Mean reward: 6.042935103615127\n",
      "Loss: 2.3735170364379883\n",
      "Current step: 1306\n",
      "Mean reward: 6.042935103615127\n",
      "Loss: 2.0148730278015137\n",
      "Current step: 1307\n",
      "Mean reward: 6.0430646837634585\n",
      "Loss: 2.505645513534546\n",
      "Current step: 1308\n",
      "Mean reward: 6.0430646837634585\n",
      "Loss: 4.276744842529297\n",
      "Current step: 1309\n",
      "Mean reward: 6.043193801125546\n",
      "Loss: 1.2091087102890015\n",
      "Current step: 1310\n",
      "Mean reward: 6.043193801125546\n",
      "Loss: 3.92444109916687\n",
      "Current step: 1311\n",
      "Mean reward: 6.043322458176182\n",
      "Loss: 3.376870632171631\n",
      "Current step: 1312\n",
      "Mean reward: 6.043322458176182\n",
      "Loss: 3.2316646575927734\n",
      "Current step: 1313\n",
      "Mean reward: 6.043450657372546\n",
      "Loss: 3.1564295291900635\n",
      "Current step: 1314\n",
      "Mean reward: 6.043450657372546\n",
      "Loss: 2.575471878051758\n",
      "Current step: 1315\n",
      "Mean reward: 6.043578401154357\n",
      "Loss: 3.6855814456939697\n",
      "Current step: 1316\n",
      "Mean reward: 6.043578401154357\n",
      "Loss: 1.8320707082748413\n",
      "Current step: 1317\n",
      "Mean reward: 6.043705691944035\n",
      "Loss: 0.21481560170650482\n",
      "Current step: 1318\n",
      "Mean reward: 6.043705691944035\n",
      "Loss: 2.0227010250091553\n",
      "Current step: 1319\n",
      "Mean reward: 6.043832532146847\n",
      "Loss: 2.3487303256988525\n",
      "Current step: 1320\n",
      "Mean reward: 6.043832532146847\n",
      "Loss: 3.0405895709991455\n",
      "Current step: 1321\n",
      "Mean reward: 6.043958924151061\n",
      "Loss: 1.435632586479187\n",
      "Current step: 1322\n",
      "Mean reward: 6.043958924151061\n",
      "Loss: 4.280692100524902\n",
      "Current step: 1323\n",
      "Mean reward: 6.0440848703281\n",
      "Loss: 2.565516948699951\n",
      "Current step: 1324\n",
      "Mean reward: 6.0440848703281\n",
      "Loss: 5.134002685546875\n",
      "Current step: 1325\n",
      "Mean reward: 6.044210373032685\n",
      "Loss: 2.6514787673950195\n",
      "Current step: 1326\n",
      "Mean reward: 6.044210373032685\n",
      "Loss: 1.8640772104263306\n",
      "Current step: 1327\n",
      "Mean reward: 6.044335434602984\n",
      "Loss: 4.282435894012451\n",
      "Current step: 1328\n",
      "Mean reward: 6.044335434602984\n",
      "Loss: 0.761444091796875\n",
      "Current step: 1329\n",
      "Mean reward: 6.044460057360754\n",
      "Loss: 3.7997379302978516\n",
      "Current step: 1330\n",
      "Mean reward: 6.044460057360754\n",
      "Loss: 3.5865488052368164\n",
      "Current step: 1331\n",
      "Mean reward: 6.044584243611493\n",
      "Loss: 2.390775203704834\n",
      "Current step: 1332\n",
      "Mean reward: 6.044584243611493\n",
      "Loss: 3.891430377960205\n",
      "Current step: 1333\n",
      "Mean reward: 6.044707995644572\n",
      "Loss: 1.3629906177520752\n",
      "Current step: 1334\n",
      "Mean reward: 6.044707995644572\n",
      "Loss: 2.3719558715820312\n",
      "Current step: 1335\n",
      "Mean reward: 6.044831315733382\n",
      "Loss: 3.0942604541778564\n",
      "Current step: 1336\n",
      "Mean reward: 6.044831315733382\n",
      "Loss: 3.686706304550171\n",
      "Current step: 1337\n",
      "Mean reward: 6.044954206135471\n",
      "Loss: 3.7052664756774902\n",
      "Current step: 1338\n",
      "Mean reward: 6.044954206135471\n",
      "Loss: 2.543900489807129\n",
      "Current step: 1339\n",
      "Mean reward: 6.0450766690926825\n",
      "Loss: 5.378718852996826\n",
      "Current step: 1340\n",
      "Mean reward: 6.0450766690926825\n",
      "Loss: 2.3787317276000977\n",
      "Current step: 1341\n",
      "Mean reward: 6.045198706831294\n",
      "Loss: 1.4815905094146729\n",
      "Current step: 1342\n",
      "Mean reward: 6.045198706831294\n",
      "Loss: 4.419749736785889\n",
      "Current step: 1343\n",
      "Mean reward: 6.045320321562145\n",
      "Loss: 2.424645185470581\n",
      "Current step: 1344\n",
      "Mean reward: 6.045320321562145\n",
      "Loss: 4.178696155548096\n",
      "Current step: 1345\n",
      "Mean reward: 6.045441515480778\n",
      "Loss: 3.337296962738037\n",
      "Current step: 1346\n",
      "Mean reward: 6.045441515480778\n",
      "Loss: 3.211627721786499\n",
      "Current step: 1347\n",
      "Mean reward: 6.0455622907675695\n",
      "Loss: 3.3690013885498047\n",
      "Current step: 1348\n",
      "Mean reward: 6.0455622907675695\n",
      "Loss: 4.85993766784668\n",
      "Current step: 1349\n",
      "Mean reward: 6.045682649587853\n",
      "Loss: 2.072554111480713\n",
      "Current step: 1350\n",
      "Mean reward: 6.045682649587853\n",
      "Loss: 3.2729508876800537\n",
      "Current step: 1351\n",
      "Mean reward: 6.045802594092061\n",
      "Loss: 2.988075017929077\n",
      "Current step: 1352\n",
      "Mean reward: 6.045802594092061\n",
      "Loss: 2.4573140144348145\n",
      "Current step: 1353\n",
      "Mean reward: 6.045922126415842\n",
      "Loss: 4.643846035003662\n",
      "Current step: 1354\n",
      "Mean reward: 6.045922126415842\n",
      "Loss: 3.344320058822632\n",
      "Current step: 1355\n",
      "Mean reward: 6.046041248680193\n",
      "Loss: 1.8325104713439941\n",
      "Current step: 1356\n",
      "Mean reward: 6.046041248680193\n",
      "Loss: 4.157384395599365\n",
      "Current step: 1357\n",
      "Mean reward: 6.046159962991583\n",
      "Loss: 2.356358289718628\n",
      "Current step: 1358\n",
      "Mean reward: 6.046159962991583\n",
      "Loss: 4.5010223388671875\n",
      "Current step: 1359\n",
      "Mean reward: 6.04627827144208\n",
      "Loss: 3.5891809463500977\n",
      "Current step: 1360\n",
      "Mean reward: 6.04627827144208\n",
      "Loss: 2.7963762283325195\n",
      "Current step: 1361\n",
      "Mean reward: 6.046396176109471\n",
      "Loss: 3.837632179260254\n",
      "Current step: 1362\n",
      "Mean reward: 6.046396176109471\n",
      "Loss: 4.312628746032715\n",
      "Current step: 1363\n",
      "Mean reward: 6.04651367905738\n",
      "Loss: 1.9074246883392334\n",
      "Current step: 1364\n",
      "Mean reward: 6.04651367905738\n",
      "Loss: 2.8574585914611816\n",
      "Current step: 1365\n",
      "Mean reward: 6.046630782335399\n",
      "Loss: 3.6605401039123535\n",
      "Current step: 1366\n",
      "Mean reward: 6.046630782335399\n",
      "Loss: 2.016813278198242\n",
      "Current step: 1367\n",
      "Mean reward: 6.0467474879791965\n",
      "Loss: 1.4887582063674927\n",
      "Current step: 1368\n",
      "Mean reward: 6.0467474879791965\n",
      "Loss: 2.9299814701080322\n",
      "Current step: 1369\n",
      "Mean reward: 6.0468637980106426\n",
      "Loss: 4.500544548034668\n",
      "Current step: 1370\n",
      "Mean reward: 6.0468637980106426\n",
      "Loss: 4.809350490570068\n",
      "Current step: 1371\n",
      "Mean reward: 6.0469797144379225\n",
      "Loss: 2.029994249343872\n",
      "Current step: 1372\n",
      "Mean reward: 6.0469797144379225\n",
      "Loss: 1.6867880821228027\n",
      "Current step: 1373\n",
      "Mean reward: 6.047095239255649\n",
      "Loss: 2.2626216411590576\n",
      "Current step: 1374\n",
      "Mean reward: 6.047095239255649\n",
      "Loss: 2.5829720497131348\n",
      "Current step: 1375\n",
      "Mean reward: 6.047210374444986\n",
      "Loss: 3.758476972579956\n",
      "Current step: 1376\n",
      "Mean reward: 6.047210374444986\n",
      "Loss: 2.0314292907714844\n",
      "Current step: 1377\n",
      "Mean reward: 6.047325121973753\n",
      "Loss: 0.713375449180603\n",
      "Current step: 1378\n",
      "Mean reward: 6.047325121973753\n",
      "Loss: 2.853407382965088\n",
      "Current step: 1379\n",
      "Mean reward: 6.04743948379654\n",
      "Loss: 3.0732855796813965\n",
      "Current step: 1380\n",
      "Mean reward: 6.04743948379654\n",
      "Loss: 0.9647151827812195\n",
      "Current step: 1381\n",
      "Mean reward: 6.047553461854822\n",
      "Loss: 2.724179267883301\n",
      "Current step: 1382\n",
      "Mean reward: 6.047553461854822\n",
      "Loss: 2.498847723007202\n",
      "Current step: 1383\n",
      "Mean reward: 6.047667058077063\n",
      "Loss: 2.3065409660339355\n",
      "Current step: 1384\n",
      "Mean reward: 6.047667058077063\n",
      "Loss: 2.0142312049865723\n",
      "Current step: 1385\n",
      "Mean reward: 6.047780274378827\n",
      "Loss: 2.9386818408966064\n",
      "Current step: 1386\n",
      "Mean reward: 6.047780274378827\n",
      "Loss: 3.079777717590332\n",
      "Current step: 1387\n",
      "Mean reward: 6.04789311266289\n",
      "Loss: 2.8200087547302246\n",
      "Current step: 1388\n",
      "Mean reward: 6.04789311266289\n",
      "Loss: 2.9770827293395996\n",
      "Current step: 1389\n",
      "Mean reward: 6.0480055748193395\n",
      "Loss: 1.921442985534668\n",
      "Current step: 1390\n",
      "Mean reward: 6.0480055748193395\n",
      "Loss: 1.6583808660507202\n",
      "Current step: 1391\n",
      "Mean reward: 6.048117662725685\n",
      "Loss: 6.189696788787842\n",
      "Current step: 1392\n",
      "Mean reward: 6.048117662725685\n",
      "Loss: 2.24731707572937\n",
      "Current step: 1393\n",
      "Mean reward: 6.048229378246957\n",
      "Loss: 3.049612522125244\n",
      "Current step: 1394\n",
      "Mean reward: 6.048229378246957\n",
      "Loss: 1.8437275886535645\n",
      "Current step: 1395\n",
      "Mean reward: 6.048340723235823\n",
      "Loss: 2.608901262283325\n",
      "Current step: 1396\n",
      "Mean reward: 6.048340723235823\n",
      "Loss: 2.82865047454834\n",
      "Current step: 1397\n",
      "Mean reward: 6.048451699532672\n",
      "Loss: 2.115753173828125\n",
      "Current step: 1398\n",
      "Mean reward: 6.048451699532672\n",
      "Loss: 3.1609854698181152\n",
      "Current step: 1399\n",
      "Mean reward: 6.048562308965729\n",
      "Loss: 3.453084945678711\n",
      "Current step: 1400\n",
      "Mean reward: 6.048562308965729\n",
      "Loss: 2.256669521331787\n",
      "Current step: 1401\n",
      "Mean reward: 6.048672553351153\n",
      "Loss: 3.455352783203125\n",
      "Current step: 1402\n",
      "Mean reward: 6.048672553351153\n",
      "Loss: 5.069779872894287\n",
      "Current step: 1403\n",
      "Mean reward: 6.048782434493131\n",
      "Loss: 2.465707540512085\n",
      "Current step: 1404\n",
      "Mean reward: 6.048782434493131\n",
      "Loss: 4.411500453948975\n",
      "Current step: 1405\n",
      "Mean reward: 6.048891954183986\n",
      "Loss: 4.267909526824951\n",
      "Current step: 1406\n",
      "Mean reward: 6.048891954183986\n",
      "Loss: 1.6611931324005127\n",
      "Current step: 1407\n",
      "Mean reward: 6.049001114204263\n",
      "Loss: 3.548840045928955\n",
      "Current step: 1408\n",
      "Mean reward: 6.049001114204263\n",
      "Loss: 1.2322853803634644\n",
      "Current step: 1409\n",
      "Mean reward: 6.049109916322834\n",
      "Loss: 4.167773246765137\n",
      "Current step: 1410\n",
      "Mean reward: 6.049109916322834\n",
      "Loss: 1.7903910875320435\n",
      "Current step: 1411\n",
      "Mean reward: 6.04921836229699\n",
      "Loss: 2.9146995544433594\n",
      "Current step: 1412\n",
      "Mean reward: 6.04921836229699\n",
      "Loss: 3.1869592666625977\n",
      "Current step: 1413\n",
      "Mean reward: 6.04921836229699\n",
      "Loss: 2.597519636154175\n",
      "Current step: 1414\n",
      "Mean reward: 6.04921836229699\n",
      "Loss: 2.948080539703369\n",
      "Current step: 1415\n",
      "Mean reward: 6.044587734473325\n",
      "Loss: 2.295341968536377\n",
      "Current step: 1416\n",
      "Mean reward: 6.044587734473325\n",
      "Loss: 2.0099005699157715\n",
      "Current step: 1417\n",
      "Mean reward: 6.044703203758902\n",
      "Loss: 1.0885581970214844\n",
      "Current step: 1418\n",
      "Mean reward: 6.044703203758902\n",
      "Loss: 2.8274800777435303\n",
      "Current step: 1419\n",
      "Mean reward: 6.044818296923029\n",
      "Loss: 5.552814960479736\n",
      "Current step: 1420\n",
      "Mean reward: 6.044818296923029\n",
      "Loss: 1.3814301490783691\n",
      "Current step: 1421\n",
      "Mean reward: 6.044933015800442\n",
      "Loss: 1.170433759689331\n",
      "Current step: 1422\n",
      "Mean reward: 6.044933015800442\n",
      "Loss: 3.796450138092041\n",
      "Current step: 1423\n",
      "Mean reward: 6.045047362213969\n",
      "Loss: 2.646034002304077\n",
      "Current step: 1424\n",
      "Mean reward: 6.045047362213969\n",
      "Loss: 1.9852923154830933\n",
      "Current step: 1425\n",
      "Mean reward: 6.045161337974614\n",
      "Loss: 1.7282915115356445\n",
      "Current step: 1426\n",
      "Mean reward: 6.045161337974614\n",
      "Loss: 1.7497107982635498\n",
      "Current step: 1427\n",
      "Mean reward: 6.045274944881665\n",
      "Loss: 1.287393569946289\n",
      "Current step: 1428\n",
      "Mean reward: 6.045274944881665\n",
      "Loss: 3.035247325897217\n",
      "Current step: 1429\n",
      "Mean reward: 6.045388184722782\n",
      "Loss: 3.3948144912719727\n",
      "Current step: 1430\n",
      "Mean reward: 6.045388184722782\n",
      "Loss: 3.616191864013672\n",
      "Current step: 1431\n",
      "Mean reward: 6.045501059274087\n",
      "Loss: 2.565746784210205\n",
      "Current step: 1432\n",
      "Mean reward: 6.045501059274087\n",
      "Loss: 3.1696081161499023\n",
      "Current step: 1433\n",
      "Mean reward: 6.045613570300269\n",
      "Loss: 1.6091954708099365\n",
      "Current step: 1434\n",
      "Mean reward: 6.045613570300269\n",
      "Loss: 2.7544262409210205\n",
      "Current step: 1435\n",
      "Mean reward: 6.045725719554662\n",
      "Loss: 2.16841983795166\n",
      "Current step: 1436\n",
      "Mean reward: 6.045725719554662\n",
      "Loss: 2.367100715637207\n",
      "Current step: 1437\n",
      "Mean reward: 6.045837508779345\n",
      "Loss: 1.581902027130127\n",
      "Current step: 1438\n",
      "Mean reward: 6.045837508779345\n",
      "Loss: 1.1015071868896484\n",
      "Current step: 1439\n",
      "Mean reward: 6.045948939705231\n",
      "Loss: 1.2090928554534912\n",
      "Current step: 1440\n",
      "Mean reward: 6.045948939705231\n",
      "Loss: 2.4758450984954834\n",
      "Current step: 1441\n",
      "Mean reward: 6.046060014052155\n",
      "Loss: 4.173011302947998\n",
      "Current step: 1442\n",
      "Mean reward: 6.046060014052155\n",
      "Loss: 2.301926612854004\n",
      "Current step: 1443\n",
      "Mean reward: 6.04617073352896\n",
      "Loss: 3.2957897186279297\n",
      "Current step: 1444\n",
      "Mean reward: 6.04617073352896\n",
      "Loss: 1.1321158409118652\n",
      "Current step: 1445\n",
      "Mean reward: 6.046281099833591\n",
      "Loss: 4.903717994689941\n",
      "Current step: 1446\n",
      "Mean reward: 6.046281099833591\n",
      "Loss: 3.658665895462036\n",
      "Current step: 1447\n",
      "Mean reward: 6.046391114653176\n",
      "Loss: 3.108945369720459\n",
      "Current step: 1448\n",
      "Mean reward: 6.046391114653176\n",
      "Loss: 1.5954530239105225\n",
      "Current step: 1449\n",
      "Mean reward: 6.046500779664112\n",
      "Loss: 2.8022403717041016\n",
      "Current step: 1450\n",
      "Mean reward: 6.046500779664112\n",
      "Loss: 3.073315143585205\n",
      "Current step: 1451\n",
      "Mean reward: 6.046610096532157\n",
      "Loss: 2.8394837379455566\n",
      "Current step: 1452\n",
      "Mean reward: 6.046610096532157\n",
      "Loss: 3.804368495941162\n",
      "Current step: 1453\n",
      "Mean reward: 6.046719066912506\n",
      "Loss: 5.895018100738525\n",
      "Current step: 1454\n",
      "Mean reward: 6.046719066912506\n",
      "Loss: 1.9681074619293213\n",
      "Current step: 1455\n",
      "Mean reward: 6.04682769244988\n",
      "Loss: 3.4058773517608643\n",
      "Current step: 1456\n",
      "Mean reward: 6.04682769244988\n",
      "Loss: 1.7873139381408691\n",
      "Current step: 1457\n",
      "Mean reward: 6.046935974778604\n",
      "Loss: 1.1742106676101685\n",
      "Current step: 1458\n",
      "Mean reward: 6.046935974778604\n",
      "Loss: 1.0992133617401123\n",
      "Current step: 1459\n",
      "Mean reward: 6.047043915522695\n",
      "Loss: 2.1207563877105713\n",
      "Current step: 1460\n",
      "Mean reward: 6.047043915522695\n",
      "Loss: 1.0379064083099365\n",
      "Current step: 1461\n",
      "Mean reward: 6.04715151629594\n",
      "Loss: 2.73288631439209\n",
      "Current step: 1462\n",
      "Mean reward: 6.04715151629594\n",
      "Loss: 1.929121494293213\n",
      "Current step: 1463\n",
      "Mean reward: 6.047258778701971\n",
      "Loss: 2.0910420417785645\n",
      "Current step: 1464\n",
      "Mean reward: 6.047258778701971\n",
      "Loss: 1.1584748029708862\n",
      "Current step: 1465\n",
      "Mean reward: 6.047365704334358\n",
      "Loss: 2.601261615753174\n",
      "Current step: 1466\n",
      "Mean reward: 6.047365704334358\n",
      "Loss: 2.8841536045074463\n",
      "Current step: 1467\n",
      "Mean reward: 6.047472294776676\n",
      "Loss: 1.678274154663086\n",
      "Current step: 1468\n",
      "Mean reward: 6.047472294776676\n",
      "Loss: 0.5547699332237244\n",
      "Current step: 1469\n",
      "Mean reward: 6.047578551602584\n",
      "Loss: 1.666649580001831\n",
      "Current step: 1470\n",
      "Mean reward: 6.047578551602584\n",
      "Loss: 3.4077951908111572\n",
      "Current step: 1471\n",
      "Mean reward: 6.0476844763759114\n",
      "Loss: 1.7570422887802124\n",
      "Current step: 1472\n",
      "Mean reward: 6.0476844763759114\n",
      "Loss: 3.919325351715088\n",
      "Current step: 1473\n",
      "Mean reward: 6.047790070650727\n",
      "Loss: 3.00329852104187\n",
      "Current step: 1474\n",
      "Mean reward: 6.047790070650727\n",
      "Loss: 4.631214141845703\n",
      "Current step: 1475\n",
      "Mean reward: 6.047895335971415\n",
      "Loss: 3.167912483215332\n",
      "Current step: 1476\n",
      "Mean reward: 6.047895335971415\n",
      "Loss: 2.1607887744903564\n",
      "Current step: 1477\n",
      "Mean reward: 6.048000273872754\n",
      "Loss: 1.8881992101669312\n",
      "Current step: 1478\n",
      "Mean reward: 6.048000273872754\n",
      "Loss: 0.8567246198654175\n",
      "Current step: 1479\n",
      "Mean reward: 6.048104885879989\n",
      "Loss: 3.887585163116455\n",
      "Current step: 1480\n",
      "Mean reward: 6.048104885879989\n",
      "Loss: 3.584188222885132\n",
      "Current step: 1481\n",
      "Mean reward: 6.048209173508908\n",
      "Loss: 1.6033620834350586\n",
      "Current step: 1482\n",
      "Mean reward: 6.048209173508908\n",
      "Loss: 4.755688667297363\n",
      "Current step: 1483\n",
      "Mean reward: 6.048313138265911\n",
      "Loss: 2.339608669281006\n",
      "Current step: 1484\n",
      "Mean reward: 6.048313138265911\n",
      "Loss: 4.598006248474121\n",
      "Current step: 1485\n",
      "Mean reward: 6.0484167816480845\n",
      "Loss: 4.258543491363525\n",
      "Current step: 1486\n",
      "Mean reward: 6.0484167816480845\n",
      "Loss: 4.548460483551025\n",
      "Current step: 1487\n",
      "Mean reward: 6.048520105143276\n",
      "Loss: 4.207089900970459\n",
      "Current step: 1488\n",
      "Mean reward: 6.048520105143276\n",
      "Loss: 1.453167200088501\n",
      "Current step: 1489\n",
      "Mean reward: 6.048623110230163\n",
      "Loss: 2.320298194885254\n",
      "Current step: 1490\n",
      "Mean reward: 6.048623110230163\n",
      "Loss: 2.501173496246338\n",
      "Current step: 1491\n",
      "Mean reward: 6.04872579837832\n",
      "Loss: 2.7052650451660156\n",
      "Current step: 1492\n",
      "Mean reward: 6.04872579837832\n",
      "Loss: 2.1429190635681152\n",
      "Current step: 1493\n",
      "Mean reward: 6.048828171048295\n",
      "Loss: 2.781342029571533\n",
      "Current step: 1494\n",
      "Mean reward: 6.048828171048295\n",
      "Loss: 1.5600084066390991\n",
      "Current step: 1495\n",
      "Mean reward: 6.048930229691676\n",
      "Loss: 3.1245274543762207\n",
      "Current step: 1496\n",
      "Mean reward: 6.048930229691676\n",
      "Loss: 3.4969382286071777\n",
      "Current step: 1497\n",
      "Mean reward: 6.049031975751157\n",
      "Loss: 1.111977219581604\n",
      "Current step: 1498\n",
      "Mean reward: 6.049031975751157\n",
      "Loss: 1.3983545303344727\n",
      "Current step: 1499\n",
      "Mean reward: 6.049133410660608\n",
      "Loss: 3.668276309967041\n",
      "Current step: 1500\n",
      "Mean reward: 6.049133410660608\n",
      "Loss: 1.009364128112793\n",
      "Current step: 1501\n",
      "Mean reward: 6.0492345358451445\n",
      "Loss: 1.1423594951629639\n",
      "Current step: 1502\n",
      "Mean reward: 6.0492345358451445\n",
      "Loss: 1.717923641204834\n",
      "Current step: 1503\n",
      "Mean reward: 6.049335352721194\n",
      "Loss: 2.2761099338531494\n",
      "Current step: 1504\n",
      "Mean reward: 6.049335352721194\n",
      "Loss: 2.0498385429382324\n",
      "Current step: 1505\n",
      "Mean reward: 6.049435862696552\n",
      "Loss: 3.0688881874084473\n",
      "Current step: 1506\n",
      "Mean reward: 6.049435862696552\n",
      "Loss: 2.854285478591919\n",
      "Current step: 1507\n",
      "Mean reward: 6.049536067170467\n",
      "Loss: 2.313007116317749\n",
      "Current step: 1508\n",
      "Mean reward: 6.049536067170467\n",
      "Loss: 1.5235629081726074\n",
      "Current step: 1509\n",
      "Mean reward: 6.049635967533688\n",
      "Loss: 2.8101940155029297\n",
      "Current step: 1510\n",
      "Mean reward: 6.049635967533688\n",
      "Loss: 1.0980005264282227\n",
      "Current step: 1511\n",
      "Mean reward: 6.049735565168533\n",
      "Loss: 4.998604774475098\n",
      "Current step: 1512\n",
      "Mean reward: 6.049735565168533\n",
      "Loss: 2.4413437843322754\n",
      "Current step: 1513\n",
      "Mean reward: 6.049834861448963\n",
      "Loss: 2.8487601280212402\n",
      "Current step: 1514\n",
      "Mean reward: 6.049834861448963\n",
      "Loss: 4.268421173095703\n",
      "Current step: 1515\n",
      "Mean reward: 6.049834861448963\n",
      "Loss: 2.8288040161132812\n",
      "Current step: 1516\n",
      "Mean reward: 6.049834861448963\n",
      "Loss: 3.783766031265259\n",
      "Current step: 1517\n",
      "Mean reward: 6.045553047661598\n",
      "Loss: 3.904816150665283\n",
      "Current step: 1518\n",
      "Mean reward: 6.045553047661598\n",
      "Loss: 3.6248104572296143\n",
      "Current step: 1519\n",
      "Mean reward: 6.045658352878599\n",
      "Loss: 3.498237371444702\n",
      "Current step: 1520\n",
      "Mean reward: 6.045658352878599\n",
      "Loss: 3.5461385250091553\n",
      "Current step: 1521\n",
      "Mean reward: 6.04576334091121\n",
      "Loss: 2.8086953163146973\n",
      "Current step: 1522\n",
      "Mean reward: 6.04576334091121\n",
      "Loss: 1.5519014596939087\n",
      "Current step: 1523\n",
      "Mean reward: 6.04586801319034\n",
      "Loss: 2.2093658447265625\n",
      "Current step: 1524\n",
      "Mean reward: 6.04586801319034\n",
      "Loss: 3.057438850402832\n",
      "Current step: 1525\n",
      "Mean reward: 6.0459723711383\n",
      "Loss: 1.7129199504852295\n",
      "Current step: 1526\n",
      "Mean reward: 6.0459723711383\n",
      "Loss: 1.272656798362732\n",
      "Current step: 1527\n",
      "Mean reward: 6.0460764161688765\n",
      "Loss: 2.2995760440826416\n",
      "Current step: 1528\n",
      "Mean reward: 6.0460764161688765\n",
      "Loss: 0.8330962061882019\n",
      "Current step: 1529\n",
      "Mean reward: 6.046180149687385\n",
      "Loss: 2.8100593090057373\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# print(\"Q1_selected shape:\", Q1_selected.shape)  # Debug\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Compute target Q-values using the target network\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 42\u001b[0m     Q_next_state \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_NN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnsteps_next_state_batch\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: (batch_size, num_actions)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     selected_nodes_for_target_network \u001b[38;5;241m=\u001b[39m Q_next_state\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Shape: (batch_size,)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     best_Q_next_state \u001b[38;5;241m=\u001b[39m Q_next_state\u001b[38;5;241m.\u001b[39mgather(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, index\u001b[38;5;241m=\u001b[39mselected_nodes_for_target_network\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze()  \u001b[38;5;66;03m# Shape: (batch_size,)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[61], line 38\u001b[0m, in \u001b[0;36mDuelingConv1DQNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     35\u001b[0m info_x \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m3\u001b[39m:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Extract position and profit/loss from last time step\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Process price data through convolutional layers\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m price_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprice_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprice_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Concatenate with position and profit/loss\u001b[39;00m\n\u001b[0;32m     41\u001b[0m features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([price_features, info_x], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\anshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\anshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\anshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\anshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[0;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    369\u001b[0m     )\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while k < 1000000:\n",
    "    game = AAPL_env(df, commission_perc=0.1, obs_bars=obs_bars)\n",
    "    state, _, _ = game.step(\"do_nothing\")  # Shape: (5, 50)\n",
    "    state1 = preprocess_state(state, add_noise=False)\n",
    "    status = 1\n",
    "    episode_rewards = []\n",
    "    \n",
    "    while status == 1:\n",
    "        k += 1\n",
    "        \n",
    "        # Select action using epsilon-greedy policy\n",
    "        with torch.no_grad():\n",
    "            qval = Agent_NN(state1.to(device))  # Shape: (1, num_actions)\n",
    "            qval_ = qval.cpu().numpy()\n",
    "        action = get_action(qval_, 3, epsilon)\n",
    "        action_name = actions[action]\n",
    "        \n",
    "        # Take a step in the environment\n",
    "        state2, reward, done = game.step(action_name)\n",
    "        state2 = preprocess_state(state2, add_noise=False)  # Shape: (1, 3, 50)\n",
    "        exp = (state1, action, reward, state2, done)\n",
    "        replay.append(exp)\n",
    "        episode_rewards.append(reward)\n",
    "        \n",
    "        # Update epsilon for exploration-exploitation trade-off\n",
    "        epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "        \n",
    "        # Train if enough experiences are in the replay buffer\n",
    "        if len(replay) >= batch_size + 2:\n",
    "            state1_batch, action1_batch, nsteps_next_state_batch, nsteps_reward_batch, nsteps_done_batch = get_batch_for_nsteps_dqn(\n",
    "                replay=replay, batch_size=batch_size, nsteps=2, device=device\n",
    "            )\n",
    "            \n",
    "            Q1 = Agent_NN(state1_batch)\n",
    "            # print(\"Q1 shape:\", Q1.shape)  # Debug\n",
    "            # print(\"action1_batch shape:\", action1_batch.shape)  # Debug\n",
    "            Q1_selected = Q1.gather(dim=1, index=action1_batch.unsqueeze(dim=1)).squeeze()\n",
    "            # print(\"Q1_selected shape:\", Q1_selected.shape)  # Debug\n",
    "            \n",
    "            # Compute target Q-values using the target network\n",
    "            with torch.no_grad():\n",
    "                Q_next_state = target_NN(nsteps_next_state_batch)  # Shape: (batch_size, num_actions)\n",
    "                selected_nodes_for_target_network = Q_next_state.max(dim=1)[1]  # Shape: (batch_size,)\n",
    "                best_Q_next_state = Q_next_state.gather(dim=1, index=selected_nodes_for_target_network.unsqueeze(dim=1)).squeeze()  # Shape: (batch_size,)\n",
    "                Y_batch_target_for_nsteps_don = (nsteps_reward_batch + (1 - nsteps_done_batch) * best_Q_next_state).to(device)  # Shape: (batch_size,)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_fn(Q1_selected, Y_batch_target_for_nsteps_don)\n",
    "            Q_losses.append(loss.item())\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print progress\n",
    "            print(\"Current step:\", k)\n",
    "            print(\"Mean reward:\", np.mean(all_rewards_list) if all_rewards_list else 0)\n",
    "            print(\"Loss:\", loss.item())\n",
    "        \n",
    "        state1 = state2\n",
    "        status = 1 - done\n",
    "    \n",
    "    all_rewards_list.append(np.sum(episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2998a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
